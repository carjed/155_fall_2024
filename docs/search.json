[
  {
    "objectID": "solutions/04_slr_formalization.html",
    "href": "solutions/04_slr_formalization.html",
    "title": "Solutions for simple linear regression: formalizing concepts",
    "section": "",
    "text": "# Load packages and import data\nlibrary(readr)\nlibrary(ggplot2)\nlibrary(dplyr)\n\nbikes &lt;- read_csv(\"https://mac-stat.github.io/data/bikeshare.csv\")\n\n\ndim(bikes)\n\n[1] 731  15\n\nhead(bikes)\n\n# A tibble: 6 × 15\n  date       season  year month day_of_week weekend holiday temp_actual\n  &lt;date&gt;     &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;       &lt;lgl&gt;   &lt;chr&gt;         &lt;dbl&gt;\n1 2011-01-01 winter  2011 Jan   Sat         TRUE    no             57.4\n2 2011-01-02 winter  2011 Jan   Sun         TRUE    no             58.8\n3 2011-01-03 winter  2011 Jan   Mon         FALSE   no             46.5\n4 2011-01-04 winter  2011 Jan   Tue         FALSE   no             46.8\n5 2011-01-05 winter  2011 Jan   Wed         FALSE   no             48.7\n6 2011-01-06 winter  2011 Jan   Thu         FALSE   no             47.1\n# ℹ 7 more variables: temp_feel &lt;dbl&gt;, humidity &lt;dbl&gt;, windspeed &lt;dbl&gt;,\n#   weather_cat &lt;chr&gt;, riders_casual &lt;dbl&gt;, riders_registered &lt;dbl&gt;,\n#   riders_total &lt;dbl&gt;\n\n\n\nA case represents a day of the year.\nWe have 15 variables broadly concerning weather, day of week information, whether the day is a holiday.\nLots of answers are reasonable here! When and where seem to be particularly relevant because this is for a rideshare based in Washington DC with data from 2011-2012. Ridership likely changes a lot from city to city and over time."
  },
  {
    "objectID": "solutions/04_slr_formalization.html#exercise-1-get-to-know-the-data",
    "href": "solutions/04_slr_formalization.html#exercise-1-get-to-know-the-data",
    "title": "Solutions for simple linear regression: formalizing concepts",
    "section": "",
    "text": "# Load packages and import data\nlibrary(readr)\nlibrary(ggplot2)\nlibrary(dplyr)\n\nbikes &lt;- read_csv(\"https://mac-stat.github.io/data/bikeshare.csv\")\n\n\ndim(bikes)\n\n[1] 731  15\n\nhead(bikes)\n\n# A tibble: 6 × 15\n  date       season  year month day_of_week weekend holiday temp_actual\n  &lt;date&gt;     &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;       &lt;lgl&gt;   &lt;chr&gt;         &lt;dbl&gt;\n1 2011-01-01 winter  2011 Jan   Sat         TRUE    no             57.4\n2 2011-01-02 winter  2011 Jan   Sun         TRUE    no             58.8\n3 2011-01-03 winter  2011 Jan   Mon         FALSE   no             46.5\n4 2011-01-04 winter  2011 Jan   Tue         FALSE   no             46.8\n5 2011-01-05 winter  2011 Jan   Wed         FALSE   no             48.7\n6 2011-01-06 winter  2011 Jan   Thu         FALSE   no             47.1\n# ℹ 7 more variables: temp_feel &lt;dbl&gt;, humidity &lt;dbl&gt;, windspeed &lt;dbl&gt;,\n#   weather_cat &lt;chr&gt;, riders_casual &lt;dbl&gt;, riders_registered &lt;dbl&gt;,\n#   riders_total &lt;dbl&gt;\n\n\n\nA case represents a day of the year.\nWe have 15 variables broadly concerning weather, day of week information, whether the day is a holiday.\nLots of answers are reasonable here! When and where seem to be particularly relevant because this is for a rideshare based in Washington DC with data from 2011-2012. Ridership likely changes a lot from city to city and over time."
  },
  {
    "objectID": "solutions/04_slr_formalization.html#exercise-2-get-to-know-the-outcomeresponse-variable",
    "href": "solutions/04_slr_formalization.html#exercise-2-get-to-know-the-outcomeresponse-variable",
    "title": "Solutions for simple linear regression: formalizing concepts",
    "section": "Exercise 2: Get to know the outcome/response variable",
    "text": "Exercise 2: Get to know the outcome/response variable\nThe distribution of the riders_registered variable looks fairly symmetric. On average there are about 3600 registered riders per day (mean = 3656, median = 3662). On any given day, the number of registered riders is about 1560 from the mean. There seem to be a small number of low outliers (minimum ridership was 20).\n\nggplot(bikes, aes(x = riders_registered)) +\n    geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nggplot(bikes, aes(y = riders_registered)) +\n    geom_boxplot()\n\n\n\n\n\n\n\nsummary(bikes$riders_registered)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n     20    2497    3662    3656    4776    6946 \n\nbikes %&gt;% \n    summarize(sd(riders_registered))\n\n# A tibble: 1 × 1\n  `sd(riders_registered)`\n                    &lt;dbl&gt;\n1                   1560."
  },
  {
    "objectID": "solutions/04_slr_formalization.html#exercise-3-explore-the-relationship-between-ridership-and-temperature",
    "href": "solutions/04_slr_formalization.html#exercise-3-explore-the-relationship-between-ridership-and-temperature",
    "title": "Solutions for simple linear regression: formalizing concepts",
    "section": "Exercise 3: Explore the relationship between ridership and temperature",
    "text": "Exercise 3: Explore the relationship between ridership and temperature\nWe’d like to understand how daily ridership among registered users relates with the temperature that it feels like that day (temp_feel).\n\nScatterplot (outcome and predictor are both quantitative)\n\n\n\nggplot(bikes, aes(x = temp_feel, y = riders_registered)) +\n    geom_point()\n\n\n\n\n\n\n\n\n\nIf we only displayed the red line of best fit on the plot, we might miss the slight downward trend at the highest temperatures that we can see more clearly with the blue curve of best fit. A linear model is not appropriate if fit to the whole range of the data, but there does seem to be a linear relationship between ridership and temperature below 80 degrees Fahrenheit.\n\n\n# Add a red straight line of best fit and a blue curve of best fit\nggplot(bikes, aes(x = temp_feel, y = riders_registered)) +\n    geom_point() +\n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE) +\n    geom_smooth(color = \"blue\", se = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'"
  },
  {
    "objectID": "solutions/04_slr_formalization.html#exercise-4-filtering-our-data",
    "href": "solutions/04_slr_formalization.html#exercise-4-filtering-our-data",
    "title": "Solutions for simple linear regression: formalizing concepts",
    "section": "Exercise 4: Filtering our data",
    "text": "Exercise 4: Filtering our data\n\n# The %&gt;% is called a \"pipe\" and feeds what comes before it\n# into what comes after (bikes data is \"fed into\" the filter() function)\nbikes_sub &lt;- bikes %&gt;% \n    filter(temp_feel &lt; 80)"
  },
  {
    "objectID": "solutions/04_slr_formalization.html#exercise-5-model-fitting-and-coefficient-interpretation",
    "href": "solutions/04_slr_formalization.html#exercise-5-model-fitting-and-coefficient-interpretation",
    "title": "Solutions for simple linear regression: formalizing concepts",
    "section": "Exercise 5: Model fitting and coefficient interpretation",
    "text": "Exercise 5: Model fitting and coefficient interpretation\nLet’s fit a simple linear regression model and examine the results. Step through code chunk slowly, and make note of new code.\n\n# Construct and save the model as bike_mod\n# What's the purpose of \"riders_registered ~ temp_feel\"?\n# What's the purpose of \"data = bikes_sub\"?\nbike_mod &lt;- lm(riders_registered ~ temp_feel, data = bikes_sub)\n\n\n# A long summary of the model stored in bike_mod\nsummary(bike_mod)\n\n\nCall:\nlm(formula = riders_registered ~ temp_feel, data = bikes_sub)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3681.8  -928.3   -98.6   904.9  3496.7 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -2486.412    421.379  -5.901 7.37e-09 ***\ntemp_feel      86.493      6.464  13.380  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1267 on 428 degrees of freedom\nMultiple R-squared:  0.2949,    Adjusted R-squared:  0.2933 \nF-statistic:   179 on 1 and 428 DF,  p-value: &lt; 2.2e-16\n\n\n\n# A simplified model summary\ncoef(summary(bike_mod))\n\n               Estimate Std. Error   t value     Pr(&gt;|t|)\n(Intercept) -2486.41180 421.379174 -5.900652 7.368345e-09\ntemp_feel      86.49251   6.464247 13.380135 2.349753e-34\n\n\n\nE[riders_registered | temp_feel] = -2486.41180 + 86.49251 * temp_feel\nIntercept interpretation: On days that feel like 0 degrees Fahrenheit, we can expect an average of -2486.41180 riders—a negative number of riders doesn’t make sense! This results because of extrapolation—0 degrees is so far below the minimum temperature in the data. We only have information on the relationship between ridership and temperature in the ~40-100 degree range and have no idea what that relationship looks like outside that range.\nSlope interpretation: Every 1 degree increase in feeling temperature is associated with an average of about 86 more riders."
  },
  {
    "objectID": "solutions/04_slr_formalization.html#exercise-6-predictions-and-residuals",
    "href": "solutions/04_slr_formalization.html#exercise-6-predictions-and-residuals",
    "title": "Solutions for simple linear regression: formalizing concepts",
    "section": "Exercise 6: Predictions and residuals",
    "text": "Exercise 6: Predictions and residuals\nOn August 17, 2012, the temp_feel was 53.816 degrees and there were 5665 riders. We can get data for this day using the filter() and select() dplyr functions. Note, but don’t worry about the syntax – we haven’t learned this yet:\n\nbikes_sub %&gt;% \n    filter(date == \"2012-08-17\") %&gt;% \n    select(riders_registered, temp_feel) \n\n# A tibble: 1 × 2\n  riders_registered temp_feel\n              &lt;dbl&gt;     &lt;dbl&gt;\n1              5665      53.8\n\n\n\nMore riders than expected – the point is far above the trend line\n-2486.41180 + 86.49251 * 53.816 = 2168.269\nWe get the same result with predict():\n\n\n# What is the purpose of newdata = ___???\npredict(bike_mod, newdata = data.frame(temp_feel = 53.816))\n\n       1 \n2168.269 \n\n\n\nresidual = 5665 - 2168.269 = 3496.731. On August 17, 2012, there were 3496.731 more riders than would be expected from our model.\n\nPositive residuals are above the trend line—we under-estimate ridership.\nNegative residuals are below the trend line—we over-estimate ridership.\n\nOn an 85 degree day, we would predict 4865.452 riders. Even though we can compute this prediction, it’s not a good idea because of extrapolation–the data that we used to fit our model was filtered to days less than 80 degrees.\n\n\n-2486.41180 + 86.49251 * 85\n\n[1] 4865.452\n\npredict(bike_mod, newdata = data.frame(temp_feel = 85))\n\n       1 \n4865.451"
  },
  {
    "objectID": "solutions/04_slr_formalization.html#exercise-7-changing-temperature-units-challenge",
    "href": "solutions/04_slr_formalization.html#exercise-7-changing-temperature-units-challenge",
    "title": "Solutions for simple linear regression: formalizing concepts",
    "section": "Exercise 7: Changing temperature units (CHALLENGE)",
    "text": "Exercise 7: Changing temperature units (CHALLENGE)\nIf we had measured temperature in degrees Celsius rather than degrees Fahrenheit, both the intercept and slope should change. The intercept would now represent 0 degrees Celsius (32 degrees Fahrenheit) and a one unit change in temperature is now 1 degree Celsius (1.8 degrees Fahrenheit)."
  },
  {
    "objectID": "solutions/04_slr_formalization.html#exercise-8-ridership-and-windspeed",
    "href": "solutions/04_slr_formalization.html#exercise-8-ridership-and-windspeed",
    "title": "Solutions for simple linear regression: formalizing concepts",
    "section": "Exercise 8: Ridership and windspeed",
    "text": "Exercise 8: Ridership and windspeed\nLet’s pull together everything that you’ve practiced in the preceding exercises to investigate the relationship between riders_registered and windspeed. Go back to using the bikes dataset (instead of bikes_sub) because we no longer need to only keep days less than 80 degrees.\n\n# Construct and interpret a visualization of this relationship\n# Include a representation of the relationship trend\nggplot(bikes, aes(x = windspeed, y = riders_registered)) + \n    geom_point() + \n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE) +\n    geom_smooth(color = \"blue\", se = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n# Use lm to construct a model of riders_registered vs windspeed\n# Save this as bike_mod2\nbike_mod2 &lt;- lm(riders_registered ~ windspeed, data = bikes)\n\n# Get a short summary of this model\ncoef(summary(bike_mod2))\n\n              Estimate Std. Error   t value      Pr(&gt;|t|)\n(Intercept) 4490.09761  149.65992 30.002005 2.023179e-129\nwindspeed    -65.34145   10.86299 -6.015053  2.844453e-09\n\n\n\nThere’s a weak, negative relationship – ridership tends to be smaller on windier days.\nE[riders_registered | windspeed] = 4490.09761 - 65.34145 windspeed\n\nIntercept: On days with no wind, we’d expect around 4490 riders. (0 is a little below the minimum of the observed data, but not by much! So extrapolation in interpreting the intercept isn’t a huge concern.)\nSlope: Every 1mph increase in windspeed is associated with a ridership decrease of 65 riders on average.\n\nSee the code below to predict ridership on August 17, 2012 and calculate the corresponding residual. Note that this residual is smaller than the residual from the temperature model (that residual was 3496.731). This indicates that August 17 was more of an outlier in ridership given the temperature than the windspeed.\n\n\nbikes %&gt;% \n    filter(date == \"2012-08-17\") %&gt;% \n    select(riders_registered, windspeed)\n\n# A tibble: 1 × 2\n  riders_registered windspeed\n              &lt;dbl&gt;     &lt;dbl&gt;\n1              5665      15.5\n\n# prediction\n4490.09761 - 65.34145 * 15.50072\n\n[1] 3477.258\n\n# residual \n5665 - 3477.258\n\n[1] 2187.742"
  },
  {
    "objectID": "solutions/04_slr_formalization.html#exercise-9-data-drills-filter-select-summarize",
    "href": "solutions/04_slr_formalization.html#exercise-9-data-drills-filter-select-summarize",
    "title": "Solutions for simple linear regression: formalizing concepts",
    "section": "Exercise 9: Data drills (filter, select, summarize)",
    "text": "Exercise 9: Data drills (filter, select, summarize)\nThis exercise is designed to help you keep building your dplyr skills. These skills are important to data cleaning and digging, which in turn is important to really making meaning of our data. We’ll work with a simpler set of 10 data points:\n\nnew_bikes &lt;- bikes %&gt;% \n    select(date, temp_feel, humidity, riders_registered, day_of_week) %&gt;% \n    head(10)\n\n\nVerb 1: summarize\nsummarize() calculates numerical summaries of variables (columns).\n\nnew_bikes %&gt;% \n    summarize(mean(temp_feel), mean(humidity))\n\n# A tibble: 1 × 2\n  `mean(temp_feel)` `mean(humidity)`\n              &lt;dbl&gt;            &lt;dbl&gt;\n1              52.0            0.544\n\n\n\n\nVerb 2: select\nselect() selects variables (columns).\n\nnew_bikes %&gt;%\n    select(date, temp_feel)\n\n# A tibble: 10 × 2\n   date       temp_feel\n   &lt;date&gt;         &lt;dbl&gt;\n 1 2011-01-01      64.7\n 2 2011-01-02      63.8\n 3 2011-01-03      49.0\n 4 2011-01-04      51.1\n 5 2011-01-05      52.6\n 6 2011-01-06      53.0\n 7 2011-01-07      50.8\n 8 2011-01-08      46.6\n 9 2011-01-09      42.5\n10 2011-01-10      45.6\n\n\n\nnew_bikes %&gt;% \n    select(-date, -temp_feel)\n\n# A tibble: 10 × 3\n   humidity riders_registered day_of_week\n      &lt;dbl&gt;             &lt;dbl&gt; &lt;chr&gt;      \n 1    0.806               654 Sat        \n 2    0.696               670 Sun        \n 3    0.437              1229 Mon        \n 4    0.590              1454 Tue        \n 5    0.437              1518 Wed        \n 6    0.518              1518 Thu        \n 7    0.499              1362 Fri        \n 8    0.536               891 Sat        \n 9    0.434               768 Sun        \n10    0.483              1280 Mon        \n\n\n\n\nVerb 3: filter\nfilter() keeps only days (rows) that meet the given condition(s).\n\nnew_bikes %&gt;% \n    filter(riders_registered &gt; 850)\n\n# A tibble: 7 × 5\n  date       temp_feel humidity riders_registered day_of_week\n  &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;             &lt;dbl&gt; &lt;chr&gt;      \n1 2011-01-03      49.0    0.437              1229 Mon        \n2 2011-01-04      51.1    0.590              1454 Tue        \n3 2011-01-05      52.6    0.437              1518 Wed        \n4 2011-01-06      53.0    0.518              1518 Thu        \n5 2011-01-07      50.8    0.499              1362 Fri        \n6 2011-01-08      46.6    0.536               891 Sat        \n7 2011-01-10      45.6    0.483              1280 Mon        \n\n\n\nnew_bikes %&gt;% \n    filter(day_of_week == \"Sat\")\n\n# A tibble: 2 × 5\n  date       temp_feel humidity riders_registered day_of_week\n  &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;             &lt;dbl&gt; &lt;chr&gt;      \n1 2011-01-01      64.7    0.806               654 Sat        \n2 2011-01-08      46.6    0.536               891 Sat        \n\n\n\nnew_bikes %&gt;% \n    filter(riders_registered &gt; 850, day_of_week == \"Sat\")\n\n# A tibble: 1 × 5\n  date       temp_feel humidity riders_registered day_of_week\n  &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;             &lt;dbl&gt; &lt;chr&gt;      \n1 2011-01-08      46.6    0.536               891 Sat"
  },
  {
    "objectID": "solutions/04_slr_formalization.html#exercise-10-your-turn",
    "href": "solutions/04_slr_formalization.html#exercise-10-your-turn",
    "title": "Solutions for simple linear regression: formalizing concepts",
    "section": "Exercise 10: Your turn",
    "text": "Exercise 10: Your turn\nUse dplyr verbs to complete each task below.\n\n# Keep only information about the humidity and day of week\nnew_bikes %&gt;% \n    select(humidity, day_of_week)\n\n# A tibble: 10 × 2\n   humidity day_of_week\n      &lt;dbl&gt; &lt;chr&gt;      \n 1    0.806 Sat        \n 2    0.696 Sun        \n 3    0.437 Mon        \n 4    0.590 Tue        \n 5    0.437 Wed        \n 6    0.518 Thu        \n 7    0.499 Fri        \n 8    0.536 Sat        \n 9    0.434 Sun        \n10    0.483 Mon        \n\n# Keep only information about the humidity and day of week using a different approach\nnew_bikes %&gt;% \n    select(-date, -temp_feel, -riders_registered)\n\n# A tibble: 10 × 2\n   humidity day_of_week\n      &lt;dbl&gt; &lt;chr&gt;      \n 1    0.806 Sat        \n 2    0.696 Sun        \n 3    0.437 Mon        \n 4    0.590 Tue        \n 5    0.437 Wed        \n 6    0.518 Thu        \n 7    0.499 Fri        \n 8    0.536 Sat        \n 9    0.434 Sun        \n10    0.483 Mon        \n\n# Keep only information for Sundays\nnew_bikes %&gt;% \n    filter(day_of_week == \"Sun\")\n\n# A tibble: 2 × 5\n  date       temp_feel humidity riders_registered day_of_week\n  &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;             &lt;dbl&gt; &lt;chr&gt;      \n1 2011-01-02      63.8    0.696               670 Sun        \n2 2011-01-09      42.5    0.434               768 Sun        \n\n# Keep only information for Sundays with temperatures below 50\nnew_bikes %&gt;% \n    filter(day_of_week == \"Sun\", temp_feel &lt; 50)\n\n# A tibble: 1 × 5\n  date       temp_feel humidity riders_registered day_of_week\n  &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;             &lt;dbl&gt; &lt;chr&gt;      \n1 2011-01-09      42.5    0.434               768 Sun        \n\n# Calculate the maximum and minimum temperatures\nnew_bikes %&gt;% \n    summarize(min(temp_feel), max(temp_feel))\n\n# A tibble: 1 × 2\n  `min(temp_feel)` `max(temp_feel)`\n             &lt;dbl&gt;            &lt;dbl&gt;\n1             42.5             64.7"
  },
  {
    "objectID": "solutions/02_foundations_univariate.html",
    "href": "solutions/02_foundations_univariate.html",
    "title": "Solutions for Univariate visualization and summaries",
    "section": "",
    "text": "Results of brainstorming themes will vary\nFrom the “Data and Method” section at the end of the Pudding article, we see this paragraph:\n\n\nThe writers of these questions likely skew roughly 2/3 female (according to Pauline Phillips, who mentions the demographics of responses to a survey she disseminated in 1987), and consequently, their interests are overrepresented; we’ve been unable to find other demographic data surrounding their origins. There is, doubtless, a level of editorializing here: only a fraction of the questions that people have written in have seen publication, because agony aunts (the writers of advice columns) must selectively filter what gets published. Nevertheless, the concerns of the day seem to be represented, such as the HIV/AIDS crisis in the 1980s. Additionally, we believe that the large sample of questions in our corpus (20,000+) that have appeared over recent decades gives a sufficient directional sense of broad trends.\n\n\nWriters of the questions are predominately female. The 2/3 proportion was estimated in 1987, so it would be useful to understand shifts in demographics over time.\nWhat questions were chosen to be answered on the column? Likely a small fraction of what got submitted. What themes tended to get cut out?"
  },
  {
    "objectID": "solutions/02_foundations_univariate.html#exercise-1-get-curious",
    "href": "solutions/02_foundations_univariate.html#exercise-1-get-curious",
    "title": "Solutions for Univariate visualization and summaries",
    "section": "",
    "text": "Results of brainstorming themes will vary\nFrom the “Data and Method” section at the end of the Pudding article, we see this paragraph:\n\n\nThe writers of these questions likely skew roughly 2/3 female (according to Pauline Phillips, who mentions the demographics of responses to a survey she disseminated in 1987), and consequently, their interests are overrepresented; we’ve been unable to find other demographic data surrounding their origins. There is, doubtless, a level of editorializing here: only a fraction of the questions that people have written in have seen publication, because agony aunts (the writers of advice columns) must selectively filter what gets published. Nevertheless, the concerns of the day seem to be represented, such as the HIV/AIDS crisis in the 1980s. Additionally, we believe that the large sample of questions in our corpus (20,000+) that have appeared over recent decades gives a sufficient directional sense of broad trends.\n\n\nWriters of the questions are predominately female. The 2/3 proportion was estimated in 1987, so it would be useful to understand shifts in demographics over time.\nWhat questions were chosen to be answered on the column? Likely a small fraction of what got submitted. What themes tended to get cut out?"
  },
  {
    "objectID": "solutions/02_foundations_univariate.html#exercise-2-importing-and-getting-to-know-the-data",
    "href": "solutions/02_foundations_univariate.html#exercise-2-importing-and-getting-to-know-the-data",
    "title": "Solutions for Univariate visualization and summaries",
    "section": "Exercise 2: Importing and getting to know the data",
    "text": "Exercise 2: Importing and getting to know the data\n\n# Load package\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(readr)\n\n# Read in the course evaluation data\nabby &lt;- read_csv(\"https://mac-stat.github.io/data/dear_abby.csv\")\n\nRows: 20034 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): day, url, title, question_only\ndbl (7): year, month, letterId, afinn_overall, afinn_pos, afinn_neg, bing_pos\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nNote how clicking the abby data causes both a popup pane and the command View(abby) to appear in the Console. In fact, the View() function is the underlying command that opens a dataset pane. (View() should always be entered in the Console and NOT your Quarto document.)\nEach row / case corresponds to a single question.\nColumns = variables\nTry out each function below. Identify what each function tells you about the abby data and note this in the ???:\n\n\n# First number = number of rows / cases\n# Second number = number of columns / variables\ndim(abby)\n\n[1] 20034    11\n\n# Number of rows (cases)\nnrow(abby)\n\n[1] 20034\n\n# Number of columns (variables)\nncol(abby)\n\n[1] 11\n\n# View first few rows of the dataset (6 rows, by default)\nhead(abby)\n\n# A tibble: 6 × 11\n   year month day   url     title letterId question_only afinn_overall afinn_pos\n  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;                 &lt;dbl&gt;     &lt;dbl&gt;\n1  1985     1 01    proque… WOMA…        1 \"i have been…           -30         5\n2  1985     1 01    proque… WOMA…        1 \"this is for…           -30         5\n3  1985     1 02    proque… LAME…        1 \"our 16-year…             1         3\n4  1985     1 03    proque… 'NOR…        1 \"i was a hap…            -3         7\n5  1985     1 04    proque… IT'S…        1 \"you be the …            13        31\n6  1985     1 04    proque… IT'S…        1 \"a further w…            13        31\n# ℹ 2 more variables: afinn_neg &lt;dbl&gt;, bing_pos &lt;dbl&gt;\n\n# Get all column (variable) names\nnames(abby)\n\n [1] \"year\"          \"month\"         \"day\"           \"url\"          \n [5] \"title\"         \"letterId\"      \"question_only\" \"afinn_overall\"\n [9] \"afinn_pos\"     \"afinn_neg\"     \"bing_pos\"     \n\n\n\nWe can display the first 10 rows with head(abby, n = 10)."
  },
  {
    "objectID": "solutions/02_foundations_univariate.html#exercise-3-preparing-to-summarize-and-visualize-the-data",
    "href": "solutions/02_foundations_univariate.html#exercise-3-preparing-to-summarize-and-visualize-the-data",
    "title": "Solutions for Univariate visualization and summaries",
    "section": "Exercise 3: Preparing to summarize and visualize the data",
    "text": "Exercise 3: Preparing to summarize and visualize the data\n\nThe sentiment variables are afinn_overall, afinn_pos, afinn_neg, and bing_pos, and they are quantitative. The afinn variables don’t have units but we can still get a sense of the scale by remembering that each word gets a score between -5 and 5. The bing_pos variable doesn’t have units because it’s a fraction, but we know that it ranges from 0 to 1.\ntheme would be categorical.\nAppropriate visualizations:\n\nsingle quantitative variable: boxplot, histogram, density plot\nsingle categorical variable: barplot"
  },
  {
    "objectID": "solutions/02_foundations_univariate.html#exercise-4-exploring-themes-in-the-letters",
    "href": "solutions/02_foundations_univariate.html#exercise-4-exploring-themes-in-the-letters",
    "title": "Solutions for Univariate visualization and summaries",
    "section": "Exercise 4: Exploring themes in the letters",
    "text": "Exercise 4: Exploring themes in the letters\n\nlibrary(dplyr)\nlibrary(stringr)\n\nabby &lt;- abby %&gt;% \n    mutate(\n        moms = ifelse(str_detect(question_only, \"mother|mama|mom\"), \"mom\", \"no mom\"),\n        dads = ifelse(str_detect(question_only, \"father|papa|dad\"), \"dad\", \"no dad\"),\n        marriage = ifelse(str_detect(question_only, \"marriage|marry|married\"), \"marriage\", \"no marriage\"),\n        money = ifelse(str_detect(question_only, \"money|finance\"), \"money\", \"no money\"),\n        themes = str_c(moms, dads, marriage, money, sep = \"|\")\n    )\n\n\nCode will vary\nExpectations about the plot will vary\n\n\nggplot(abby, aes(x = themes)) +\n    geom_bar() +\n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\n\n\n\n\n\n\n\nCounts in the table below match the barplot\n\n\n# Construct a table of counts\nabby %&gt;% \n    count(themes)\n\n# A tibble: 16 × 2\n   themes                                 n\n   &lt;chr&gt;                              &lt;int&gt;\n 1 mom|dad|marriage|money                67\n 2 mom|dad|marriage|no money            567\n 3 mom|dad|no marriage|money            109\n 4 mom|dad|no marriage|no money         906\n 5 mom|no dad|marriage|money            121\n 6 mom|no dad|marriage|no money         839\n 7 mom|no dad|no marriage|money         293\n 8 mom|no dad|no marriage|no money     2462\n 9 no mom|dad|marriage|money             41\n10 no mom|dad|marriage|no money         350\n11 no mom|dad|no marriage|money          96\n12 no mom|dad|no marriage|no money      760\n13 no mom|no dad|marriage|money         360\n14 no mom|no dad|marriage|no money     2967\n15 no mom|no dad|no marriage|money      865\n16 no mom|no dad|no marriage|no money  9231\n\n\n\nWhat do the plot layers do?\n\n\n# Just sets up the \"canvas\" of the plot with axis labels\nggplot(abby, aes(x = themes))\n\n\n\n\n\n\n\n\n\n# Adds the bars\nggplot(abby, aes(x = themes)) +\n    geom_bar()\n\n\n\n\n\n\n\n\n\n# Rotates the x axis labels\nggplot(abby, aes(x = themes)) +\n    geom_bar() +\n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\n\n\n\n\n\n\n\n# Changes the visual theme of the plot with a white background and removes gridlines\nggplot(abby, aes(x = themes)) +\n    geom_bar() +\n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +\n    theme_classic()"
  },
  {
    "objectID": "solutions/02_foundations_univariate.html#exercise-5-exploring-course-overall-ratings",
    "href": "solutions/02_foundations_univariate.html#exercise-5-exploring-course-overall-ratings",
    "title": "Solutions for Univariate visualization and summaries",
    "section": "Exercise 5: Exploring course overall ratings",
    "text": "Exercise 5: Exploring course overall ratings\nNow we’ll look at the distribution of the avg_rating variable and associated summary statistics.\n\n\nWe might expect the mean of this variable is less than zero given that more negative words might be appear in questions on an advice column.\nThe code has a similar structure to the barplot in that there is an initial ggplot() layer which sets the canvas, then a + to add a layer, then the final layer geom_boxplot() (like geom_bar()) which tells R what type of plot to make.\n\n\n\nggplot(abby, aes(x = afinn_overall)) +\n    geom_boxplot()\n\nWarning: Removed 490 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\n\nWe replace geom_boxplot() with geom_histogram() and geom_density().\n\nThe tallest bar of the histogram indicates that over 7500 questions had an overall afinn sentiment score between around -8 to 0.(The -8 to 0 comes from eyeballing where the tallest bar is placed on the x-axis, and the height of this bar indicates how many cases fall into that bin.)\nThe shape of the distribution: roughly symmetric\n\n\n\n# Histogram\nggplot(abby, aes(x = afinn_overall)) +\n    geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 490 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\n# Density plot\nggplot(abby, aes(x = afinn_overall)) +\n    geom_density()\n\nWarning: Removed 490 rows containing non-finite outside the scale range\n(`stat_density()`).\n\n\n\n\n\n\n\n\n\n\n\nBoxplot shows min, max, median, 1st and 3rd quartile easily. (It shows median, 1st and 3rd quartile directly as lines)\nHistogram and density plot show min and max but the mean and median aren’t shown directly–we have to roughly guess based on the peak of the distribution\n\n\n\n# Summary statistics\nsummary(abby$afinn_overall)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max.     NA's \n-140.000   -6.000   -1.000   -1.401    3.000  100.000      490 \n\nabby %&gt;% \n    summarize(mean(afinn_overall, na.rm = TRUE), median(afinn_overall, na.rm = TRUE), sd(afinn_overall, na.rm = TRUE))\n\n# A tibble: 1 × 3\n  mean(afinn_overall, na.rm = TR…¹ median(afinn_overall…² sd(afinn_overall, na…³\n                             &lt;dbl&gt;                  &lt;dbl&gt;                  &lt;dbl&gt;\n1                            -1.40                     -1                   11.1\n# ℹ abbreviated names: ¹​`mean(afinn_overall, na.rm = TRUE)`,\n#   ²​`median(afinn_overall, na.rm = TRUE)`, ³​`sd(afinn_overall, na.rm = TRUE)`\n\n\n\nThe distribution of sentiment scores is roughly symmetric with a mean of -1.4 and a similar median of -1. The median and mean are quite similar because the distribution is fairly symmetric. The standard deviation of the sentiment scores is about 11.08 which tells us how much variation there is from the center of the distribution. 11.08 is somewhat high given the IQR of -6 to 3 (which is a span of 9 units)."
  },
  {
    "objectID": "solutions/02_foundations_univariate.html#exercise-6-box-plots-vs.-histograms-vs.-density-plots",
    "href": "solutions/02_foundations_univariate.html#exercise-6-box-plots-vs.-histograms-vs.-density-plots",
    "title": "Solutions for Univariate visualization and summaries",
    "section": "Exercise 6: Box plots vs. histograms vs. density plots",
    "text": "Exercise 6: Box plots vs. histograms vs. density plots\n\nBoxplots very clearly show key summary statistics like median, 1st and 3rd quartile\nBoxplots can oversimplify by not showing the shape of the distribution."
  },
  {
    "objectID": "solutions/02_foundations_univariate.html#exercise-7-explore-outliers",
    "href": "solutions/02_foundations_univariate.html#exercise-7-explore-outliers",
    "title": "Solutions for Univariate visualization and summaries",
    "section": "Exercise 7: Explore outliers",
    "text": "Exercise 7: Explore outliers\nThere are some positive words in the questions that seem to pull up the sentiment score a lot despite the negative overall tone. From this we can see the limitations of a basic sentiment analysis in which the sentiment of each word is considered in isolation.\n\nabby %&gt;% \n    filter(afinn_overall &gt; 50) %&gt;% \n    pull(question_only) %&gt;% \n    head() # Just to look at first 6\n\n[1] \"i am a 36-year-old college dropout whose lifelong ambition was to be a physician. i have a very good job selling pharmaceutical supplies, but my heart is still in the practice of medicine. i do volunteer work at the local hospital on my time off, and people tell me i would have made a wonderful doctor.\\nif i go back to college and get my degree, then go to medical school, do my internship and finally get into the actual practice of medicine, it will take me seven years! but, abby, in seven years i will be 43 years old. what do you think?\\nunfulfilled in philly\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n[2] \"we have an only child--a grown daughter we dearly love--and when we pass on, we want to leave her our entire estate, which is considerable.\\nthe thing that troubles us is this: our daughter is married to a very unworthy character. for years he has taken advantage of her sweet, forgiving, generous nature because he knows she worships him. we are sure that whatever we leave our daughter will be spent on this dirty dog.\\nhow can we prevent this from happening?\\nbewildered\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n[3] \"both of our sons have been married for about 15 years. their wives were of normal weight when they married our sons, but one daughter-in- law weighs about 300 pounds and the other weighs about 225. their ages are 35 and 37. both our sons are good-looking, and neither is fat.\\nour daughters-in-law seem to have no pride in their appearance, which upsets everyone in the family, except themselves. they are fat, they know it and they don't care! when they first began to put on weight, they tried various diets, pills, doctors, etc., but they both gave up and decided to \\\"accept\\\" themselves as they are.\\nthey wear the wrong kind of clothes (shorts and blue jeans) without any apologies.\\nour problem (my husband's and mine) is how do we cope with this? we are ashamed to be around them. our sons have accepted the situation, but we seem unable to.\\nperhaps we need more help than the girls. any suggestions?\\nupset in florida\"                                                                                                                                                                                                                                                                                                                                                                                                                                           \n[4] \"the letter from \\\"concerned mom,\\\" who was trying to teach her 5-year-old not to accept gifts from strangers, prompts this letter.\\na gentleman friend of mine recently stood in line behind a mother and her young daughter at a bank. the child remarked on the visor he was wearing, as it had the name of a popular pizza imprinted on it.\\nmy friend, who is the public relations director for this pizza firm, wanted the child to have the visor but, instead of giving it to the child, he handed the visor to her mother and said to the child: \\\"i'm giving this to your mother to give to you, because she's probably told you never to accept gifts from a stranger. you won't ever do that, will you?\\\"\\nwhat a thoughtful way to be friendly while reinforcing a message mothers cannot stress enough.\\nsue in wichita, kan.\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n[5] \"in january, i sent an original manuscript as a gift to woody allen. i had hand-bound the pages, and decorated the binding with baroque pearls and amethyst. i enclosed my name, address and telephone number. i had hoped that woody would send me a note or call me, or at the very least, instruct his secretary to do so.\\nto date, i haven't received even an acknowledgment that my gift was received. is it unrealistic of me to expect a thank-you from a famous person?\\ndisappointed in california.\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n[6] \"will you please, please discourage high school and college graduates from sending graduation invitations to every distant relative they and their parents ever heard of? we all know that sending \\\"invitations\\\" to people we hardly know is a flagrant, shameless bid for a gift. and if, in a moment of weakness, one does send a gift, a barrage of birth announcements and invitations to weddings, showers and more graduations is sure to follow.\\ni am a 75-year-old widow, living on social security and very little else. i just received a high school graduation invitation from the granddaughter of a third cousin whom i have not seen in so long i wouldn't even recognize her. (i have never even met her granddaughter.)\\ni have many relatives in this town, but i never hear from them unless they are celebrating something that requires a gift. i have no car, yet they \\\"invite\\\" me to every imaginable event, knowing full well i can't possibly attend. this is just shameless begging.\\ni am not cheap. i just sent a generous graduation gift to a neighbor girl who used to stop by every day to bring in my mail and newspaper and ask if i needed any errands run.\\ndon't suggest that i send \\\"a nice card\\\" to the relatives who send me invitations to events they know i can't attend. we both know a card is not what these spongers want.\\nsick of them in iowa city\""
  },
  {
    "objectID": "solutions/02_foundations_univariate.html#exercise-8-returning-to-our-context-looking-ahead",
    "href": "solutions/02_foundations_univariate.html#exercise-8-returning-to-our-context-looking-ahead",
    "title": "Solutions for Univariate visualization and summaries",
    "section": "Exercise 8: Returning to our context, looking ahead",
    "text": "Exercise 8: Returning to our context, looking ahead\n\nAnswers will vary"
  },
  {
    "objectID": "solutions/02_foundations_univariate.html#exercise-11-read-in-and-get-to-know-the-weather-data",
    "href": "solutions/02_foundations_univariate.html#exercise-11-read-in-and-get-to-know-the-weather-data",
    "title": "Solutions for Univariate visualization and summaries",
    "section": "Exercise 11: Read in and get to know the weather data",
    "text": "Exercise 11: Read in and get to know the weather data\n\nweather &lt;- read_csv(\"https://raw.githubusercontent.com/Mac-STAT/data/main/weather_3_locations.csv\")\n\nRows: 2367 Columns: 24\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (6): location, windgustdir, winddir9am, winddir3pm, raintoday, raintom...\ndbl  (17): mintemp, maxtemp, rainfall, evaporation, sunshine, windgustspeed,...\ndate  (1): date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "solutions/02_foundations_univariate.html#exercise-12-exploring-the-data-structure",
    "href": "solutions/02_foundations_univariate.html#exercise-12-exploring-the-data-structure",
    "title": "Solutions for Univariate visualization and summaries",
    "section": "Exercise 12: Exploring the data structure",
    "text": "Exercise 12: Exploring the data structure\nCheck out the basic features of the weather data.\n\n# Examine the first six cases\nhead(weather)\n\n# A tibble: 6 × 24\n  date       location  mintemp maxtemp rainfall evaporation sunshine windgustdir\n  &lt;date&gt;     &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;      \n1 2020-01-01 Wollongo…    17.1    23.1        0          NA       NA SSW        \n2 2020-01-02 Wollongo…    17.7    24.2        0          NA       NA SSW        \n3 2020-01-03 Wollongo…    19.7    26.8        0          NA       NA NE         \n4 2020-01-04 Wollongo…    20.4    35.5        0          NA       NA SSW        \n5 2020-01-05 Wollongo…    19.8    21.4        0          NA       NA SSW        \n6 2020-01-06 Wollongo…    18.3    22.9        0          NA       NA NE         \n# ℹ 16 more variables: windgustspeed &lt;dbl&gt;, winddir9am &lt;chr&gt;, winddir3pm &lt;chr&gt;,\n#   windspeed9am &lt;dbl&gt;, windspeed3pm &lt;dbl&gt;, humidity9am &lt;dbl&gt;,\n#   humidity3pm &lt;dbl&gt;, pressure9am &lt;dbl&gt;, pressure3pm &lt;dbl&gt;, cloud9am &lt;dbl&gt;,\n#   cloud3pm &lt;dbl&gt;, temp9am &lt;dbl&gt;, temp3pm &lt;dbl&gt;, raintoday &lt;chr&gt;,\n#   risk_mm &lt;dbl&gt;, raintomorrow &lt;chr&gt;\n\n# Find the dimensions of the data\ndim(weather)\n\n[1] 2367   24\n\n\nA case represents a day of the year in a particular area (Hobart, Uluru, Wollongong as seen by the location variable)."
  },
  {
    "objectID": "solutions/02_foundations_univariate.html#exercise-13-exploring-rainfall",
    "href": "solutions/02_foundations_univariate.html#exercise-13-exploring-rainfall",
    "title": "Solutions for Univariate visualization and summaries",
    "section": "Exercise 13: Exploring rainfall",
    "text": "Exercise 13: Exploring rainfall\nThe raintoday variable contains information about rainfall.\n\nraintoday is categorical (No, Yes)\nIt is more common to have no rain.\n\n\n# Visualization\nggplot(weather, aes(x = raintoday)) +\n    geom_bar()\n\n\n\n\n\n\n\n# Numerical summaries\nweather %&gt;% \n    count(raintoday)\n\n# A tibble: 3 × 2\n  raintoday     n\n  &lt;chr&gt;     &lt;int&gt;\n1 No         1864\n2 Yes         446\n3 &lt;NA&gt;         57"
  },
  {
    "objectID": "solutions/02_foundations_univariate.html#exercise-14-exploring-temperature",
    "href": "solutions/02_foundations_univariate.html#exercise-14-exploring-temperature",
    "title": "Solutions for Univariate visualization and summaries",
    "section": "Exercise 14: Exploring temperature",
    "text": "Exercise 14: Exploring temperature\nThe maxtemp variable contains information on the daily high temperature.\n\nmaxtemp is quantitative\nThe typical max temperature is around 23 degrees Celsius (with an average of 23.62 and a median of 22 degrees). The max temperatures ranged from 8.6 to 45.4 degrees. Finally, on the typical day, the max temp falls about 7.8 degrees from the mean. There are multiple modes in the distribution of max temperature—this likely reflects the different cities in the dataset.\n\n\n# Visualization\nggplot(weather, aes(x = maxtemp)) + \n    geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 34 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\n# Numerical summaries\nsummary(weather$maxtemp)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   8.60   18.10   22.00   23.62   27.40   45.40      34 \n\n# There are missing values (NAs) in this variable, so we add\n# the na.rm = TRUE argument\nweather %&gt;% \n    summarize(sd(maxtemp, na.rm = TRUE))\n\n# A tibble: 1 × 1\n  `sd(maxtemp, na.rm = TRUE)`\n                        &lt;dbl&gt;\n1                        7.80"
  },
  {
    "objectID": "solutions/02_foundations_univariate.html#exercise-15-customizing-challenge",
    "href": "solutions/02_foundations_univariate.html#exercise-15-customizing-challenge",
    "title": "Solutions for Univariate visualization and summaries",
    "section": "Exercise 15: Customizing! (CHALLENGE)",
    "text": "Exercise 15: Customizing! (CHALLENGE)\n\n\n\n\nggplot(weather, aes(x = maxtemp)) + \n    geom_histogram() + \n    labs(x = \"Maximum temperature\", y = \"Number of days\", title = \"Distribution of max temperatures in Perth\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 34 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Make the bars green\nggplot(weather, aes(x = raintoday)) + \n    geom_bar(fill = \"green\")"
  },
  {
    "objectID": "solutions/03_slr_introduction.html",
    "href": "solutions/03_slr_introduction.html",
    "title": "Solutions for simple linear regression: Visualization and Introduction",
    "section": "",
    "text": "Use an appropriate function to look at the first few rows of the data.\n\n\nhead(lifts)\n\n# A tibble: 6 × 21\n  Name        Sex   Event Equipment   Age BodyweightKg Best3SquatKg Best3BenchKg\n  &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n1 Natalya Po… F     D     Raw        37           58.4          NA          NA  \n2 Fatima Rod… F     SBD   Single-p…  NA           74.8          NA          NA  \n3 Josh Kelley M     SBD   Single-p…  NA           72.4         147.         97.5\n4 Timothy Ca… M     D     Raw        16           72.9          NA          NA  \n5 M Moynihan  M     B     Raw        NA           67.5          NA         100  \n6 Lucas Wegr… M     B     Raw        23.5        103.           NA         188. \n# ℹ 13 more variables: Best3DeadliftKg &lt;dbl&gt;, TotalKg &lt;dbl&gt;, Place &lt;chr&gt;,\n#   Dots &lt;dbl&gt;, Wilks &lt;dbl&gt;, Glossbrenner &lt;dbl&gt;, Goodlift &lt;dbl&gt;, Tested &lt;chr&gt;,\n#   Country &lt;chr&gt;, State &lt;chr&gt;, Date &lt;date&gt;, MeetCountry &lt;chr&gt;, MeetState &lt;chr&gt;\n\n\n\nCreate a new code chunk, and use an appropriate function to learn how much data we have (in terms of cases and variables).\n\n\ndim(lifts)\n\n[1] 100000     21\n\n\n\nA case represents an individual lifter at a single weightlifting competition.\nIt looks like some meets may be missing if they weren’t detected by the web scraper used by the maintainers of the Open Powerlifting database. They don’t describe in detail the process used for transferring PDFs of results to their database, so it’s unclear what errors in transcription might have resulted. Still, it’s worth taking a moment to appreciate the labor they put into making these results available for passionate powerlifters to explore."
  },
  {
    "objectID": "solutions/03_slr_introduction.html#exercise-1-get-to-know-the-data",
    "href": "solutions/03_slr_introduction.html#exercise-1-get-to-know-the-data",
    "title": "Solutions for simple linear regression: Visualization and Introduction",
    "section": "",
    "text": "Use an appropriate function to look at the first few rows of the data.\n\n\nhead(lifts)\n\n# A tibble: 6 × 21\n  Name        Sex   Event Equipment   Age BodyweightKg Best3SquatKg Best3BenchKg\n  &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n1 Natalya Po… F     D     Raw        37           58.4          NA          NA  \n2 Fatima Rod… F     SBD   Single-p…  NA           74.8          NA          NA  \n3 Josh Kelley M     SBD   Single-p…  NA           72.4         147.         97.5\n4 Timothy Ca… M     D     Raw        16           72.9          NA          NA  \n5 M Moynihan  M     B     Raw        NA           67.5          NA         100  \n6 Lucas Wegr… M     B     Raw        23.5        103.           NA         188. \n# ℹ 13 more variables: Best3DeadliftKg &lt;dbl&gt;, TotalKg &lt;dbl&gt;, Place &lt;chr&gt;,\n#   Dots &lt;dbl&gt;, Wilks &lt;dbl&gt;, Glossbrenner &lt;dbl&gt;, Goodlift &lt;dbl&gt;, Tested &lt;chr&gt;,\n#   Country &lt;chr&gt;, State &lt;chr&gt;, Date &lt;date&gt;, MeetCountry &lt;chr&gt;, MeetState &lt;chr&gt;\n\n\n\nCreate a new code chunk, and use an appropriate function to learn how much data we have (in terms of cases and variables).\n\n\ndim(lifts)\n\n[1] 100000     21\n\n\n\nA case represents an individual lifter at a single weightlifting competition.\nIt looks like some meets may be missing if they weren’t detected by the web scraper used by the maintainers of the Open Powerlifting database. They don’t describe in detail the process used for transferring PDFs of results to their database, so it’s unclear what errors in transcription might have resulted. Still, it’s worth taking a moment to appreciate the labor they put into making these results available for passionate powerlifters to explore."
  },
  {
    "objectID": "solutions/03_slr_introduction.html#exercise-2-mutating-our-data",
    "href": "solutions/03_slr_introduction.html#exercise-2-mutating-our-data",
    "title": "Solutions for simple linear regression: Visualization and Introduction",
    "section": "Exercise 2: Mutating our data",
    "text": "Exercise 2: Mutating our data\nStrength-to-weight ratio (SWR) is defined as TotalKg/BodyweightKg. We can use the mutate() function from the dplyr package to create a new variable in our dataframe for SWR using the following code:\n\nlifts &lt;- lifts %&gt;% \n    mutate(SWR = TotalKg / BodyweightKg)\n\nAdapt the example above to create a new variable called SWR, where SWR is defined as TotalKg/BodyweightKg."
  },
  {
    "objectID": "solutions/03_slr_introduction.html#exercise-3-get-to-know-the-outcomeresponse-variable",
    "href": "solutions/03_slr_introduction.html#exercise-3-get-to-know-the-outcomeresponse-variable",
    "title": "Solutions for simple linear regression: Visualization and Introduction",
    "section": "Exercise 3: Get to know the outcome/response variable",
    "text": "Exercise 3: Get to know the outcome/response variable\nLet’s get acquainted with the SWR variable.\n\nConstruct an appropriate plot to visualize the distribution of this variable, and compute appropriate numerical summaries.\n\n\nlifts %&gt;%\n  ggplot(aes(SWR)) +\n  geom_histogram(bins = 10, col = \"black\")\n\nWarning: Removed 8752 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\nlifts %&gt;% summarize(mean(SWR), min(SWR), max(SWR))\n\n# A tibble: 1 × 3\n  `mean(SWR)` `min(SWR)` `max(SWR)`\n        &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1          NA         NA         NA\n\n\n\nWrite a good paragraph interpreting the plot and numerical summaries.\n\nStrength-to-weight (SWR) ratio ranges from 0.3 to 13.2, with a mean SWR of 4.8. We observe that most SWRs appear to be centered between 4 and 7, with a slight right-skew to the data. The distribution of SWRs appears to be unimodal."
  },
  {
    "objectID": "solutions/03_slr_introduction.html#exercise-4-data-visualization---two-quantitative-variables",
    "href": "solutions/03_slr_introduction.html#exercise-4-data-visualization---two-quantitative-variables",
    "title": "Solutions for simple linear regression: Visualization and Introduction",
    "section": "Exercise 4: Data visualization - two quantitative variables",
    "text": "Exercise 4: Data visualization - two quantitative variables\nWe’d like to visualize the relationship between body weight and the strength-to-weight ratio. A scatterplot (or informally, a “point cloud”) allows us to do this! The code below creates a scatterplot of body weight vs. SWR using ggplot().\n\n# scatterplot\n\n# The alpha = 0.5 in geom_point() adds transparency to the points\n# to make them easier to see. You can make this smaller for more transparency\nlifts %&gt;%\n  ggplot(aes(x = BodyweightKg, y = SWR)) +\n  geom_point(alpha = 0.5)\n\nWarning: Removed 8752 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\na & b. In our plot aesthetics, we now have two variables listed (an “x” and a “y”) as opposed to just a single variable. The “geom” for a scatterplot is geom_point. Otherwise, the code structure remains very similar!\n\nIn general, it seems as though higher body weights are associated with lower SWRs. Once body weight (in kg) is greater than 50, the relationship between body weight and SWR appears to be weakly negative, and roughly linear. The points are very dispersed, indicating that there is a good amount of variation in this relationship (hence the term “weak”)."
  },
  {
    "objectID": "solutions/03_slr_introduction.html#exercise-5-scatterplots---patterns-in-point-clouds",
    "href": "solutions/03_slr_introduction.html#exercise-5-scatterplots---patterns-in-point-clouds",
    "title": "Solutions for simple linear regression: Visualization and Introduction",
    "section": "Exercise 5: Scatterplots - patterns in point clouds",
    "text": "Exercise 5: Scatterplots - patterns in point clouds\nSometimes, it can be easier to see a pattern in a point cloud by adding a smoothing line to our scatterplots. The code below adapts the code in Exercise 4 to do this:\n\n# scatterplot with smoothing line\nlifts %&gt;%\n  ggplot(aes(x = BodyweightKg, y = SWR)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\nWarning: Removed 8752 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 8752 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\nThis doesn’t change my answer much (but it may have changed yours, and that’s okay!). It does appear as though there is a weakly negative relationship between body weight and SWR, particularly once body weight is above a certain value.\nI would say that yes, a linear relationship here seems reasonable! Even though there is some curvature in the smoothed trend line early on, that is based on very few data points. Those data points with low body weights aren’t enough to convince me that the relationship couldn’t be roughly linear between body weight and SWR."
  },
  {
    "objectID": "solutions/03_slr_introduction.html#exercise-6-correlation",
    "href": "solutions/03_slr_introduction.html#exercise-6-correlation",
    "title": "Solutions for simple linear regression: Visualization and Introduction",
    "section": "Exercise 6: Correlation",
    "text": "Exercise 6: Correlation\n\nI would describe the correlation between body weight and SWR as weak and negative.\nI’ll guess -0.1, since the line is negative, and the points are very dispersed around the line!"
  },
  {
    "objectID": "solutions/03_slr_introduction.html#exercise-7-computing-correlation-in-r",
    "href": "solutions/03_slr_introduction.html#exercise-7-computing-correlation-in-r",
    "title": "Solutions for simple linear regression: Visualization and Introduction",
    "section": "Exercise 7: Computing correlation in R",
    "text": "Exercise 7: Computing correlation in R\n\n# correlation\n\n# Note: the order in which you put your two quantitative variables into the cor\n# function doesn't matter! Try switching them around to cpmfor, this for yourself\nlifts %&gt;%\n  summarize(cor(SWR, BodyweightKg))\n\n# A tibble: 1 × 1\n  `cor(SWR, BodyweightKg)`\n                     &lt;dbl&gt;\n1                       NA\n\n\nSo close to our guess!"
  },
  {
    "objectID": "solutions/03_slr_introduction.html#exercise-8-limitations-of-correlation",
    "href": "solutions/03_slr_introduction.html#exercise-8-limitations-of-correlation",
    "title": "Solutions for simple linear regression: Visualization and Introduction",
    "section": "Exercise 8: Limitations of correlation",
    "text": "Exercise 8: Limitations of correlation\n\n# correlation between x1, y1\nanscombe %&gt;% summarize(cor(x1, y1))\n\n  cor(x1, y1)\n1   0.8164205\n\n# correlation between x2, y2\nanscombe %&gt;% summarize(cor(x2, y2))\n\n  cor(x2, y2)\n1   0.8162365\n\n# correlation between x3, y3\nanscombe %&gt;% summarize(cor(x3, y3))\n\n  cor(x3, y3)\n1   0.8162867\n\n# correlation between x4, y4\nanscombe %&gt;% summarize(cor(x4, y4))\n\n  cor(x4, y4)\n1   0.8165214\n\n\n\nEach of these correlations are nearly the same!\nEach of these correlations is relatively strong, and positive, since 0.8 is positive and closer to 1 than 0.\n\n\n\n# scatterplot: x1, y1\nanscombe %&gt;%\n  ggplot(aes(x = x1, y = y1)) +\n  geom_point()\n\n\n\n\n\n\n\n# scatterplot: x2, y2\nanscombe %&gt;%\n  ggplot(aes(x = x2, y = y2)) +\n  geom_point()\n\n\n\n\n\n\n\n# scatterplot: x3, y3\nanscombe %&gt;%\n  ggplot(aes(x = x3, y = y3)) +\n  geom_point()\n\n\n\n\n\n\n\n# scatterplot: x4, y4\nanscombe %&gt;%\n  ggplot(aes(x = x4, y = y4)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nThe message of this exercise is that data visualization is important in addition to numerical summaries! Many different sets of points can have nearly the same correlation, but display very different patterns in point clouds upon closer inspection. Reporting correlation alone is not enough to summarize the relationship between two quantitative variables, and should be accompanied by a scatter plot!"
  },
  {
    "objectID": "solutions/03_slr_introduction.html#exercise-9-correlation-and-extreme-values",
    "href": "solutions/03_slr_introduction.html#exercise-9-correlation-and-extreme-values",
    "title": "Solutions for simple linear regression: Visualization and Introduction",
    "section": "Exercise 9: Correlation and extreme values",
    "text": "Exercise 9: Correlation and extreme values\n\n# create a toy dataset\nset.seed(1234)\nx &lt;- rnorm(100, mean = 5, sd = 2)\ny &lt;- -3 * x + rnorm(100, sd = 4)\ndat &lt;- data.frame(x = x, y = y)\n\n\n\n\n\n# scatterplot\ndat %&gt;% \n  ggplot(aes(x = x, y = y)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nThe correlation between x and y is moderately strong and negative.\nI’ll guess -0.6, since the relationship is negative and is sort of in-between weak and strong.\n\n\n\n# correlation\ndat %&gt;% summarize(cor(x, y))\n\n   cor(x, y)\n1 -0.8295483\n\n\n\n\n\n\n# creating dat_new1\nx1 &lt;- c(x, 15)\ny1 &lt;- c(y, -45)\ndat_new1 &lt;- data.frame(x = x1, y = y1)\n\n\n\n\n\n# scatterplot\ndat_new1 %&gt;%\n  ggplot(aes(x1, y1)) +\n  geom_point()\n\n\n\n\n\n\n\n# correlation\ndat %&gt;% summarize(cor(x1, y1))\n\n  cor(x1, y1)\n1  -0.8573567\n\n\nOur correlation stayed roughly the same with the addition of this new point!\n\n\n\n\n# creating dat_new1\nx2 &lt;- c(x, 15)\ny2 &lt;- c(y, 45)\ndat_new2 &lt;- data.frame(x = x2, y = y2)\n\n\n\n\n\n# scatterplot\ndat_new2 %&gt;%\n  ggplot(aes(x2, y2)) +\n  geom_point()\n\n\n\n\n\n\n\n# correlation\ndat_new2 %&gt;% summarize(cor(x2, y2))\n\n  cor(x2, y2)\n1  -0.2924792\n\n\nThe correlation changes quite a bit with the addition of this new point! Something to note is that this new point does not follow the rough linear trend that the original points had, that the first point we considered adding also had. This line seems way off base, comparatively!\n\nThe takeaway message here is that even though both of these additional points might be considered “outliers” because they have extreme x values, one changes the relationship between x and y much more than the other. In this case, the second point we considered would be influential because it changes the observed relationship between all x’s and y’s much more than the first point we considered. Not all “outliers” are considered equal!\n\n\n\n\n\ndat_new1 %&gt;%\n  ggplot(aes(x1, y1)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\ndat_new2 %&gt;%\n  ggplot(aes(x2, y2)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "solutions/06_slr_transformations.html",
    "href": "solutions/06_slr_transformations.html",
    "title": "Solutions for Simple linear regression: Transformations",
    "section": "",
    "text": "# Load packages and import data\nlibrary(readr)\nlibrary(ggplot2)\nlibrary(dplyr)\n\nhomes &lt;- read_csv(\"https://mac-stat.github.io/data/homes.csv\")\n\nbigmac &lt;- read_csv(\"https://mac-stat.github.io/data/bigmac.csv\")\n\ncollege &lt;- read_csv(\"https://mac-stat.github.io/data/college.csv\")"
  },
  {
    "objectID": "solutions/06_slr_transformations.html#exercise-1-location-transformations",
    "href": "solutions/06_slr_transformations.html#exercise-1-location-transformations",
    "title": "Solutions for Simple linear regression: Transformations",
    "section": "Exercise 1: Location transformations",
    "text": "Exercise 1: Location transformations\nLocation transformations are ones that shift a predictor variable up or down by a fixed amount. Using a location transformation is sometimes also called centering a predictor.\nWe’ll use the homes data in this exercise.\n\nFit a linear regression model of Price as a function of Living.Area, and call this model home_mod.\n\n\n# Fit the model\nhome_mod &lt;- lm(Price ~ Living.Area, data = homes)\n\n# Display model summary output\ncoef(summary(home_mod))\n\n              Estimate  Std. Error   t value      Pr(&gt;|t|)\n(Intercept) 13439.3940 4992.352849  2.691996  7.171207e-03\nLiving.Area   113.1225    2.682341 42.173065 9.486240e-268\n\n\n\n\nInterpretation of slope: Every 1 square foot increase in living area is associated with an expected / average increase in house price of $113.12.\nInterpretation of intercept: The average/expected house price for a house with zero square feet is $13,439.39. Can a house ever be zero square feet??? Nope! The intercept is meaningless in this case.\n\n\n\n\nhomes %&gt;% \n    summarize(min(Living.Area))\n\n# A tibble: 1 × 1\n  `min(Living.Area)`\n               &lt;dbl&gt;\n1                616\n\n# mutate() creates a new variable called Living.Area.Shifted that is equal to Living.Area - 600\nhomes &lt;- homes %&gt;%\n    mutate(Living.Area.Shifted = Living.Area-600)\n\n\n\nIn general terms, the intercept in this model should represent the average house price when Living.Area.Shifted is 0—in other words when Living.Area is 600 square feet. From the coefficient estimates in home_mod, we can calculate the expected / predicted house price for 600 square foot homes: 13439.394 + (113.123*600) = 81312.89. So we’re expecting the new intercept to be $81312.89.\nThe slope in this model represents the average price change for each unit change in Living.Area.Shifted (which is the same as a unit change in Living.Area). Based on this, the slope should be the same as in home_mod ($113.12 per square foot).\n\nLines up with work in part d!\n\n\n# Fit a model of Price vs. Living.Area.Shifted\nhome_mod_centered &lt;- lm(Price ~ Living.Area.Shifted, data = homes)\n\n# Display model summary output\ncoef(summary(home_mod_centered))\n\n                      Estimate  Std. Error  t value      Pr(&gt;|t|)\n(Intercept)         81312.9191 3515.879467 23.12733 2.638371e-103\nLiving.Area.Shifted   113.1225    2.682341 42.17307 9.486240e-268"
  },
  {
    "objectID": "solutions/06_slr_transformations.html#exercise-2-scale-transformations",
    "href": "solutions/06_slr_transformations.html#exercise-2-scale-transformations",
    "title": "Solutions for Simple linear regression: Transformations",
    "section": "Exercise 2: Scale transformations",
    "text": "Exercise 2: Scale transformations\nIn the code chunk below, construct a visualization comparing graduation rate (our outcome variable) and admissions rate (our predictor of interest). Remember that your outcome variable should be on the y-axis, in general!\n\n# Scatterplot of graduation rate vs. admissions rate\ncollege %&gt;%\n  ggplot(aes(x = AdmisRate, y = GradRate)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nThe correlation between admissions and graduation rates appears to be weakly negative. Notably, there are hard boundaries to admissions and graduation rates, since both must fall between 0 and 100%! A few colleges hit up against these boundaries. I would say that, with the exception of the observations that have either 0% graduation rates or 0% admission rates, the relationship does appear to be roughly linear.\nE[GradRate | AdmisRate] = \\(\\beta_0\\) + \\(\\beta_1\\) AdmisRate\n\n\n\n# Linear regression model with GradRate as the outcome, AdmisRate as predictor of interest\nmod &lt;- lm(GradRate ~ AdmisRate, data = college)\nsummary(mod)\n\n\nCall:\nlm(formula = GradRate ~ AdmisRate, data = college)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.68409 -0.13681  0.01296  0.15550  0.66204 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.68409    0.01759   38.89   &lt;2e-16 ***\nAdmisRate   -0.34613    0.02330  -14.85   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2088 on 1649 degrees of freedom\nMultiple R-squared:  0.118, Adjusted R-squared:  0.1175 \nF-statistic: 220.6 on 1 and 1649 DF,  p-value: &lt; 2.2e-16\n\n\n\nIntercept Estimate: 0.68409\n\n\nSlope Estimate: -0.34613\n\n\nOne unit of AdmisRate corresponds to a 100% change in admissions rates! The same goes for graduation rate. This is a huge change (in fact, the largest change possible).\nSuppose I want the interpretation of my slope coefficient for AdmisRate in my linear model to be in terms a “1% increase in admissions rate.” To achieve this, we could mutate our AdmisRate variable to range from 0 to 100. Let’s do that for GradRate too (just because!):\n\n\n# Mutate\ncollege &lt;- college %&gt;%\n  mutate(AdmisRate = AdmisRate * 100,\n         GradRate = GradRate * 100)\n\n\nFit a new linear regression model with the updated AdmisRate and GradRate variables as your predictor of interest and outcome, respectively. Again, report the intercept and slope estimate from your model.\n\n\n# Linear regression model with updated GradRate as the outcome, updated AdmisRate as predictor of interest\nmod_new &lt;- lm(GradRate ~ AdmisRate, data = college)\nsummary(mod_new)\n\n\nCall:\nlm(formula = GradRate ~ AdmisRate, data = college)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-68.409 -13.681   1.296  15.550  66.204 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  68.4088     1.7592   38.89   &lt;2e-16 ***\nAdmisRate    -0.3461     0.0233  -14.85   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 20.88 on 1649 degrees of freedom\nMultiple R-squared:  0.118, Adjusted R-squared:  0.1175 \nF-statistic: 220.6 on 1 and 1649 DF,  p-value: &lt; 2.2e-16\n\n\n\nIntercept Estimate: 68.4088\n\n\nSlope Estimate: -0.3461\n\nOur intercept estimate is now 100x larger, and our slope estimate has remained the same! The slope remained the same because we multiplied our outcome and our predictor of interest by the same value, and the intercept is 100x larger because we multiplied our outcome by 100 (recall that the intercept is the average expected outcome when “x” is zero).\n\nOn average, we expect colleges that differ in admissions rate by 1% to have 0.35% different graduation rates, with colleges with higher admissions rates having lower graduation rates."
  },
  {
    "objectID": "solutions/06_slr_transformations.html#exercise-3-log-transformations",
    "href": "solutions/06_slr_transformations.html#exercise-3-log-transformations",
    "title": "Solutions for Simple linear regression: Transformations",
    "section": "Exercise 3: Log transformations",
    "text": "Exercise 3: Log transformations\n\n\n\n\n# Visualization: Big Mac minutes vs. gross annual teacher income\nbigmac %&gt;%\n  ggplot(aes(x = gross_annual_teacher_income, y = bigmac_mins)) +\n  geom_point() \n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nAs annual teacher income gets higher, time it takes in minutes to earn a Big Mac decreases, though the relationship does not appear linear. The amount of time it takes to earn a Big Mac is very high when income is below about 10,000 where it sharply decreases, and then decreases at a much lower rate when income is above around 20,000.\n\nCorrelation is a summary of the linear relationship between two quantitative variables, and this relationship does not appear to be linear!\n\n\n\n# Linear regression code\nmod &lt;- lm(bigmac_mins ~ gross_annual_teacher_income, data = bigmac)\nsummary(mod)\n\n\nCall:\nlm(formula = bigmac_mins ~ gross_annual_teacher_income, data = bigmac)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-29.649  -9.556  -1.784   4.512  43.715 \n\nCoefficients:\n                              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                  5.801e+01  3.104e+00   18.69  &lt; 2e-16 ***\ngross_annual_teacher_income -9.092e-04  9.591e-05   -9.48 6.16e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 15.4 on 66 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.5766,    Adjusted R-squared:  0.5701 \nF-statistic: 89.86 on 1 and 66 DF,  p-value: 6.164e-14\n\n\nOn average, we expect a one dollar increase in gross annual teacher income to be associated with a decrease in the number of minutes it takes to earn a Big Mac by 9 x 10^(-4) minutes. Stated differently, we expect a ten-thousand dollar increase in gross annual teacher income to be associated with a decrease in the number of minutes it takes to earn a Big Mac by 9 minutes (note that here I did a scale transformation of gross annual teacher income to get this interpretation, which might make more sense when looking at the scale of salary!).\n\n\n\n\n# Residuals vs. fitted values plot\nggplot(mod, aes(x = .fitted, y = .resid)) + \n    geom_point() + \n    geom_hline(yintercept = 0) +\n    geom_smooth(se = FALSE)\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nThe residuals vs. fitted values plot shows a very clear, nonlinear pattern! As fitted values increase, residuals decrease for a while, and then sharply increase once fitted values are higher than around 40 minutes. The spread of residuals around zero also varies, with greater spread for higher fitted values.\n\nThe residuals appear to be large for people with negative fitted values and those with very high fitted values. Recall that a linear model does not “know” that number of minutes to earn a Big Mac can’t be negative, in context. If we look at the fitted line from our linear model on a scatterplot (see below)…\n\n\nbigmac %&gt;%\n  ggplot(aes(x = gross_annual_teacher_income, y = bigmac_mins)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nwe observe that negative fitted values and very large fitted values occur when annual teacher income is greater than around 70,000 and less than 10,000, respectively. This implies that the model does a worse job at predicting the number of minutes to earn a Big Mac in countries where annual teacher income is either very high or very low.\nWe’ll now consider a log transformation of teaching salary. In the code chunk below, create a new variable called log_sal that contains the logged values of gross_annual_teacher_income.\n\n# Creating new variable log_sal\nbigmac &lt;- bigmac %&gt;%\n  mutate(log_sal = log(gross_annual_teacher_income))\n\n\n\n\n\nbigmac %&gt;%\n  ggplot(aes(log_sal, bigmac_mins)) +\n  geom_point()\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nThe relationship between logged annual teaching salary and minutes to earn a Big Mac appears roughly linear, with a weakly negative relationship. Correlation is likely an appropriate numerical summary for the relationship between these two quantitative variables, as the relationship is roughly linear!\n\n\n\n\nmod_log &lt;- lm(bigmac_mins ~ log_sal, data = bigmac)\nsummary(mod_log)\n\n\nCall:\nlm(formula = bigmac_mins ~ log_sal, data = bigmac)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-36.817  -6.951  -1.241   6.032  41.357 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  210.875     14.687   14.36   &lt;2e-16 ***\nlog_sal      -18.142      1.502  -12.08   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 13.21 on 66 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.6886,    Adjusted R-squared:  0.6838 \nF-statistic: 145.9 on 1 and 66 DF,  p-value: &lt; 2.2e-16\n\n\nEach 1 unit increase in logged salary is associated with a 18.14 minute decrease in time to earn a Big Mac on average.\nWe can also use a property of logarithms to interpret the slope of -18.14 in a different way. Suppose we have two salaries: Salary1 and Salary2. If Salary2 is 10% higher than Salary1, then Salary2/Salary1 = 1.1. It is a property of logarithms that log(Salary2/Salary1) = log(Salary2) - log(Salary1). In this case log(Salary2/Salary1) = log(Salary2) - log(Salary1) = log(1.1) = 0.09531018. So a 10% increase in salary is a 0.09 unit increase in the log scale:\n\n# Multiplicative difference of 1.1, or 10% between salaries gives us the \nlog(1.1) * -18.142\n\n[1] -1.729117\n\n\nWhile a 1 unit increase in log salary is associated with an average decrease of 18 Big Mac minutes, a 0.0953 unit increase in log salary (which corresponds to a 10% multiplicative increase), is associated with a 1.7 minute decrease in Big Mac minutes.\nUnderlying math:\nCase 1: Salary = x\n   E[bigmacmin_1] = beta0 + beta1 log(x)\nCase 2: Salary = m*x\n   E[bigmacmin_2] = beta0 + beta1 log(m*x)\n\nE[bigmacmin_2] - E[bigmacmin_1] = beta1 log(m)\n\n\n\n\n# Residuals vs. fitted values plot\nggplot(mod_log, aes(x = .fitted, y = .resid)) + \n    geom_point() + \n    geom_hline(yintercept = 0) +\n    geom_smooth(se = FALSE)\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nThe residuals seem to lie roughly around zero for all possible fitted values, though the spread is still noticably larger for larger fitted values compared to smaller ones. This implies that the linearity assumption is likely satisfied for this model, but equal variance may be a concern."
  },
  {
    "objectID": "activities/04_slr_formalization.html",
    "href": "activities/04_slr_formalization.html",
    "title": "Simple linear regression: formalizing concepts",
    "section": "",
    "text": "Download the .qmd file for this activity here.\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder.\nOpen the qmd file in RStudio, and use it to type your answers/code to the exercises and reflection on the in-class activities.\n\n\n\nBy the end of this lesson, you should be able to:\n\nDifferentiate between a response / outcome variable and a predictor / explanatory variable\nWrite a model formula for a simple linear regression model with a quantitative predictor\nWrite R code to fit a linear regression model\nInterpret the intercept and slope coefficients in a simple linear regression model with a quantitative predictor\nCompute expected / predicted / fitted values and residuals from a linear regression model formula\nInterpret predicted values and residuals in the context of the data\nExplain the connection between residuals and the least squares criterion\n\n\n\n\nChoose either the reading or the videos to go through before class.\n\nReading: Sections 2.8, 3.1-3.3, 3.6 in the STAT 155 Notes\nVideos:\n\nSummarizing the Relationships between Two Quantitative Variables (Time: 12:12)\nIntroduction to Linear Models (Time: 10:57)\nMethod of Least Squares (Time: 5:10)\nInterpretation of Intercept and Slope (Time: 11:09)\nR Code for Fitting a Linear Model (Time: 11:07)",
    "crumbs": [
      "Simple linear regression: formalizing concepts"
    ]
  },
  {
    "objectID": "activities/04_slr_formalization.html#learning-goals",
    "href": "activities/04_slr_formalization.html#learning-goals",
    "title": "Simple linear regression: formalizing concepts",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nDifferentiate between a response / outcome variable and a predictor / explanatory variable\nWrite a model formula for a simple linear regression model with a quantitative predictor\nWrite R code to fit a linear regression model\nInterpret the intercept and slope coefficients in a simple linear regression model with a quantitative predictor\nCompute expected / predicted / fitted values and residuals from a linear regression model formula\nInterpret predicted values and residuals in the context of the data\nExplain the connection between residuals and the least squares criterion",
    "crumbs": [
      "Simple linear regression: formalizing concepts"
    ]
  },
  {
    "objectID": "activities/04_slr_formalization.html#readings-and-videos",
    "href": "activities/04_slr_formalization.html#readings-and-videos",
    "title": "Simple linear regression: formalizing concepts",
    "section": "",
    "text": "Choose either the reading or the videos to go through before class.\n\nReading: Sections 2.8, 3.1-3.3, 3.6 in the STAT 155 Notes\nVideos:\n\nSummarizing the Relationships between Two Quantitative Variables (Time: 12:12)\nIntroduction to Linear Models (Time: 10:57)\nMethod of Least Squares (Time: 5:10)\nInterpretation of Intercept and Slope (Time: 11:09)\nR Code for Fitting a Linear Model (Time: 11:07)",
    "crumbs": [
      "Simple linear regression: formalizing concepts"
    ]
  },
  {
    "objectID": "activities/04_slr_formalization.html#exercise-1-get-to-know-the-data",
    "href": "activities/04_slr_formalization.html#exercise-1-get-to-know-the-data",
    "title": "Simple linear regression: formalizing concepts",
    "section": "Exercise 1: Get to know the data",
    "text": "Exercise 1: Get to know the data\nCreate a new code chunk to look at the first few rows of the data and learn how much data (in terms of cases and variables) we have.\n\nWhat does a case represent?\nHow many and what kinds of variables do we have?\nThinking about the who, what, when, where, why, and how of this data, which of the 5W’s + H seem most relevant to our investigations? Explain your thoughts.",
    "crumbs": [
      "Simple linear regression: formalizing concepts"
    ]
  },
  {
    "objectID": "activities/04_slr_formalization.html#exercise-2-get-to-know-the-outcomeresponse-variable",
    "href": "activities/04_slr_formalization.html#exercise-2-get-to-know-the-outcomeresponse-variable",
    "title": "Simple linear regression: formalizing concepts",
    "section": "Exercise 2: Get to know the outcome/response variable",
    "text": "Exercise 2: Get to know the outcome/response variable\nLet’s get acquainted with the riders_registered variable.\n\nConstruct an appropriate plot to visualize the distribution of this variable, and compute appropriate numerical summaries.\nWrite a good paragraph interpreting the plot and numerical summaries.",
    "crumbs": [
      "Simple linear regression: formalizing concepts"
    ]
  },
  {
    "objectID": "activities/04_slr_formalization.html#exercise-3-explore-the-relationship-between-ridership-and-temperature",
    "href": "activities/04_slr_formalization.html#exercise-3-explore-the-relationship-between-ridership-and-temperature",
    "title": "Simple linear regression: formalizing concepts",
    "section": "Exercise 3: Explore the relationship between ridership and temperature",
    "text": "Exercise 3: Explore the relationship between ridership and temperature\nWe’d like to understand how daily ridership among registered users relates with the temperature that it feels like that day (temp_feel).\n\nWhat type of plot would be appropriate to visualize this relationship? Sketch and describe what you expect this plot to look like.\nCreate an appropriate plot using ggplot(). How does the plot compare to what you predicted?\nAdd the following two lines after your plot to add a linear (blue) and curved (red) smoothing line. What do you notice? Is a simple linear regression model appropriate for this data?\n\n\n# Add a red straight line of best fit and a blue curve of best fit\nYOUR_PLOT +\n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE) +\n    geom_smooth(color = \"blue\", se = FALSE)",
    "crumbs": [
      "Simple linear regression: formalizing concepts"
    ]
  },
  {
    "objectID": "activities/04_slr_formalization.html#exercise-4-filtering-our-data",
    "href": "activities/04_slr_formalization.html#exercise-4-filtering-our-data",
    "title": "Simple linear regression: formalizing concepts",
    "section": "Exercise 4: Filtering our data",
    "text": "Exercise 4: Filtering our data\nThe relationship between registered riders and temperature looks linear below 80 degrees. We can use the filter() function from the dplyr package to subset our cases. (We’ll learn techniques soon for handling this nonlinear relationship.)\nIf we wanted to only keep cases where registered ridership was greater than 2000, we would use the following code:\n\n# The %&gt;% is called a \"pipe\" and feeds what comes before it\n# into what comes after (bikes data is \"fed into\" the filter() function)\nNEW_DATASET_NAME &lt;- bikes %&gt;% \n    filter(riders_registered &gt; 2000)\n\nAdapt the example above to create a new dataset called bikes_sub that only keeps cases where the felt temperature is less than 80 degrees.",
    "crumbs": [
      "Simple linear regression: formalizing concepts"
    ]
  },
  {
    "objectID": "activities/04_slr_formalization.html#exercise-5-model-fitting-and-coefficient-interpretation",
    "href": "activities/04_slr_formalization.html#exercise-5-model-fitting-and-coefficient-interpretation",
    "title": "Simple linear regression: formalizing concepts",
    "section": "Exercise 5: Model fitting and coefficient interpretation",
    "text": "Exercise 5: Model fitting and coefficient interpretation\nLet’s fit a simple linear regression model and examine the results. Step through code chunk slowly, and make note of new code.\n\n# Construct and save the model as bike_mod\n# What's the purpose of \"riders_registered ~ temp_feel\"?\n# What's the purpose of \"data = bikes_sub\"?\nbike_mod &lt;- lm(riders_registered ~ temp_feel, data = bikes_sub)\n\n\n# A long summary of the model stored in bike_mod\nsummary(bike_mod)\n\n\n# A simplified model summary\ncoef(summary(bike_mod))\n\n\nUsing the model summary output, complete the following model formula:\nE[riders_registered | temp_feel] = ___ + ___ * temp_feel\nInterpret the intercept in terms of the data context. Make sure to use non-causal language, include units, and talk about averages rather than individual cases. Is the intercept meaningful in this situation?\nInterpret the slope in terms of the data context. Make sure to use non-causal language, include units, and talk about averages rather than individual cases.",
    "crumbs": [
      "Simple linear regression: formalizing concepts"
    ]
  },
  {
    "objectID": "activities/04_slr_formalization.html#exercise-6-predictions-and-residuals",
    "href": "activities/04_slr_formalization.html#exercise-6-predictions-and-residuals",
    "title": "Simple linear regression: formalizing concepts",
    "section": "Exercise 6: Predictions and residuals",
    "text": "Exercise 6: Predictions and residuals\nOn August 17, 2012, the temp_feel was 53.816 degrees and there were 5665 riders. We can get data for this day using the filter() and select() dplyr functions. Note, but don’t worry about the syntax – we haven’t learned this yet:\n\nbikes_sub %&gt;% \n    filter(date == \"2012-08-17\") %&gt;% \n    select(riders_registered, temp_feel) \n\n\nPeak back at the scatterplot. Identify which point corresponds to August 17, 2012. Is it close to the trend? Were there more riders than expected or fewer than expected?\nUse your model formula from the previous exercise to predict the ridership on August 17, 2012 from the temperature on that day. (That is, where do days with this temperature fall on the model trend line? How many registered riders would we expect on a 53.816 degree day?)\nCheck your part b calculation using the predict() function. Take careful note of the syntax – there’s a lot going on!\n\n\n# What is the purpose of newdata = ___???\npredict(bike_mod, newdata = data.frame(temp_feel = 53.816))\n\n\nCalculate the residual or prediction error. How far does the observed ridership fall from the model prediction?\nresidual = observed y - predicted y = ???\nAre positive residuals above or below the trend line? When we have positive residuals, does the model over- or under-estimate ridership? Repeat these questions for negative residuals.\nFor an 85 degree day, how many registered riders would we expect? Do you think it’s a good idea to make this prediction? (Revisit the visualization and filtering we did in Exercises 3 and 4.)",
    "crumbs": [
      "Simple linear regression: formalizing concepts"
    ]
  },
  {
    "objectID": "activities/04_slr_formalization.html#exercise-7-changing-temperature-units-challenge",
    "href": "activities/04_slr_formalization.html#exercise-7-changing-temperature-units-challenge",
    "title": "Simple linear regression: formalizing concepts",
    "section": "Exercise 7: Changing temperature units (CHALLENGE)",
    "text": "Exercise 7: Changing temperature units (CHALLENGE)\nSuppose we had measured temperature in degrees Celsius rather than degrees Fahrenheit. How do you think our intercept and slope estimates, and their coefficient interpretations, would change?",
    "crumbs": [
      "Simple linear regression: formalizing concepts"
    ]
  },
  {
    "objectID": "activities/04_slr_formalization.html#reflection",
    "href": "activities/04_slr_formalization.html#reflection",
    "title": "Simple linear regression: formalizing concepts",
    "section": "Reflection",
    "text": "Reflection\nStatistics is a particular kind of language and collection of tools for channeling curiosity to improve our world.\nReview the learning objectives at the top of this file and the flow of today’s activity. How do the concepts we practiced today facilitate curiosity?\n\nResponse: Put your response here.",
    "crumbs": [
      "Simple linear regression: formalizing concepts"
    ]
  },
  {
    "objectID": "activities/04_slr_formalization.html#render-your-work",
    "href": "activities/04_slr_formalization.html#render-your-work",
    "title": "Simple linear regression: formalizing concepts",
    "section": "Render your work",
    "text": "Render your work\n\nClick the “Render” button in the menu bar for this pane (blue arrow pointing right). This will create an HTML file containing all of the directions, code, and responses from this activity. A preview of the HTML will appear in the browser.\nScroll through and inspect the document to check that your work translated to the HTML format correctly.\nClose the browser tab.\nGo to the “Background Jobs” pane in RStudio and click the Stop button to end the rendering process.\nNavigate to your “Activities” subfolder within your “STAT155” folder and locate the HTML file. You can open it again in your browser to double check.",
    "crumbs": [
      "Simple linear regression: formalizing concepts"
    ]
  },
  {
    "objectID": "activities/04_slr_formalization.html#exercise-8-ridership-and-windspeed",
    "href": "activities/04_slr_formalization.html#exercise-8-ridership-and-windspeed",
    "title": "Simple linear regression: formalizing concepts",
    "section": "Exercise 8: Ridership and windspeed",
    "text": "Exercise 8: Ridership and windspeed\nLet’s pull together everything that you’ve practiced in the preceding exercises to investigate the relationship between riders_registered and windspeed. Go back to using the bikes dataset (instead of bikes_sub) because we no longer need to only keep days less than 80 degrees.\n\n# Construct and interpret a visualization of this relationship\n# Include a representation of the relationship trend\n\n\n# Use lm to construct a model of riders_registered vs windspeed\n# Save this as bike_mod2\n\n\n# Get a short summary of this model\n\n\nSummarize your observations from the visualizations.\nWrite out a formula for the model trend.\nInterpret both the intercept and the windspeed coefficient. (Note: What does a negative slope indicate?)\nUse this model to predict the ridership on August 17, 2012 and calculate the corresponding residual. (Note: You’ll first need to find the windspeed on this date!)",
    "crumbs": [
      "Simple linear regression: formalizing concepts"
    ]
  },
  {
    "objectID": "activities/04_slr_formalization.html#exercise-9-data-drills-filter-select-summarize",
    "href": "activities/04_slr_formalization.html#exercise-9-data-drills-filter-select-summarize",
    "title": "Simple linear regression: formalizing concepts",
    "section": "Exercise 9: Data drills (filter, select, summarize)",
    "text": "Exercise 9: Data drills (filter, select, summarize)\nThis exercise is designed to help you keep building your dplyr skills. These skills are important to data cleaning and digging, which in turn is important to really making meaning of our data. We’ll work with a simpler set of 10 data points:\n\nnew_bikes &lt;- bikes %&gt;% \n    select(date, temp_feel, humidity, riders_registered, day_of_week) %&gt;% \n    head(10)\n\n\nVerb 1: summarize\nThus far, in the dplyr grammar you’ve seen 3 verbs or action words: summarize(), select(), filter(). Try out the following code and then summarize the point of the summarize() function:\n\nnew_bikes %&gt;% \n    summarize(mean(temp_feel), mean(humidity))\n\n\n\nVerb 2: select\nTry out the following code and then summarize the point of the select() function:\n\nnew_bikes %&gt;%\n    select(date, temp_feel)\n\n\nnew_bikes %&gt;% \n    select(-date, -temp_feel)\n\n\n\nVerb 3: filter\nTry out the following code and then summarize the point of the filter() function:\n\nnew_bikes %&gt;% \n    filter(riders_registered &gt; 850)\n\n\nnew_bikes %&gt;% \n    filter(day_of_week == \"Sat\")\n\n\nnew_bikes %&gt;% \n    filter(riders_registered &gt; 850, day_of_week == \"Sat\")",
    "crumbs": [
      "Simple linear regression: formalizing concepts"
    ]
  },
  {
    "objectID": "activities/04_slr_formalization.html#exercise-10-your-turn",
    "href": "activities/04_slr_formalization.html#exercise-10-your-turn",
    "title": "Simple linear regression: formalizing concepts",
    "section": "Exercise 10: Your turn",
    "text": "Exercise 10: Your turn\nUse dplyr verbs to complete each task below.\n\n# Keep only information about the humidity and day of week\n\n# Keep only information about the humidity and day of week using a different approach\n\n# Keep only information for Sundays\n\n# Keep only information for Sundays with temperatures below 50\n\n# Calculate the maximum and minimum temperatures\n\n\nSolutions",
    "crumbs": [
      "Simple linear regression: formalizing concepts"
    ]
  },
  {
    "objectID": "activities/06_slr_transformations.html",
    "href": "activities/06_slr_transformations.html",
    "title": "Simple linear regression: Transformations",
    "section": "",
    "text": "Download the .qmd file for this activity here.\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder.\nOpen the qmd file in RStudio, and use it to type your answers/code to the exercises and reflection on the in-class activities.\n\n\n\nBy the end of this lesson, you should be able to:\n\nDistinguish between the different motivations for transformations of variables (interpretation, regression assumptions, etc.)\nDetermine when a particular transformation (center, scale, or log) may be appropriate\nInterpret regression coefficients after a transformation has taken place\n\n\n\n\nPlease watch the following video before class.\n\nVideo: Simple Linear Regression: Transformations\n\nThe following reading is optional.\n\nSection 3.8.4 in the STAT 155 Notes covers log transformations, and the “ladder of power,” which we will not cover in class.",
    "crumbs": [
      "Simple linear regression: Transformations"
    ]
  },
  {
    "objectID": "activities/06_slr_transformations.html#learning-goals",
    "href": "activities/06_slr_transformations.html#learning-goals",
    "title": "Simple linear regression: Transformations",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nDistinguish between the different motivations for transformations of variables (interpretation, regression assumptions, etc.)\nDetermine when a particular transformation (center, scale, or log) may be appropriate\nInterpret regression coefficients after a transformation has taken place",
    "crumbs": [
      "Simple linear regression: Transformations"
    ]
  },
  {
    "objectID": "activities/06_slr_transformations.html#readings-and-videos",
    "href": "activities/06_slr_transformations.html#readings-and-videos",
    "title": "Simple linear regression: Transformations",
    "section": "",
    "text": "Please watch the following video before class.\n\nVideo: Simple Linear Regression: Transformations\n\nThe following reading is optional.\n\nSection 3.8.4 in the STAT 155 Notes covers log transformations, and the “ladder of power,” which we will not cover in class.",
    "crumbs": [
      "Simple linear regression: Transformations"
    ]
  },
  {
    "objectID": "activities/06_slr_transformations.html#exercise-1-location-transformations",
    "href": "activities/06_slr_transformations.html#exercise-1-location-transformations",
    "title": "Simple linear regression: Transformations",
    "section": "Exercise 1: Location transformations",
    "text": "Exercise 1: Location transformations\nLocation transformations are ones that shift a predictor variable up or down by a fixed amount. Using a location transformation is sometimes also called centering a predictor.\nWe’ll use the homes data in this exercise.\n\nFit a linear regression model of Price as a function of Living.Area, and call this model home_mod.\n\n\n# Fit the model\n\n\n# Display model summary output\n\n\nInterpret the intercept and the coefficient for Living.Area. Is the interpretation of the intercept meaningful?\nWe can use a location transformation on Living.Area to “start” it at a more reasonable value. We can see from the summarize() code below that the smallest house is 616 quare feet, so let’s center this predictor at 600 square feet. There is no code to fill in here, but make note of the mutate() syntax.\n\n\nhomes %&gt;% \n    summarize(min(Living.Area))\n\n# What is mutate() doing???\nhomes &lt;- homes %&gt;%\n    mutate(Living.Area.Shifted = Living.Area-600)\n\n\nWe can actually determine the coefficients of the Price ~ Living.Area.Shifted model by hand.\n\nFirst, write out in general terms (without specific numbers) how we would interpret the intercept and slope in this model.\nUse these general interpretations as well as the summary output of home_mod to determine what these new coefficients should be.\n\nNow check your answer to part d by fitting the model.\n\n\n# Fit a model of Price vs. Living.Area.Shifted\n\n\n# Display model summary output",
    "crumbs": [
      "Simple linear regression: Transformations"
    ]
  },
  {
    "objectID": "activities/06_slr_transformations.html#exercise-2-scale-transformations",
    "href": "activities/06_slr_transformations.html#exercise-2-scale-transformations",
    "title": "Simple linear regression: Transformations",
    "section": "Exercise 2: Scale transformations",
    "text": "Exercise 2: Scale transformations\nIn this exercise, we’ll explore the relationship between four-year graduation rate and admissions rate of colleges.\nIn the code chunk below, construct a visualization comparing graduation rate (our outcome variable) and admissions rate (our predictor of interest). Remember that your outcome variable should be on the y-axis, in general!\n\n# Scatterplot of graduation rate vs. admissions rate\n\n\nDescribe the relationship you observe between the two quantitative variables, in terms of correlation (weak/strong, positive/negative). Does the relationship appear to be roughly linear?\nWrite a linear regression model formula of the form E[Y | X] = … (filling in Y and X appropriately).\nFit this model in R, and report (don’t interpret yet!) the slope coefficient and intercept coefficient estimates.\n\n\n# Linear regression model with GradRate as the outcome, AdmisRate as predictor of interest\n\n\nIntercept Estimate: Your response here\n\n\nSlope Estimate: Your response here\n\n\nConsidering the units of AdmisRate, what does it mean for AdmisRate to change by one unit? What are the units for AdmisRate (and GradRate, for that matter!)?\nSuppose I want the interpretation of my slope coefficient for AdmisRate in my linear model to be in terms a “1% increase in admissions rate.” To achieve this, we could mutate our AdmisRate variable to range from 0 to 100. Let’s do that for GradRate too (just because!):\n\n\n# Mutate\ncollege &lt;- college %&gt;%\n  mutate(AdmisRate = AdmisRate * ___,\n         GradRate = ___ * ___)\n\n\nFit a new linear regression model with the updated AdmisRate and GradRate variables as your predictor of interest and outcome, respectively. Again, report the intercept and slope estimate from your model.\n\n\n# Linear regression model with updated GradRate as the outcome, updated AdmisRate as predictor of interest\n\n\nIntercept Estimate: Your response here\n\n\nSlope Estimate: Your response here\n\nHow have your intercept and slope estimates changed from the previous model, if at all?\n\nInterpret the regression coefficient that corresponds to the estimated linear relationship between admissions and graduation rates, in the context of the problem. Make sure to use non-causal language, include units, and talk about averages rather than individual cases.",
    "crumbs": [
      "Simple linear regression: Transformations"
    ]
  },
  {
    "objectID": "activities/06_slr_transformations.html#exercise-3-log-transformations",
    "href": "activities/06_slr_transformations.html#exercise-3-log-transformations",
    "title": "Simple linear regression: Transformations",
    "section": "Exercise 3: Log transformations",
    "text": "Exercise 3: Log transformations\nThe Big Mac Index has been published by The Economist since 1986 as a metric for comparing purchasing power between countries, giving rise to the phrase Burgernomics. It was developed (sort of jokingly) as a way to explain exchange rates in digestible terms.\nAs an example, suppose a Big Mac in Switzerland costs 6.70 Swiss franc, and in the U.S. a Big Mac costs 5.58 USD. Then the Big Mac Index is 6.70/5.58 = 1.20, and is the implied exchange rate between Swiss franc and USD.\nIf you’d like to read more about the Big Mac index, here’s an article in The Economist (this may be behind a pay-wall for you, you can read up to 5 free articles in the Economist per month).\nFor this exercise, we’ll explore the relationship between average teaching salary in a country and the amount of time someone needs to work to be able to afford a Big Mac. The variables we’ll consider are:\n\nbigmac_mins: average minutes to earn 1 Big Mac\ngross_annual_teacher_income: average gross teacher salary in 1 year (USD)\n\n\nCreate an appropriate visualization that displays the relationship between average minutes to earn a Big Mac and gross annual, average teaching salary, and describe what you observe.\n\n\n# Visualization: Big Mac minutes vs. gross annual teacher income\n\n\nExplain why correlation might not be an appropriate numerical summary for the relationship between the two variables you plotted above.\nFit a linear regression model with bigmac_mins as the outcome and gross_annual_teacher_income as the predictor of interest, and interpret the coefficient for gross_annual_teacher_income, in context. Make sure to use non-causal language, include units, and talk about averages rather than individual cases.\n\n\n# Linear regression code\n\n\nPlot residuals vs. fitted values for the model you fit, and describe what you observe. Are there any noticeable patterns in the residuals? Describe them!\n\n\n# Residuals vs. fitted values plot\n\n\nFor which observations do the residuals from the linear regression model appear to be relatively large (i.e. for which observations would predictions fall farthest from observed outcomes)? What possible consequences would this have for people using this model to predict the amount of time it takes for them to earn enough money to afford a Big Mac?\n\nWe’ll now consider a log transformation of teaching salary. In the code chunk below, create a new variable called log_sal that contains the logged values of gross_annual_teacher_income.\n\n# Creating new variable log_sal\nbigmac &lt;- bigmac %&gt;%\n  mutate(log_sal = log(___))\n\n\nCreate an appropriate visualization that displays the relationship between average minutes to earn a Big Mac and logged gross annual, average teaching salary, and describe what you observe. Does correlation seem like it may be an appropriate numerical summary for the relationship between these two variables? Explain why or why not.\nFit a linear regression model with bigmac_mins as the outcome and log_sal as the predictor of interest, and interpret the coefficient for log_sal, in context. Make sure to use non-causal language, include units, and talk about averages rather than individual cases.\nPlot residuals vs. fitted values for the model you fit, and describe what you observe. Are there any noticeable patterns in the residuals? Describe them!\n\n\n# Residuals vs. fitted values plot",
    "crumbs": [
      "Simple linear regression: Transformations"
    ]
  },
  {
    "objectID": "activities/06_slr_transformations.html#reflection",
    "href": "activities/06_slr_transformations.html#reflection",
    "title": "Simple linear regression: Transformations",
    "section": "Reflection",
    "text": "Reflection\nTwo of the main motivations for transforming variables in our regression models is to (1) intentionally change the interpretation of regression coefficients, and (2) to better satisfy linear regression assumptions (e.g. remove “patterns” from our residual plots). The first is nearly always justified by the scientific context of the research questions you are trying to answer, while the second is a bit more muddy.\nThink about the pros and cons of transforming your variables to satisfy linear regression assumptions. Is there a limit to how much you would be willing to transform your variables? Would transforming too much leave you with un-interpretable regression coefficients?\n\nResponse: Put your response here.\n\n\nSolutions",
    "crumbs": [
      "Simple linear regression: Transformations"
    ]
  },
  {
    "objectID": "solutions/05_slr_model_eval.html",
    "href": "solutions/05_slr_model_eval.html",
    "title": "Solutions for simple linear regression: model evaluation",
    "section": "",
    "text": "# Load packages and import data\nlibrary(readr)\nlibrary(ggplot2)\nlibrary(dplyr)\n\nbikes &lt;- read_csv(\"https://mac-stat.github.io/data/bikeshare.csv\")"
  },
  {
    "objectID": "solutions/05_slr_model_eval.html#exercise-1-is-the-model-correct",
    "href": "solutions/05_slr_model_eval.html#exercise-1-is-the-model-correct",
    "title": "Solutions for simple linear regression: model evaluation",
    "section": "Exercise 1: Is the model correct?",
    "text": "Exercise 1: Is the model correct?\nThe blue curved trend line shows a clear downward trend around 85 degrees, which contextually makes plenty of sense—extremely hot days would naturally see less riders. Overall the combination of the upward trend and downward trend makes for a curved relationship that is not captured well by a straight line of best fit.\n\nggplot(bikes, aes(x = temp_feel, y = riders_registered)) + \n    geom_point() + \n    geom_smooth(se = FALSE) +\n    geom_smooth(method = \"lm\", se = FALSE, color = \"red\")\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "solutions/05_slr_model_eval.html#exercise-2-fixing-the-model",
    "href": "solutions/05_slr_model_eval.html#exercise-2-fixing-the-model",
    "title": "Solutions for simple linear regression: model evaluation",
    "section": "Exercise 2: Fixing the model",
    "text": "Exercise 2: Fixing the model\nThe second plot (showing the model with squared temperature) follows the natural curve in the trend better.\n\nbikes &lt;- bikes %&gt;% \n    mutate(temp_feel_squared = temp_feel^2)\n\n# Plot the model WITHOUT squared temperature\nggplot(bikes, aes(x = temp_feel, y = riders_registered)) + \n    geom_point() + \n    geom_smooth(se = FALSE) +\n    geom_smooth(method = \"lm\", se = FALSE, color = \"red\")\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n# Plot the model WITH squared temperature\nggplot(bikes, aes(x = temp_feel, y = riders_registered)) + \n    geom_point() + \n    geom_smooth(se = FALSE) +\n    geom_smooth(method = \"lm\", formula = y ~ x + I(x^2), se = FALSE, color = \"red\")\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'"
  },
  {
    "objectID": "solutions/05_slr_model_eval.html#exercise-3-residual-plots",
    "href": "solutions/05_slr_model_eval.html#exercise-3-residual-plots",
    "title": "Solutions for simple linear regression: model evaluation",
    "section": "Exercise 3: Residual plots",
    "text": "Exercise 3: Residual plots\nThe first residual plot (from the model with just a straight line trend) shows a lingering trend in the residuals—the blue curve traces the trend in the residuals, and it does not lie flat on the y = 0 line.\nOn the other hand, the second residual plot (from the model which uses a squared term to allow for curvature) shows very little trend in the residuals—the blue curve is almost flat on the y = 0 line.\n\n# Fit a linear model\nbike_mod1 &lt;- lm(riders_registered ~ temp_feel, data = bikes)\n# Fit a quadratic model\nbike_mod2 &lt;- lm(riders_registered ~ temp_feel + temp_feel_squared, data = bikes)\n\n# Check out the residual plot for bike_mod1 (the incorrect model)\nggplot(bike_mod1, aes(x = .fitted, y = .resid)) + \n    geom_point() + \n    geom_hline(yintercept = 0) +\n    geom_smooth(se = FALSE)\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n# Construct the residual plot for bike_mod2 (the good model)\nggplot(bike_mod2, aes(x = .fitted, y = .resid)) + \n    geom_point() + \n    geom_hline(yintercept = 0) +\n    geom_smooth(se = FALSE)\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'"
  },
  {
    "objectID": "solutions/05_slr_model_eval.html#exercise-4-another-example-of-an-incorrect-model",
    "href": "solutions/05_slr_model_eval.html#exercise-4-another-example-of-an-incorrect-model",
    "title": "Solutions for simple linear regression: model evaluation",
    "section": "Exercise 4: Another example of an incorrect model",
    "text": "Exercise 4: Another example of an incorrect model\n\n\n\n\n# Import the data\nlibrary(fivethirtyeight)\n\nSome larger datasets need to be installed separately, like senators and\nhouse_district_forecast. To install these, we recommend you install the\nfivethirtyeightdata package by running:\ninstall.packages('fivethirtyeightdata', repos =\n'https://fivethirtyeightdata.github.io/drat/', type = 'source')\n\ndata(bechdel)\n\n# Get only 1997 movies\nmovies_1997 &lt;- bechdel %&gt;% \n    filter(year == 1997)\n\n# Construct the model\nbechdel_model &lt;- lm(intgross ~ budget, movies_1997)\n\n\n# Scatterplot of earnings and budget with linear and curved trend lines\nggplot(movies_1997, aes(x = budget, y = intgross)) +\n    geom_point() +\n    geom_smooth(se = FALSE) +\n    geom_smooth(method = \"lm\", se = FALSE, color = \"red\")\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n# Residual plot for bechdel_model\nggplot(bechdel_model, aes(x = .fitted, y = .resid)) +\n    geom_point() +\n    geom_hline(yintercept = 0) +\n    geom_smooth(se = FALSE)\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nFrom the scatterplot, we can see that there is one movie that is a massive outlier in both budget and earnings, and this outlier is pulling up the trend line that makes the model for “regular” movies that have budgets and earnings in “normal” ranges.\nThe outlier movie is Titanic:\n\n\n# One of many ways to filter to find the outlier movie!\nmovies_1997 %&gt;% \n    filter(intgross &gt; 2000000000)\n\n# A tibble: 1 × 15\n   year imdb      title   test  clean_test binary budget domgross intgross code \n  &lt;int&gt; &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt; &lt;ord&gt;      &lt;chr&gt;   &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;\n1  1997 tt0120338 Titanic ok    ok         PASS      2e8   6.59e8   2.19e9 1997…\n# ℹ 5 more variables: budget_2013 &lt;int&gt;, domgross_2013 &lt;dbl&gt;,\n#   intgross_2013 &lt;dbl&gt;, period_code &lt;int&gt;, decade_code &lt;int&gt;"
  },
  {
    "objectID": "solutions/05_slr_model_eval.html#exercise-5-is-the-model-strong-developing-r-squared-intuition",
    "href": "solutions/05_slr_model_eval.html#exercise-5-is-the-model-strong-developing-r-squared-intuition",
    "title": "Solutions for simple linear regression: model evaluation",
    "section": "Exercise 5: Is the model strong? Developing R-squared intuition",
    "text": "Exercise 5: Is the model strong? Developing R-squared intuition\nThe R-squared metric is a way to quantify the strength of a model. It measures how much variation in the outcome/response variable can be explained by the model.\nWhere does R-squared come from? Well, it turns out that we can partition the variance of the observed response values into the variability that’s explained by the model (the variance of the predictions) and the variability that’s left unexplained by the model (the variance of the residuals):\n\\[\\text{Var(observed) = Var(predicted) + Var(residuals)}\\]\n“Good” models have residuals that don’t deviate far from 0. So the smaller the variance in the residuals (thus larger the variance in the predictions), the stronger the model. Take a look at the picture below and write a few sentences addressing the following:\n\nThe first row corresponds to the weaker model. We can tell because the points are much more dispersed from the trend line than in the second row. Recall that the correlation metric measures how closely clustered points are about a straight line of best fit, so we would expect the correlation to be lower for the first row than the second row.\nThe variance of the residuals is much lower for the second row—the residuals are all quite small. This indicates a stronger model."
  },
  {
    "objectID": "solutions/05_slr_model_eval.html#exercise-6-further-exploring-r-squared",
    "href": "solutions/05_slr_model_eval.html#exercise-6-further-exploring-r-squared",
    "title": "Solutions for simple linear regression: model evaluation",
    "section": "Exercise 6: Further exploring R-squared",
    "text": "Exercise 6: Further exploring R-squared\nIn this exercise, we’ll look at data from a synthetic dataset called Anscombe’s quartet. Load the data in as follows, and look at the first few rows:\n\ndata(anscombe)\n\n# Look at the first few rows\nhead(anscombe)\n\n  x1 x2 x3 x4   y1   y2    y3   y4\n1 10 10 10  8 8.04 9.14  7.46 6.58\n2  8  8  8  8 6.95 8.14  6.77 5.76\n3 13 13 13  8 7.58 8.74 12.74 7.71\n4  9  9  9  8 8.81 8.77  7.11 8.84\n5 11 11 11  8 8.33 9.26  7.81 8.47\n6 14 14 14  8 9.96 8.10  8.84 7.04\n\n\nAll of these models have close to the same intercept, slope, and R-squared!\n\nanscombe_mod1 &lt;- lm(y1 ~ x1, data = anscombe)\nanscombe_mod2 &lt;- lm(y2 ~ x2, data = anscombe)\nanscombe_mod3 &lt;- lm(y3 ~ x3, data = anscombe)\nanscombe_mod4 &lt;- lm(y4 ~ x4, data = anscombe)\n\nsummary(anscombe_mod1)\n\n\nCall:\nlm(formula = y1 ~ x1, data = anscombe)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.92127 -0.45577 -0.04136  0.70941  1.83882 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)   3.0001     1.1247   2.667  0.02573 * \nx1            0.5001     0.1179   4.241  0.00217 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.237 on 9 degrees of freedom\nMultiple R-squared:  0.6665,    Adjusted R-squared:  0.6295 \nF-statistic: 17.99 on 1 and 9 DF,  p-value: 0.00217\n\nsummary(anscombe_mod2)\n\n\nCall:\nlm(formula = y2 ~ x2, data = anscombe)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.9009 -0.7609  0.1291  0.9491  1.2691 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)    3.001      1.125   2.667  0.02576 * \nx2             0.500      0.118   4.239  0.00218 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.237 on 9 degrees of freedom\nMultiple R-squared:  0.6662,    Adjusted R-squared:  0.6292 \nF-statistic: 17.97 on 1 and 9 DF,  p-value: 0.002179\n\nsummary(anscombe_mod3)\n\n\nCall:\nlm(formula = y3 ~ x3, data = anscombe)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.1586 -0.6146 -0.2303  0.1540  3.2411 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)   3.0025     1.1245   2.670  0.02562 * \nx3            0.4997     0.1179   4.239  0.00218 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.236 on 9 degrees of freedom\nMultiple R-squared:  0.6663,    Adjusted R-squared:  0.6292 \nF-statistic: 17.97 on 1 and 9 DF,  p-value: 0.002176\n\nsummary(anscombe_mod4)\n\n\nCall:\nlm(formula = y4 ~ x4, data = anscombe)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-1.751 -0.831  0.000  0.809  1.839 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)   3.0017     1.1239   2.671  0.02559 * \nx4            0.4999     0.1178   4.243  0.00216 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.236 on 9 degrees of freedom\nMultiple R-squared:  0.6667,    Adjusted R-squared:  0.6297 \nF-statistic:    18 on 1 and 9 DF,  p-value: 0.002165\n\n\nBut when we look at the scatterplots, they all look substantially different, and we would want to approach our modeling differently for each one:\n\nx1 and y1: A linear model seems appropriate for this data.\nx2 and y2: The scatterplot is clearly curved—a “linear” regression model with squared terms, for example, would be more appropriate for this data. (We’ll talk more about ways to handle nonlinear relationships soon!)\nx3 and y3: There is a very clear outlier at about x3 = 13 that we would want to dig into to better understand the context. After that investigation, we might consider removing this outlier and refitting the model.\nx4 and y4: There is clearly something strange going on with most of the cases having an x4 value of exactly 8. We would not want to jump straight into modeling. Instead, we should dig deeper to find out more about this data.\n\n\nggplot(anscombe, aes(x = x1, y = y1)) +\n    geom_point() + \n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nggplot(anscombe, aes(x = x2, y = y2)) +\n    geom_point() + \n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nggplot(anscombe, aes(x = x3, y = y3)) +\n    geom_point() + \n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nggplot(anscombe, aes(x = x4, y = y4)) +\n    geom_point() + \n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "solutions/05_slr_model_eval.html#exercises-7---10",
    "href": "solutions/05_slr_model_eval.html#exercises-7---10",
    "title": "Solutions for simple linear regression: model evaluation",
    "section": "Exercises 7 - 10",
    "text": "Exercises 7 - 10\nNo solutions for these exercises. These require longer discussions, not discrete answers."
  },
  {
    "objectID": "tech_setup.html",
    "href": "tech_setup.html",
    "title": "Tech Setup",
    "section": "",
    "text": "Follow these instructions to set up the software that we’ll be using throughout the semester. Even if you’ve already downloaded both R and RStudio, you’ll want to re-download to make sure that you have the most current versions.\n\nRequired: Change the default file download location for your internet browser.\n\nGenerally by default, internet browsers automatically save all files to the Downloads folder on your computer. This does not encourage good file organization practices. You need to change this option so that your browser asks you where to save each file before downloading it.\nThis page has information on how to do this for the most common browsers.\n\n\nRequired: Download R and RStudio.\n\nFIRST: Download R here.\n\nIn the top section, you will see three links “Download R for …”\nChoose the link that corresponds to your computer.\nAs of August 27, 2024, the latest version of R is 4.4.1 (“Race for Your Life”).\n\nSECOND: Download RStudio here.\n\nClick the button under step 2 to install the version of RStudio recommended for your computer.\nAs of August 27, 2024, the latest version of RStudio is 2024.04.2+764.\n\n\n\nSuggested: Watch this video describing key configuration options for RStudio.\n\nRequired: Install required packages.\n\nAn R package is an extra bit of functionality that will help us in our data analysis efforts in a variety of ways.\nOpen RStudio and click inside the Console pane (by default, the bottom left pane). Copy and paste the following command into the Console. You should see the text below appear to the right of the &gt;, which is called the R prompt. After you paste, hit Enter.\n\n\ninstall.packages(c(\"tidyverse\"))\n\n\nYou will see a lot of text from status messages appearing in the Console as the packages are being installed. Wait until you see the &gt; again.\nEnter the command library(tidyverse) and hit Enter.\nIf you see an error message, then there was a problem installing the package. Talk to the instructor or a preceptor for help.\nQuit RStudio. You’re done setting up!\n\n\nOptional: For a tour of RStudio features, watch this video. It also shows you how to customize the layout and color scheme of RStudio.\n\nRequired: Set essential RStudio options.\nGo to Tools -&gt; Global Options -&gt; General -&gt; Workplace. You’ll see 2 options:\n\nRestore .RData into workspace at startup: Leave this unchecked\nSave workspace to .RData on exit: Select “Never”\n\nWithout doing this RStudio will save and reload everything that you’ve been working on from the start of the semester. Since we’ll be working with new data each class, we want to keep our digital environment clean. Essentially, this is like an artist getting a clean canvas for each new painting rather than trying to paint all paintings on a single canvas."
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Week\nT\nTh\nHomework\n\n\n\n\n1 (9/2 - 9/6)\nFirst day\n01: Welcome and data fundamentals\n02: Univariate vizualization + summaries\n\n\n\n2 (9/9 - 9/13)\n03: SLR discovery day + Start 04\nReview 04: SLR formalization + 05: SLR model eval\nHomework 1 due Friday at 5pm\n\n\n3 (9/16 - 9/20)\n06: SLR transformations\n07: SLR categorical predictor + Library Activity\nHomework 2 due\n\n\n4 (9/23 - 9/27)\n08: MLR intro\nQuiz 1 (60 mins)\nOH/project work\n\n\n\n5 (9/30 - 10/4)\n09: MLR principles\n10: MLR confounding\nHomework 3 due\n\n\n6 (10/7 - 10/11)\n11: MLR interaction discovery + Start 12: MLR interaction practice\nReview 12: MLR interaction practice + 13: MLR Model Building 1\nHomework 4 due\nProject Checkpoint 1 due\n\n\n7 (10/14 - 10/18)\n14: MLR Model Building 2\nFALL BREAK \n\n\n\n8 (10/21 - 10/25)\n15+16\nMIDTERM GRADES (Wed)\n17: Multiple logistic, prediction, evaluation\nHomework 5 due\n\n\n9 (10/28 - 11/1)\n18: Tools for inference (sampling variation, sampling distributions)\nQuiz 2 (60 mins) + OH/project work\n\n\n\n\n10 (11/4 - 11/8)\nELECTION DAY \n19: Tools for inference (bootstrapping, normal distribution)\n20: Confidence intervals\nLAST DAY TO WITHDRAW (Fri)\nHomework 6 due\n\n\n11 (11/11 - 11/15)\n21: Hypothesis testing discovery + start 22: Hypothesis testing details\nReview 22 + 23: Hypothesis testing practice\nHomework 7 due\n\n\n12 (11/18 - 11/22)\n24: Hypothesis testing (F-test)\n25: ASA statement on p-values\nHomework 8 due\n\n\n13 (11/25 - 11/29)\nProject Time\nTHANKSGIVING\nProject Checkpoint 2 due\n(Tuesday at 5pm)\n\n\n14 (12/2 - 12/6)\nProject Time\nProject Time\n\n\n\n15 (12/9 - 12/13)\nLast Day of Class\nProject Paper Due, Presentations\nFinal Exam Period - \nQuiz 3"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STAT 155: Introduction to Statistical Modeling",
    "section": "",
    "text": "Macalester College, Fall 2024\n\nLearn the fundamentals of summarizing, visualizing, and modeling data to answer research questions.\n\n\nInstructor: Jedidiah Carlson  Class meeting times:\n\nSection 05: Tu/Th 1:20-2:50pm\nSection 06: Tu/Th 3:00-4:30pm\n\nClass location: THEATR 202 \nInstructor drop-in hours:\n\nlocation: My office (OLRI 235)\ntimes: See this calendar (Tentatively from 1-3pm on Wednesdays and 10am-11am on Thursdays, but subject to change based on responses to the introductions survey).\n1:1 appointments: I’m also happy to meet one-on-one if my normal drop-in hours don’t work for you. You can schedule a time to meet with me using this link.\n\n\n\n\n\n\n\n\n\nWeek 1: 9/2 - 9/6 (Data fundamentals, univariate visualization and summaries)\n\n\n\n\n\n\n\nWelcome (back) to campus!\n\n\n\nBefore class:\n\nreview the course syllabus\ncomplete the Introductions survey\ntry downloading R and RStudio\n\n\n\n\nBefore class:\n\nDownload and familiarize yourself with R and RStudio\nComplete the Introductions survey (if you haven’t already!)\nComplete today’s checkpoint on Moodle\n\nDo either the readings or videos for the Day 2 Activity (see Moodle for links)\ndue 30 minutes before class on 9/5\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 2: 9/9 - 9/13 (Simple linear regression)\n\n\n\n\n\n\n\n\nPractice Problems #1 will be due on Friday, 9/13 at 5pm!\nFriday, 9/13 is also the add/drop deadline\nPreceptor office hours start this week–see the course calendar for times\n\n\n\n\nBefore class:\n\nComplete today’s checkpoint on Moodle\n\nDo either the readings or videos for the Day 3 Activity (see Moodle for links)\ndue 30 minutes before class on 9/10\n\n\n\n\n\nBefore class:\n\nComplete today’s checkpoint on Moodle\n\nDo either the readings or videos for the Day 4 Activity (see Moodle for links)\ndue 30 minutes before class on 9/12\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 3: 9/16 - 9/20 (Simple linear regression: model evaluation and variable transformations)\n\n\n\n\n\n\n\n\nPractice Problems #2 will be due Friday, 9/20 at 5pm\nReminder that preceptor office hours are held in the Sub-Hub (the glass room in the middle of the first floor of OLRI)\n\nsee Moodle for the preceptor office hours calendar, or add this calendar in your Mac Google account\n\nPlease remember to read your email 🥲\n\n\n\n\nBefore class:\n\nComplete the Project Preferences survey\nComplete today’s checkpoint on Moodle\n\nDo either the readings or videos for the Day 5 Activity (see Moodle for links)\ndue 30 minutes before class on 9/17\n\n\n\n\n\nBefore class:\n\nComplete today’s checkpoint on Moodle\n\nDo either the readings or videos for the Day 6 Activity (see Moodle for links)\n\nLibrary data discovery day!\n\n\n\n\n\n\n\n\n\n\n\nWeek 4: 9/23 - 9/27 (Simple linear regression: categorical predictors)\n\n\n\n\n\n\n\n\n\n\nBefore class:\n\nNo readings/videos/checkpoints for today!\n\n\n\n\n\nQuiz 1 today (1 hour in class)\n\n\n\n\n\n\n\n\n\n\n\nWeek 5: 9/30 - 10/4 (Multiple linear regression: confounding)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 6: 10/7 - 10/11 (Multiple linear regression: interaction)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 7: 10/14 - 10/18 (Multiple linear regression: model building) (Fall Break)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 8: 10/21 - 10/25 (Logistic regression)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 9: 10/28 - 11/1 (Tools for statistical inference)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 10: 11/4 - 11/8 (Confidence intervals)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 11: 11/11 - 11/15 (Hypothesis testing)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 12: 11/18 - 11/22 (Hypothesis testing)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 13: 11/25 - 11/29 (Hypothesis testing, p-values) (Thanksgiving Break)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 14: 12/2 - 12/6 (Project work)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 15: 12/9 - 12/13 (Project work, paper, and presentations)\n\n\n\n\n\n\n\n\n\n\n(Last day of class)\n\n\n\n\nIf you find any typos, bugs, dead links, or have other questions, please email jcarls13@macalester.edu"
  },
  {
    "objectID": "index.html#course-schedule-announcements",
    "href": "index.html#course-schedule-announcements",
    "title": "STAT 155: Introduction to Statistical Modeling",
    "section": "",
    "text": "Week 1: 9/2 - 9/6 (Data fundamentals, univariate visualization and summaries)\n\n\n\n\n\n\n\nWelcome (back) to campus!\n\n\n\nBefore class:\n\nreview the course syllabus\ncomplete the Introductions survey\ntry downloading R and RStudio\n\n\n\n\nBefore class:\n\nDownload and familiarize yourself with R and RStudio\nComplete the Introductions survey (if you haven’t already!)\nComplete today’s checkpoint on Moodle\n\nDo either the readings or videos for the Day 2 Activity (see Moodle for links)\ndue 30 minutes before class on 9/5\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 2: 9/9 - 9/13 (Simple linear regression)\n\n\n\n\n\n\n\n\nPractice Problems #1 will be due on Friday, 9/13 at 5pm!\nFriday, 9/13 is also the add/drop deadline\nPreceptor office hours start this week–see the course calendar for times\n\n\n\n\nBefore class:\n\nComplete today’s checkpoint on Moodle\n\nDo either the readings or videos for the Day 3 Activity (see Moodle for links)\ndue 30 minutes before class on 9/10\n\n\n\n\n\nBefore class:\n\nComplete today’s checkpoint on Moodle\n\nDo either the readings or videos for the Day 4 Activity (see Moodle for links)\ndue 30 minutes before class on 9/12\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 3: 9/16 - 9/20 (Simple linear regression: model evaluation and variable transformations)\n\n\n\n\n\n\n\n\nPractice Problems #2 will be due Friday, 9/20 at 5pm\nReminder that preceptor office hours are held in the Sub-Hub (the glass room in the middle of the first floor of OLRI)\n\nsee Moodle for the preceptor office hours calendar, or add this calendar in your Mac Google account\n\nPlease remember to read your email 🥲\n\n\n\n\nBefore class:\n\nComplete the Project Preferences survey\nComplete today’s checkpoint on Moodle\n\nDo either the readings or videos for the Day 5 Activity (see Moodle for links)\ndue 30 minutes before class on 9/17\n\n\n\n\n\nBefore class:\n\nComplete today’s checkpoint on Moodle\n\nDo either the readings or videos for the Day 6 Activity (see Moodle for links)\n\nLibrary data discovery day!\n\n\n\n\n\n\n\n\n\n\n\nWeek 4: 9/23 - 9/27 (Simple linear regression: categorical predictors)\n\n\n\n\n\n\n\n\n\n\nBefore class:\n\nNo readings/videos/checkpoints for today!\n\n\n\n\n\nQuiz 1 today (1 hour in class)\n\n\n\n\n\n\n\n\n\n\n\nWeek 5: 9/30 - 10/4 (Multiple linear regression: confounding)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 6: 10/7 - 10/11 (Multiple linear regression: interaction)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 7: 10/14 - 10/18 (Multiple linear regression: model building) (Fall Break)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 8: 10/21 - 10/25 (Logistic regression)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 9: 10/28 - 11/1 (Tools for statistical inference)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 10: 11/4 - 11/8 (Confidence intervals)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 11: 11/11 - 11/15 (Hypothesis testing)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 12: 11/18 - 11/22 (Hypothesis testing)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 13: 11/25 - 11/29 (Hypothesis testing, p-values) (Thanksgiving Break)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 14: 12/2 - 12/6 (Project work)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 15: 12/9 - 12/13 (Project work, paper, and presentations)\n\n\n\n\n\n\n\n\n\n\n(Last day of class)\n\n\n\n\nIf you find any typos, bugs, dead links, or have other questions, please email jcarls13@macalester.edu"
  },
  {
    "objectID": "activities/01_foundations_welcome.html",
    "href": "activities/01_foundations_welcome.html",
    "title": "Collecting and Summarizing Data",
    "section": "",
    "text": "Welcome to our first in-class activity! Today we will collect and summarize some data. Our goals are to get to know the people in this class and to start working with data.\nBy the end of this lesson, you should be able to:\n\nDefine cases and variables\nApply the 5 W’s + H (who, what, when, where, why, and how) to data collection\n\nLinks to related reading(s):\n\nWhat is Data?\nData Context\n\nThis activity is structured a bit differently than the activities for the remainder of the class. In this section, you’ll typically find a mini-lecture, review material, or guided / structural examples, followed by exercises.\nFor today, you’ll have some steps to follow for an interactive, tactile activity at your tables before working through the exercises below together.\n\n\nAt your table, write a one to two word answer to each of the following 7 question(s), each on a separate post-it note (do this individually). If there are two questions: write your answer to the first question on the left-hand side of the post-it note, and your answer to the second question on the bottom of the post-it note.\n\nHow many hours of sleep did you get last night? How many cups of coffee did you drink this morning?\nWhat is your declared or potential major? (If you are a double major, just pick whichever one you think of first.)\nWhat is your class year? (first year, sophomore, junior, senior)\nHow many stats courses have you taken in the past?\nOn a scale of 1 (get me out of here) to 10 (yay!), how excited are you about this course?\nIs it your birthday this semester? (yes/no)\nHow many unread emails do you have in your inbox right now?\nHave you used R/RStudio a lot, a little, or never?\n\n\n\n\nDesignate one person from your table to distribute your group’s answers to the questions to the corresponding “station” around the classroom. Each table should have a number on it, corresponding to the “station”/question.\n\n\n\nFill out an electronic version of these questions. We’ll come back to this in a future class. Wait until everyone in your group is done with this before moving on to the exercises.",
    "crumbs": [
      "Collecting and Summarizing Data"
    ]
  },
  {
    "objectID": "activities/01_foundations_welcome.html#step-1",
    "href": "activities/01_foundations_welcome.html#step-1",
    "title": "Collecting and Summarizing Data",
    "section": "",
    "text": "At your table, write a one to two word answer to each of the following 7 question(s), each on a separate post-it note (do this individually). If there are two questions: write your answer to the first question on the left-hand side of the post-it note, and your answer to the second question on the bottom of the post-it note.\n\nHow many hours of sleep did you get last night? How many cups of coffee did you drink this morning?\nWhat is your declared or potential major? (If you are a double major, just pick whichever one you think of first.)\nWhat is your class year? (first year, sophomore, junior, senior)\nHow many stats courses have you taken in the past?\nOn a scale of 1 (get me out of here) to 10 (yay!), how excited are you about this course?\nIs it your birthday this semester? (yes/no)\nHow many unread emails do you have in your inbox right now?\nHave you used R/RStudio a lot, a little, or never?",
    "crumbs": [
      "Collecting and Summarizing Data"
    ]
  },
  {
    "objectID": "activities/01_foundations_welcome.html#step-2",
    "href": "activities/01_foundations_welcome.html#step-2",
    "title": "Collecting and Summarizing Data",
    "section": "",
    "text": "Designate one person from your table to distribute your group’s answers to the questions to the corresponding “station” around the classroom. Each table should have a number on it, corresponding to the “station”/question.",
    "crumbs": [
      "Collecting and Summarizing Data"
    ]
  },
  {
    "objectID": "activities/01_foundations_welcome.html#step-3",
    "href": "activities/01_foundations_welcome.html#step-3",
    "title": "Collecting and Summarizing Data",
    "section": "",
    "text": "Fill out an electronic version of these questions. We’ll come back to this in a future class. Wait until everyone in your group is done with this before moving on to the exercises.",
    "crumbs": [
      "Collecting and Summarizing Data"
    ]
  },
  {
    "objectID": "activities/01_foundations_welcome.html#exercise-1",
    "href": "activities/01_foundations_welcome.html#exercise-1",
    "title": "Collecting and Summarizing Data",
    "section": "Exercise 1",
    "text": "Exercise 1\nWith your group, in no more than two sentences per question, respond to the questions posed by the 5 W’s + H for the data at your group’s table. If you need a refresher on the 5 W’s + H, check out the related readings posted at the top of this activity!\nWho\n\nResponse: Type your response here.\n\nWhat\n\nResponse: Type your response here.\n\nWhen\n\nResponse: Type your response here.\n\nWhere\n\nResponse: Type your response here.\n\nWhy\n\nResponse: Type your response here.\n\nHow\n\nResponse: Type your response here.",
    "crumbs": [
      "Collecting and Summarizing Data"
    ]
  },
  {
    "objectID": "activities/01_foundations_welcome.html#exercise-2",
    "href": "activities/01_foundations_welcome.html#exercise-2",
    "title": "Collecting and Summarizing Data",
    "section": "Exercise 2",
    "text": "Exercise 2\nMove the post-it notes around to construct a visualization of the responses at your station.",
    "crumbs": [
      "Collecting and Summarizing Data"
    ]
  },
  {
    "objectID": "activities/01_foundations_welcome.html#exercise-3",
    "href": "activities/01_foundations_welcome.html#exercise-3",
    "title": "Collecting and Summarizing Data",
    "section": "Exercise 3",
    "text": "Exercise 3\nCalculate at least one numerical summary of the post-it note responses at your station, and record your numerical summary in the response text below. Write a complete sentence, not just the numerical summary alone! This is good practice for summarizing data in more formal writing.\n\nResponse: Type your response here.",
    "crumbs": [
      "Collecting and Summarizing Data"
    ]
  },
  {
    "objectID": "activities/01_foundations_welcome.html#exercise-4",
    "href": "activities/01_foundations_welcome.html#exercise-4",
    "title": "Collecting and Summarizing Data",
    "section": "Exercise 4",
    "text": "Exercise 4\nIn no more than three sentences, describe what you learn about from the visual and numerical summaries. Try to write your description in a way that tells an interesting story about the people in this class.\n\nResponse: Type your response here.",
    "crumbs": [
      "Collecting and Summarizing Data"
    ]
  },
  {
    "objectID": "activities/01_foundations_welcome.html#exercise-5",
    "href": "activities/01_foundations_welcome.html#exercise-5",
    "title": "Collecting and Summarizing Data",
    "section": "Exercise 5",
    "text": "Exercise 5\nImagine that you took all the post-it notes in this room and organized them into a spreadsheet. What would each row in the underlying data set represent? What would each column of the data set represent? Check out the first related reading, linked at the top of this activity, if you need assistance!\n\nResponse: Type your response here.",
    "crumbs": [
      "Collecting and Summarizing Data"
    ]
  },
  {
    "objectID": "activities/01_foundations_welcome.html#reflection",
    "href": "activities/01_foundations_welcome.html#reflection",
    "title": "Collecting and Summarizing Data",
    "section": "Reflection",
    "text": "Reflection\nIn three to four sentences, reflect upon today’s activity. Some reflection prompts are found below:\n\nDo you think the context in which the data was collected influenced the results you found?\nWho would the numerical summaries you calculated potentially be represented of? Could you generalize the information you learned to a broader population (all students at Mac, perhaps), or would you have ethical concerns with generalizing your results?\nWhat (if anything) surprised you about the numerical summaries calculated by your group, or other groups?\nDid your data visualization help you better understand, or discover new things about the data that otherwise would have been difficult to distinguish? Why or why not?\n\n\nResponse: Type your response here.",
    "crumbs": [
      "Collecting and Summarizing Data"
    ]
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "Practice Problems",
    "section": "",
    "text": "…due Fridays at 5pm Central on Moodle!\n\nPractice Problems 1, due 9/13\nPractice Problems 2, due 9/20\nPractice Problems 3, due 10/4\nPractice Problems 4, due 10/11\nPractice Problems 5, due 10/25\nPractice Problems 6, due 11/8\nPractice Problems 7, due 11/15\nPractice Problems 8, due 11/22"
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Project",
    "section": "",
    "text": "As noted in the syllabus, a detailed description of the group project can be found here. Important dates and additional information are listed below.\n\nImportant Dates\nDetails coming soon!\n\n\nGrading\nThe final draft will be graded using the rubric found here. Although the first two checkpoints will not directly contribute to your course grade, the feedback they allow me to provide will ensure the success of your final draft!\n\n\nResources\nLater in the semester, I will post at least one example of a successful final draft, as well as a google doc template for the final draft.\n\n\nProject Groups\nProject groups will ultimately be determined by me, with the assistance of a Project Group Preferences survey. The survey will be sent out early in the semester (exact date TBD) and will allow you to either list people you would like to be in a group with or specify that you would like to be placed in a group randomly by me. I will do my best to ensure that groups are constructed as closely to survey responses as possible. Since one component of the project involves an in-class presentation, you may not work with students in different sections on the project.\nIf for any reason there is an individual (or individuals) with whom you do not feel safe participating in a project group with, there will be a space to note this on the survey. You will not be expected to provide any justification for your response to this question, but note that as I need to place you in groups, the survey will not be anonymous.\nGroup work and collaboration are important components of nearly all statistical analyses and projects. I recognize that individual contributions to a group project are not always consistent between group members. To this end, you will (as a group) be expected to explicitly specify the project tasks completed by each team member along with the final draft of your paper.\nIf there are any concerns with project groups throughout the semester, I am happy to meet with groups or individuals to discuss ways to move forward."
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": " ",
    "section": "",
    "text": "Macalester College, Fall 2024\n\nSection 05: Tu/Th 1:20-2:50pm, THTR 202\nSection 06: Tu/Th 3:00-4:30pm, THTR 202\n\n\n\n\nJedidiah (Jed) Carlson, PhD\nPronouns: he/him\nPronunciation: listen here\nOffice: Olin-Rice 235\nWebsite: https://jedidiahcarlson.com\nEmail: jcarls13@macalester.edu\n\n\n\n\n\n\nCall me “Jed”\n\n\n\nYou may call me (in order of my personal preference), Jed, Professor Carlson, or Dr. Carlson–but please use whichever of these options you are most comfortable with!\n\n\nDrop-in (office) hours:\n\nlocation: My office (OLRI 235)\ntimes: See this calendar (Generally from 10am-12pm on Wednesdays and 10am-11am on Thursdays, but subject to change).\n1:1 appointments: I’m also happy to meet one-on-one if my normal drop-in hours don’t work for you. You can schedule a time to meet with me using this link.\n\n\n\n\nThis course provides an introduction to statistical modeling. In other words, you will develop the basic skills to analyze data, test research hypotheses, and make predictions about the world.\nBeing able to summarize, interpret, and communicate about data are crucial for navigating today’s information landscape, and these are precisely the skills that we’ll build in this class. Throughout the semester, we’ll study the fundamental methods that statisticians use to extract knowledge from data, emphasizing statistical literacy & intuition, real data applications, and modern computing over memorizing facts and formulas.\n\n\nBy actively participating in this course, you will develop and/or strengthen your abilities to:\n\nVisualize: explore, understand, and describe patterns in data with plots and graphics\nModel: build, interpret, and evaluate statistical models to identify trends in data\nInfer: extend observations from sample data to draw conclusions and make predictions\nCompute: use the (free!) statistical software R to analyze real data and create reproducible reports\nContextualize: interpret results in context, by considering the methods of data collection, the scientific and social contexts, and ethical dimensions\nCommunicate: accurately describe methods and results in a way that is scientifically sound and widely accessible\nCollaborate: work productively and effectively in a group setting\n\n\n\n\n\n\nThere is no required textbook for this course. Throughout the course, readings may be assigned from these notes, or other sources. All links and materials needed will be provided on the home page of this website.\nThe best resources for this course are course content videos, attending and participating in class / assignments, and office hours. I am happy to talk about possible additional materials / strategies for effective learning at any time throughout the semester!\n\n\n\nWe will use the (completely free and open source) R programming language extensively throughout this course. RStudio (an interface for R) will facilitate our use of R. You may use RStudio in one of two ways:\n\nDesktop version: Download for Windows or Mac at https://posit.co/downloads/. Note: You first need to download and install R on your computer in order to use the desktop version of RStudio\nOnline: Go to https://rstudio.macalester.edu, and log in with your full Mac email address and your usual Mac password to get access. (Note that this is a shared resource across MSCS, and you may experience performance issues due to high traffic, server outages, etc.)\n\nMore detailed instructions on downloading, installing, and getting started with R, RStudio, and an important package called Quarto is available on the Tech Setup tab.\n\n\n\n\nWhen taking a new course, figuring out the right workflow/cadence of effort throughout the week can be a big adjustment. And most of you are doing this for 4 different courses! Below are some suggestions for what to expect in the course and how to focus your time and attention during and outside of class.\n\n\nPre-class videos/readings: Some class periods will have required videos or reading to get acquainted with new concepts before seeing them again in class. My goal for these videos and readings is for you to get the most out of class time by being able to more easily follow explanations in class and to engage most fully in class activities. When there are required readings or videos, there will be an associated checkpoint to complete on Moodle (due 30 minutes before the start of the next class).\n\n\n\n\n\n\nSuggestions\n\n\n\n\nAs you take notes on videos/readings, highlight or otherwise mark all the areas where you have questions. Gather up all of these questions in one place, and bring them to class with you.\nRecord any reflections from in-class time about your learning process or interactions with peers while they are still fresh.\nAfter learning a new topic in class, it is helpful to attempt the upcoming assignment as soon as possible. Just by getting some rough ideas down quickly, you avoid the difficulty of starting from a blank slate.\nCome to instructor and preceptor drop-in hours (office hours) to chat about the course or anything else!\n\n\n\n\n\n\nClass time will be a mix of interactive lecture and longer stretches of group work. During the lecture portion, I will pause explanation frequently to prompt a short exercise or ask questions that you’ll reflect on individually or together.\n\n\n\n\n\n\nSuggestions\n\n\n\n\nAs we review the material at the start of class and as you work on the class activity, reference your set of questions from the pre-class material. Have you made progress on addressing those questions? Who or what helped with improving your understanding, and how?"
  },
  {
    "objectID": "syllabus.html#your-instructor",
    "href": "syllabus.html#your-instructor",
    "title": " ",
    "section": "",
    "text": "Jedidiah (Jed) Carlson, PhD\nPronouns: he/him\nPronunciation: listen here\nOffice: Olin-Rice 235\nWebsite: https://jedidiahcarlson.com\nEmail: jcarls13@macalester.edu\n\n\n\n\n\n\nCall me “Jed”\n\n\n\nYou may call me (in order of my personal preference), Jed, Professor Carlson, or Dr. Carlson–but please use whichever of these options you are most comfortable with!\n\n\nDrop-in (office) hours:\n\nlocation: My office (OLRI 235)\ntimes: See this calendar (Generally from 10am-12pm on Wednesdays and 10am-11am on Thursdays, but subject to change).\n1:1 appointments: I’m also happy to meet one-on-one if my normal drop-in hours don’t work for you. You can schedule a time to meet with me using this link."
  },
  {
    "objectID": "syllabus.html#overview",
    "href": "syllabus.html#overview",
    "title": " ",
    "section": "",
    "text": "This course provides an introduction to statistical modeling. In other words, you will develop the basic skills to analyze data, test research hypotheses, and make predictions about the world.\nBeing able to summarize, interpret, and communicate about data are crucial for navigating today’s information landscape, and these are precisely the skills that we’ll build in this class. Throughout the semester, we’ll study the fundamental methods that statisticians use to extract knowledge from data, emphasizing statistical literacy & intuition, real data applications, and modern computing over memorizing facts and formulas.\n\n\nBy actively participating in this course, you will develop and/or strengthen your abilities to:\n\nVisualize: explore, understand, and describe patterns in data with plots and graphics\nModel: build, interpret, and evaluate statistical models to identify trends in data\nInfer: extend observations from sample data to draw conclusions and make predictions\nCompute: use the (free!) statistical software R to analyze real data and create reproducible reports\nContextualize: interpret results in context, by considering the methods of data collection, the scientific and social contexts, and ethical dimensions\nCommunicate: accurately describe methods and results in a way that is scientifically sound and widely accessible\nCollaborate: work productively and effectively in a group setting\n\n\n\n\n\n\nThere is no required textbook for this course. Throughout the course, readings may be assigned from these notes, or other sources. All links and materials needed will be provided on the home page of this website.\nThe best resources for this course are course content videos, attending and participating in class / assignments, and office hours. I am happy to talk about possible additional materials / strategies for effective learning at any time throughout the semester!\n\n\n\nWe will use the (completely free and open source) R programming language extensively throughout this course. RStudio (an interface for R) will facilitate our use of R. You may use RStudio in one of two ways:\n\nDesktop version: Download for Windows or Mac at https://posit.co/downloads/. Note: You first need to download and install R on your computer in order to use the desktop version of RStudio\nOnline: Go to https://rstudio.macalester.edu, and log in with your full Mac email address and your usual Mac password to get access. (Note that this is a shared resource across MSCS, and you may experience performance issues due to high traffic, server outages, etc.)\n\nMore detailed instructions on downloading, installing, and getting started with R, RStudio, and an important package called Quarto is available on the Tech Setup tab.\n\n\n\n\nWhen taking a new course, figuring out the right workflow/cadence of effort throughout the week can be a big adjustment. And most of you are doing this for 4 different courses! Below are some suggestions for what to expect in the course and how to focus your time and attention during and outside of class.\n\n\nPre-class videos/readings: Some class periods will have required videos or reading to get acquainted with new concepts before seeing them again in class. My goal for these videos and readings is for you to get the most out of class time by being able to more easily follow explanations in class and to engage most fully in class activities. When there are required readings or videos, there will be an associated checkpoint to complete on Moodle (due 30 minutes before the start of the next class).\n\n\n\n\n\n\nSuggestions\n\n\n\n\nAs you take notes on videos/readings, highlight or otherwise mark all the areas where you have questions. Gather up all of these questions in one place, and bring them to class with you.\nRecord any reflections from in-class time about your learning process or interactions with peers while they are still fresh.\nAfter learning a new topic in class, it is helpful to attempt the upcoming assignment as soon as possible. Just by getting some rough ideas down quickly, you avoid the difficulty of starting from a blank slate.\nCome to instructor and preceptor drop-in hours (office hours) to chat about the course or anything else!\n\n\n\n\n\n\nClass time will be a mix of interactive lecture and longer stretches of group work. During the lecture portion, I will pause explanation frequently to prompt a short exercise or ask questions that you’ll reflect on individually or together.\n\n\n\n\n\n\nSuggestions\n\n\n\n\nAs we review the material at the start of class and as you work on the class activity, reference your set of questions from the pre-class material. Have you made progress on addressing those questions? Who or what helped with improving your understanding, and how?"
  },
  {
    "objectID": "syllabus.html#course-website",
    "href": "syllabus.html#course-website",
    "title": " ",
    "section": "Course website",
    "text": "Course website\nAll course materials will be posted on the course website. The home tab of this website will contain information about due dates, in-class activities, and general day-to-day going-ons."
  },
  {
    "objectID": "syllabus.html#moodle",
    "href": "syllabus.html#moodle",
    "title": " ",
    "section": "Moodle",
    "text": "Moodle\nMoodle will be used to submit assignments/checkpoint quizzes, post grades, assignment feedback, announcements, and more. Please check the course Moodle page every day before class!"
  },
  {
    "objectID": "syllabus.html#email",
    "href": "syllabus.html#email",
    "title": " ",
    "section": "Email",
    "text": "Email\nPlease send any personal questions or administrative updates (e.g., attendance, accommodations) to me via email. Please put “STAT 155” in the subject line of all emails to help ensure that it does not get lost in my inbox!\nI will generally not respond to emails outside of business hours (9am-5pm M-F). Please allow 1 business day for a response (e.g. an email sent on Friday may not get a response until the following Monday).\nAny urgent announcements (e.g. unexpected class cancellations, notice of modifications to assignments) will be made over email."
  },
  {
    "objectID": "syllabus.html#drop-in-office-hours",
    "href": "syllabus.html#drop-in-office-hours",
    "title": " ",
    "section": "Drop-in (office) hours",
    "text": "Drop-in (office) hours\nOffice hours are an open-ended time for you to go over coursework, clarify concepts, solicit my biased opinions sage wisdom on career planning/graduate school, discuss research/internship opportunities, find resources you need, or chat about life in general. To encourage attendance at office hours, there may be individual and/or collective incentives along the way and/or at the end of the semester, depending on how well you utilize office hours (but please be respectful of your peers and do not monopolize this time).\n\n\n\n\n\n\nFirst time office hours user?\n\n\n\nIf you are nervous about coming to office hours for the first time, I encourage you to come with a friend! (they don’t even have to be enrolled in STAT 155!). You may also find it useful to come prepared with a specific question or topic you would like to discuss (some examples here–and remember, it does not have to be about STAT 155 material!)."
  },
  {
    "objectID": "syllabus.html#preceptors",
    "href": "syllabus.html#preceptors",
    "title": " ",
    "section": "Preceptors",
    "text": "Preceptors\nWe are supported by 9 preceptors across the 6 sections of STAT 155 this semester. All MSCS courses will also share a dedicated R preceptor (Kyle Suelflow), who can help with any issues you have with your R code or RStudio configuration.\nSamina, Owen, and Rana will be the preceptors dedicated to grading practice problems in our section and will sometimes come to class to help with activities. Preceptor drop-in hours (office hours) will be shared across all sections of the course and posted on our course homepage.\n\nSamina Stack\nOwen Carr\nRana Rishmawi\nRyan Mickelborough\nIlhaan Dhegadub\nJulia Van Orman\nTanisha Dodla\nSydney Ohr\nLucas Nelson\nKyle Suelflow (R preceptor)\n\nIn addition, the Macalester Academic Excellence (MAX) Center provides tutoring for STAT 155. Check out their website for more information and their tutoring schedule."
  },
  {
    "objectID": "syllabus.html#assignments-and-assessments",
    "href": "syllabus.html#assignments-and-assessments",
    "title": " ",
    "section": "Assignments and assessments",
    "text": "Assignments and assessments\n\nCheckpoints\nFor class days where some reading and/or videos are required beforehand, there will be a short multiple-choice Moodle checkpoint due 30 minutes before class starts (12:50pm for Section 05, and 2:30pm for Section 06).\nYou can attempt a checkpoint question as many times as you want, but there is a 33% point deduction for each successive attempt on a question. For example, if your first attempt on a 1-point question is incorrect, the maximum possible score on that question is 0.67 points for the second attempt. On the third attempt, the maximum score is 0.33 points. No points are awarded for the 4th attempt and beyond.\n\n\nPractice problems\nTo practice concepts that we cover in class, there will be 8 weekly practice problems (PPs) due on Fridays at 5pm. (Note that if needed, extensions are possible—see the late work policy.)\nYou will receive qualitative feedback on all questions on these practice problem sets. These assignments will receive on overall score on the following scale:\n\nHigh pass: 2 points\nPass: 1 point\nNeeds improvement: 0 points\n\nShowing growth: If, on a quiz, you demonstrate stronger understanding of the concepts that you missed on a PP, you have the chance to earn a higher score on the PP. Either via email or through an in-person conversation with the instructor, you must discuss how your understanding of the concept(s) changed from the PP to the quiz by addressing feedback from both the PP and the quiz. You can do this once for each quiz (excluding the final), and you can show improvement on multiple PPs using a single quiz.\n\n\nQuizzes\nThere will be 3 quizzes over the course of the semester.\n\nQuiz 1: Thursday, 9/26. 1 hour in class.\nQuiz 2: Thursday, 10/31. 1 hour in class. Will cover material from the first quiz to some extent because of the way that material in this course builds on earlier ideas.\nQuiz 3: ~1.25 hours during our final exam slot. Will cover content from the whole course.\n\nSection 05: Saturday, 12/14 1:30-3:30pm. Section 06: Monday, 12/16 1:30-3:30pm.\nEach quiz question will be graded on the following scale:\n\n3 points: fully correct\n2 points: mostly correct with minor errors\n1 point: missing key understanding\n0 points: fully off target or blank\n\nQuiz format:\n\nFully pen/pencil and paper. You will not need to write code or use a calculator, but you will need to be able to read and interpret output from R code.\nYou are allowed to bring a 3x5 index card with notes written on both sides. Typing your notes and pasting them on the card is fine.\n\nShowing growth: You can earn up to 50% of missed points back on quizzes if you complete a quiz correction and reflection. You must:\n\nWrite a reflection of how you prepared for the quiz and where you felt strongest and more uncertain in your understanding before taking the quiz\nSchedule a meeting with the instructor. During our conversation, you will correct your quiz responses and discuss the above reflection. You will get immediate feedback at this meeting. Use my appointment booking link to schedule this meeting.\n\n\n\nProject\nThe goal of the course project is to apply the data analysis skills from our course to investigate a research question in a dataset of your choosing. Through milestones over the course of the semester, you will make steady progress on your projects and iterate on feedback. Full details about the project will be available on the Project page."
  },
  {
    "objectID": "syllabus.html#course-grading-system",
    "href": "syllabus.html#course-grading-system",
    "title": " ",
    "section": "Course grading system",
    "text": "Course grading system\nIn order to earn a given letter grade, all requirements listed under that column need to be met.\n\n\n\n\n\n\n\n\n\n\n\n\nGrade: A\nGrade: B\nGrade: C\n\n\n\n\nCheckpoint average\n≥ 80%\n≥ 70%\n≥ 60%\n\n\nPractice problems (PPs)\n14 out of 16 points across all 8 PPs.\nMust submit all 8 PPs.\n12 out of 16 points across all 8 PPs.\n10 out of 16 points across all 8 PPs.\n\n\nQuiz average\n≥ 90%\n≥ 80%\n≥ 70%\n\n\nProject\nEarn highest level (Excellent) on all 6 rubric categories\nEarn highest level (Excellent) on all but 1 rubric category\nEarn highest level (Excellent) on all but 2 rubric categories\n\n\n\nIf your work for different course components falls under different letter grades, your final letter grade will be an “average” of the letter grades for the different components.\nC  C  C  C --&gt; C\nC  C  C  B --&gt; C+\nC  C  C  A --&gt; C+\nC  C  B  B --&gt; B-\nC  C  B  A --&gt; B-\nC  C  A  A --&gt; B\nC  B  B  B --&gt; B-\nC  B  B  A --&gt; B\nC  B  A  A --&gt; B+\nC  A  A  A --&gt; B+\nB  B  B  B --&gt; B\nB  B  B  A --&gt; B+\nB  B  A  A --&gt; A-\nB  A  A  A --&gt; A-\nA  A  A  A --&gt; A"
  },
  {
    "objectID": "syllabus.html#attendance",
    "href": "syllabus.html#attendance",
    "title": " ",
    "section": "Attendance",
    "text": "Attendance\nAttendance is not (directly) a part of your grade–I recognize that some students may learn more effectively when working through the material independently, and mandating attendance can create a barrier to accessibility. However, because this course is designed to be interactive and community-oriented, regular attendance will likely improve your experience and help you get the most out of the course (remember, that encompasses lots of intangibles and is more than just your final grade!).\nNote that I will still take attendance each class period–this is strictly for my own record-keeping and to ensure you are staying connected and have all have the resources you need to succeed. If you do miss class, I expect you to complete the in-class activity on your own. Check the solutions in the online manual and come to office hours with any follow-up questions."
  },
  {
    "objectID": "syllabus.html#late-work",
    "href": "syllabus.html#late-work",
    "title": " ",
    "section": "Late work",
    "text": "Late work\nHomework assignments will generally be due weekly on Fridays at 5pm.\nThroughout the semester, you may use up to three self-set extensions on practice problems. These three extensions can be used on practice problems only, not checkpoints or quizzes. The purpose of deadlines (and extensions) is to keep you accountable for your own learning, to keep you on track with the pace of the course (which builds upon itself throughout the semester), and to provide preceptors and myself the ability to give you timely feedback on assignments.\nIn order to use an extension, you must email me (jcarls13@macalester.edu) before the practice problem deadline to inform me you plan to use an extension. In your email, please specify (1) that you are using an extension, and (2) your self-set deadline is for the assignment. You do not need to specify a reason. For example, you could say “I am using my second extension. I will have Practice Problems #7 in by 5:00pm two days from now.” Once you set your deadline, I expect you to stick to it. If you do not e-mail me prior to the practice problem deadline, the extension will not be counted, and your assignment will be counted as late. Late homework without prior communication receives no credit.\nIf you have run out of extensions and/or an extenuating circumstance occurs that impacts your ability to submit assignments on time, please email me to discuss the situation. I am happy to be flexible as long as you communicate!"
  },
  {
    "objectID": "syllabus.html#religious-observance",
    "href": "syllabus.html#religious-observance",
    "title": " ",
    "section": "Religious Observance",
    "text": "Religious Observance\nStudents may wish to take part in religious observances that occur during the semester. If you have a religious observance/practice that conflicts with your participation in the course, please contact me before the end of the second week of the semester to discuss appropriate accommodations.\nIn an effort to respect religious diversity, I request that students who plan to observe a religious holiday that conflicts with class meetings or class requirements talk to me about reasonable consideration by the end of the second week of the course."
  },
  {
    "objectID": "syllabus.html#academic-integrity",
    "href": "syllabus.html#academic-integrity",
    "title": " ",
    "section": "Academic integrity",
    "text": "Academic integrity\nAcademic integrity is the cornerstone of our learning community. Students are expected to be familiar with the college’s standards on academic integrity.\nI encourage you to work with your classmates to discuss material and ideas for assignments, but in order for you to receive individualized feedback on your own learning, you must submit your own work. This involves writing your own code and putting explanations into your own words. Always cite any sources you use, including AI (see section below)."
  },
  {
    "objectID": "syllabus.html#artificial-intelligence-ai-use",
    "href": "syllabus.html#artificial-intelligence-ai-use",
    "title": " ",
    "section": "Artificial Intelligence (AI) Use",
    "text": "Artificial Intelligence (AI) Use\nSome of you may actively use (or be interested in using) Generative AI tools (ChatGPT, Google Gemini, Claude, etc.) to find/synthesize information or augment your writing/coding. Building literacy with how these tools work may be extremely important in your future for economic reasons (job skills) as well as cultural ones (meme skills).\nHowever, in an introductory course like this one, I strongly discourage the use of AI, for three main reasons:\n\nWe are learning the essentials of a new language and way of thinking. My mandate as an educator is to help build new neural networks in your own squishy, magnificent brains that cost $0, take up about 1.3 liters of space, and consume 20 watts of energy, not in a $100 billion, 1000-acre supercomputing cluster that consumes 5 gigawatts of energy.\nI care much more about developing your ability to identify interesting problems, iteratively seek a solution, and convince the world that your solution works than I do about your ability to find answers that are already known (using AI or otherwise). Remember that “generative” AI is only capable of remixing existing information–it cannot create new knowledge, situate that knowledge in the context of your lived experience, or instigate change.\nIn this course, I hope to emphasize the importance of process over output. Consider an analogy of a painting class at Macalester. You’re a novice painter, but you have a strong point of view and a solid understanding of context and tradition, so you decide to write an AI prompt to generate the artwork and translate it to physical media. After lots of wordsmithing and iterations on Midjourney, your AI-generated image ready. It’s provocative and beautiful…it will look even better on canvas! You get to work, admiring yourself for finishing faster than your classmates because you knew exactly what your final product would look like. You step back to admire your masterpiece, and realize it’s at best a paint-by-numbers, and at worst, complete garbage because you were so focused on crafting the perfect AI prompt that you didn’t really learn how to mix colors or use different brush techniques.\n\nLearning how to do something the “long” or “hard” way is beneficial not only for developing critical thinking skills, but because that process can be enriching and fulfilling in its own right. Though AI can (sometimes) put access to answers at your fingertips, it cannot replace the physical, sensory, and emotional experience of sketching out ideas on a whiteboard with friends, stopping by your professor’s office for a donut, or the satisfaction of knowing that you can do something hard from scratch.\nIn addition, please be aware of the many technical limitations and ethical considerations of using AI:\n\nAI does not always generate accurate output. If it gives you a number, fact, or code, assume it is wrong unless you either know the answer or can check in with another source. AI works best for topics you already understand to a sufficient extent.\nIf you provide minimum effort prompts, you will get low quality results. You will need to refine your prompts in order to get good outcomes. This will take work.\nBe thoughtful about when this tool is useful. Don’t use it if it isn’t appropriate for the case or circumstance.\nThe environmental impact of AI should not be ignored. The building and usage of AI tools consumes a lot of energy (see here and here). For this reason, we will be very thoughtful about when we use AI and will discuss other sustainability behaviors that we can incorporate into our lives to offset this usage.\n\nAll of that being said, I cannot (nor do I want to) enforce my personal perspective on students who wish to use AI to enhance their learning. If you do choose to use AI, any ideas, language, or code that is produced by AI must be cited, just like any other resource. - How to cite AI: If you have used AI in any assignment, please include a paragraph at the end explaining what you used the AI for and what prompts you used to get the results. Failure to do so is in violation of the academic integrity policy at Macalester College.\nIf you have any questions about your use of AI tools, please contact me to discuss them."
  },
  {
    "objectID": "syllabus.html#well-being",
    "href": "syllabus.html#well-being",
    "title": " ",
    "section": "Well-being",
    "text": "Well-being\nI want you to succeed. Both here at Macalester and beyond. To help make this happen, I am committed to the following.\nRespect: Everyone comes from a different path through life, and it is our moral duty as human beings to listen to each other without judgment and to respect one another. I have no tolerance for discrimination of any kind, in and out of the classroom. If you are seeking campus resources regarding discrimination, the Department of Multicultural Life and the Center for Religious and Spiritual Life are wonderful resources. We will also respect the MSCS Community Guidelines.\nSensitive Topics: Applications in this course span issues in science, policy, and society. As such, we may sometimes address topics that are sensitive for you. I will try to announce in class if an assignment or activity involves a potentially sensitive topic. If you have reservations about a particular topic, please come talk to me to discuss possible options.\nAccommodations: If you need accommodations for any reason, please contact Disability Services to discuss your needs, and speak with me as soon as possible afterwards so that we can discuss your accommodation plan. If you already have official accommodations, please discuss these with me within the first week of class so that you get off to a great start. Contact me if you have other special circumstances. I will find resources for you.\nTitle IX: You deserve a community free from discrimination, sexual harassment, hostility, sexual assault, domestic violence, dating violence, and stalking. If you or anyone you know has experienced harassment or discrimination, know that you are not alone. Macalester provides staff and resources to help you find support. Please be aware that as a faculty member, it is my responsibility to report disclosure about sexual harassment, sexual misconduct, relationship violence, and stalking to the Title IX Office. The purpose of this report is to ensure that anyone experiencing harm receives the resources and support they need. I will keep this information private, and it will not be shared beyond this required report.\nYou may also contact Macalester’s Title IX Coordinator directly (phone: 651-696-6258; e-mail: titleixcordinator@macalester.edu); they will provide you with supportive measures, resources, and referrals. Additional information about how to file a report (including anonymously) is available on the Title IX website.\nGeneral Health and Well-being: I care that you prioritize your well-being in this semester and beyond. Investing time into taking care of yourself will have profound impacts on all aspects of your life. Remember that beyond being a student, you are a human being carrying your own experiences, thoughts, emotions, and identities. It is important to acknowledge any stressors you may be facing, which can be mental, emotional, physical, cultural, financial, etc., and how they can have an impact on you. I encourage you to remember that you have a body with needs. In the classroom, eat when you are hungry, drink water, use the restroom, and step out if you are upset and need some air. Please do what is necessary so long as it does not impede your or others’ ability to be mentally and emotionally present in the course. Outside of the classroom, sleeping well, moving your body, and connecting with others can be strategies can help nourish you. If you are having difficulties maintaining your well-being, please don’t hesitate to contact me and/or find support from physical and mental health resources here, here, and here."
  },
  {
    "objectID": "syllabus.html#you-belong-here",
    "href": "syllabus.html#you-belong-here",
    "title": " ",
    "section": "You belong here!",
    "text": "You belong here!\nStatistics–like most other areas of science–has a long history of excluding and exploiting people from marginalized communities and identities. Many of the earliest statisticians in the 19th and 20th centuries used and abused statistics to justify colonialism, ableism, classism, sexism, eugenics, and white supremacy.\nOn top of this, cultural norms around academic performance in quantitative disciplines can make courses like this one feel intimidating and exclusionary, rather than collaborative and interdisciplinary.\nTo counter these problematic aspects of the field, my central goal as an instructor is to intentionally foster community and connectedness. I believe that your unique voices and perspectives in this class will enrich our collective learning process and, in turn, your college experience. I encourage you to get to know your classmates (and me!) beyond a superficial familiarity and connect over our shared interests, identities, and ideas. You can help cultivate that community by being thoughtful about the way you engage with others and stretching your comfort zone to interact with people who are outside of your established social circles."
  },
  {
    "objectID": "syllabus.html#informed-skepticism",
    "href": "syllabus.html#informed-skepticism",
    "title": " ",
    "section": "Informed skepticism",
    "text": "Informed skepticism\nIn virtually all of contemporary Western science, statistical reasoning is foundational to establishing trust in scientific theories. However, it is shockingly common to come across results that are 1) not generalizable or cannot be replicated, 2) invalidated by honest coding/modeling mistakes, 3) based on deliberately cherry-picked models, or–in extreme cases–4) data that have been outright fabricated/falsified. Like in all aspects of life, trust in scientific claims must be earned.\nIn this course and beyond, I encourage you to approach any statistical results you encounter with a healthy skepticism, informed by both your gut intuition and the material you’ve learned. Know that you may be wrong (counter-intuitive results are abundant!) but you should always feel empowered to respectfully and rigorously challenge statistical claims."
  },
  {
    "objectID": "syllabus.html#a-commitment-to-ethical-deliberation-and-conduct",
    "href": "syllabus.html#a-commitment-to-ethical-deliberation-and-conduct",
    "title": " ",
    "section": "A commitment to ethical deliberation and conduct",
    "text": "A commitment to ethical deliberation and conduct\nBecause statistics is a way to make sense of the world around us, it is also a way to influence it. This comes with an inherent responsibility to grapple with the ethical and sociopolitical dimensions of the content in this course. This includes delving into the context of how methods were developed, questioning assumptions, and considering the potential for misuse and misinterpretation. Throughout the course, you will be challenged to consider the broader impact of your work: How might your results and interpretations directly or indirectly affect the environment, specific individuals, or human culture & society? Whose prior scientific contributions are you amplifying or ignoring? How do your assumptions and biases shape your scientific approach and communication?"
  },
  {
    "objectID": "syllabus.html#mistakes-and-uncertainty-are-essential",
    "href": "syllabus.html#mistakes-and-uncertainty-are-essential",
    "title": " ",
    "section": "Mistakes and uncertainty are essential",
    "text": "Mistakes and uncertainty are essential\nI expect that you and I will make lots of mistakes along the way in this course. Perhaps paradoxically, this is an important way to gain confidence: as we make mistakes, we will develop skills for recognizing and correcting them. These skills are vital for succeeding in STEM careers (and life in general). This course will provide a low-stakes environment for us to practice accountability, reflection, and troubleshooting when mistakes occur."
  },
  {
    "objectID": "syllabus.html#context-before-content",
    "href": "syllabus.html#context-before-content",
    "title": " ",
    "section": "Context before content",
    "text": "Context before content\nRigorous statistical reasoning demands that we understand the context of our data and our research questions before we run a model and obtain/interpret results. I also aim to be mindful of various other contexts that shape our learning experience: our individual identities/histories, the classroom environment, the campus climate, etc. Throughout the semester, we will create space to address and discuss whatever contexts might impact our ability to engage the material (and how they may even relate to the material!), whether it’s a flickering light in the classroom that’s distracting, a looming election, or anywhere in between."
  },
  {
    "objectID": "solutions/08_mlr_intro.html",
    "href": "solutions/08_mlr_intro.html",
    "title": "Introduction to multiple regression",
    "section": "",
    "text": "# Load packages\nlibrary(readr)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Load data\nlibrary(palmerpenguins)\ndata(penguins)\npenguins &lt;- penguins %&gt;% \n  filter(species != \"Adelie\", bill_length_mm &lt; 57)\n\n# Check it out\nhead(penguins)\n\n# A tibble: 6 × 8\n  species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;           &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Gentoo  Biscoe           46.1          13.2               211        4500\n2 Gentoo  Biscoe           50            16.3               230        5700\n3 Gentoo  Biscoe           48.7          14.1               210        4450\n4 Gentoo  Biscoe           50            15.2               218        5700\n5 Gentoo  Biscoe           47.6          14.5               215        5400\n6 Gentoo  Biscoe           46.5          13.5               210        4550\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;"
  },
  {
    "objectID": "solutions/08_mlr_intro.html#exercise-1-visualizing-the-relationship",
    "href": "solutions/08_mlr_intro.html#exercise-1-visualizing-the-relationship",
    "title": "Introduction to multiple regression",
    "section": "Exercise 1: Visualizing the relationship",
    "text": "Exercise 1: Visualizing the relationship\n\nno wrong answer\nThere are multiple options!\n\n\npenguins %&gt;% \n  ggplot(aes(y = flipper_length_mm, x = bill_length_mm, color = species)) + \n  geom_point()\n\n\n\n\n\n\n\npenguins %&gt;% \n  ggplot(aes(y = flipper_length_mm, x = bill_length_mm, shape = species)) + \n  geom_point()"
  },
  {
    "objectID": "solutions/08_mlr_intro.html#exercise-2-visualizing-the-model",
    "href": "solutions/08_mlr_intro.html#exercise-2-visualizing-the-model",
    "title": "Introduction to multiple regression",
    "section": "Exercise 2: Visualizing the model",
    "text": "Exercise 2: Visualizing the model\n\nno wrong answer\n\n\n\npenguins %&gt;% \n  ggplot(aes(y = flipper_length_mm, x = bill_length_mm, color = species)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "solutions/08_mlr_intro.html#exercise-3-intuition",
    "href": "solutions/08_mlr_intro.html#exercise-3-intuition",
    "title": "Introduction to multiple regression",
    "section": "Exercise 3: Intuition",
    "text": "Exercise 3: Intuition\n\nGentoo tend to have longer flippers.\nFlipper length is positively associated with bill length.\nNo. the lines are parallel / have the same slopes."
  },
  {
    "objectID": "solutions/08_mlr_intro.html#exercise-4-model-formula",
    "href": "solutions/08_mlr_intro.html#exercise-4-model-formula",
    "title": "Introduction to multiple regression",
    "section": "Exercise 4: Model formula",
    "text": "Exercise 4: Model formula\n\nbill_length_mm + species\nE[flipper_length_mm | bill_length_mm, speciesGentoo] = 127.75 + 1.40 * bill_length_mm + 22.85 * speciesGentoo\n\n\n# Build the model\npenguin_mod &lt;- lm(flipper_length_mm ~ bill_length_mm + species, data = penguins)\n\n# Summarize the model\ncoef(summary(penguin_mod))\n\n                 Estimate Std. Error  t value     Pr(&gt;|t|)\n(Intercept)    127.753693  6.1174521 20.88348 1.194472e-50\nbill_length_mm   1.402367  0.1249665 11.22194 1.194932e-22\nspeciesGentoo   22.848036  0.7938292 28.78206 1.981732e-70"
  },
  {
    "objectID": "solutions/08_mlr_intro.html#exercise-5-sub-model-formulas",
    "href": "solutions/08_mlr_intro.html#exercise-5-sub-model-formulas",
    "title": "Introduction to multiple regression",
    "section": "Exercise 5: Sub-model formulas",
    "text": "Exercise 5: Sub-model formulas\nChinstrap: flipper_length_mm = 127.75 + 1.40 bill_length_mm\nGentoo: flipper_length_mm = (127.75 + 22.85) + 1.40 bill_length_mm = 150.6 + 1.40 bill_length_mm"
  },
  {
    "objectID": "solutions/08_mlr_intro.html#exercise-6-coefficients-physical-interpretation",
    "href": "solutions/08_mlr_intro.html#exercise-6-coefficients-physical-interpretation",
    "title": "Introduction to multiple regression",
    "section": "Exercise 6: coefficients – physical interpretation",
    "text": "Exercise 6: coefficients – physical interpretation\n\nThe intercept coefficient, 127.75, is the intercept of the line for Chinstrap penguins.\nThe bill_length_mm coefficient, 1.40, is the slope of both lines.\nThe speciesGentoo coefficient, 22.85, indicates that the intercept of the line for Gentoo is 22.85mm higher than the intercept of the line for Chinstrap. Similarly, since the lines are parallel, the line for Gentoo is 22.85mm higher than the line for Chinstrap at any bill_length_mm."
  },
  {
    "objectID": "solutions/08_mlr_intro.html#exercise-7-coefficients-contextual-interpretation",
    "href": "solutions/08_mlr_intro.html#exercise-7-coefficients-contextual-interpretation",
    "title": "Introduction to multiple regression",
    "section": "Exercise 7: coefficients – contextual interpretation",
    "text": "Exercise 7: coefficients – contextual interpretation\n\nFor Chinstrap penguins with 0mm bills (silly), we expect a flipper length of 127.75mm.\nFor both Chinstrap and Gentoo penguins, flipper lengths increase by 1.40mm on average for every additional mm in bill length.\nAt any bill_length_mm, we expect the a Gentoo penguin to have 22.85mm longer flippers than a Chinstrap, on average."
  },
  {
    "objectID": "solutions/08_mlr_intro.html#exercise-8-prediction",
    "href": "solutions/08_mlr_intro.html#exercise-8-prediction",
    "title": "Introduction to multiple regression",
    "section": "Exercise 8: Prediction",
    "text": "Exercise 8: Prediction\n\n# a\n127.75 + 1.40*50 + 22.85*0\n\n[1] 197.75\n\n# b\n127.75 + 1.40*50 + 22.85*1\n\n[1] 220.6\n\n# c\npredict(penguin_mod,\n        newdata = data.frame(bill_length_mm = 50, \n                             species = \"Chinstrap\"))\n\n      1 \n197.872 \n\npredict(penguin_mod,\n        newdata = data.frame(bill_length_mm = 50, \n                             species = \"Gentoo\"))\n\n       1 \n220.7201"
  },
  {
    "objectID": "solutions/08_mlr_intro.html#exercise-9-r-squared",
    "href": "solutions/08_mlr_intro.html#exercise-9-r-squared",
    "title": "Introduction to multiple regression",
    "section": "Exercise 9: R-squared",
    "text": "Exercise 9: R-squared\n\nspecies\nno wrong answer\nIt’s higher than the R-squared when we use either predictor alone!"
  },
  {
    "objectID": "activities/05_slr_model_eval.html",
    "href": "activities/05_slr_model_eval.html",
    "title": "Simple linear regression: model evaluation",
    "section": "",
    "text": "Download the .qmd file for this activity here.\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder.\nOpen the qmd file in RStudio, and use it to type your answers/code to the exercises and reflection on the in-class activities.\n\n\n\nBy the end of this lesson, you should be able to:\n\nUse residual plots to evaluate the correctness of a model\nExplain the rationale for the R-squared metric of model strength\nInterpret the R-squared metric\nThink about ethical implications of modeling by examining the impacts of biased data, power dynamics, the role of categorization, and the role of emotion and lived experience\n\n\n\n\nRefer to the before-class reading or videos:\n\nReading: Sections 1.7, 3.7, and 3.8 in the STAT 155 Notes\nVideos:\n\nModel evaluation: is the model wrong? (slides)\nModel evaluation: is the model strong? (slides)\nModel evaluation: is the model fair? (slides)\nR Code for Evaluating and Using a Linear Model",
    "crumbs": [
      "Simple linear regression: model evaluation"
    ]
  },
  {
    "objectID": "activities/05_slr_model_eval.html#learning-goals",
    "href": "activities/05_slr_model_eval.html#learning-goals",
    "title": "Simple linear regression: model evaluation",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nUse residual plots to evaluate the correctness of a model\nExplain the rationale for the R-squared metric of model strength\nInterpret the R-squared metric\nThink about ethical implications of modeling by examining the impacts of biased data, power dynamics, the role of categorization, and the role of emotion and lived experience",
    "crumbs": [
      "Simple linear regression: model evaluation"
    ]
  },
  {
    "objectID": "activities/05_slr_model_eval.html#readings-and-videos",
    "href": "activities/05_slr_model_eval.html#readings-and-videos",
    "title": "Simple linear regression: model evaluation",
    "section": "",
    "text": "Refer to the before-class reading or videos:\n\nReading: Sections 1.7, 3.7, and 3.8 in the STAT 155 Notes\nVideos:\n\nModel evaluation: is the model wrong? (slides)\nModel evaluation: is the model strong? (slides)\nModel evaluation: is the model fair? (slides)\nR Code for Evaluating and Using a Linear Model",
    "crumbs": [
      "Simple linear regression: model evaluation"
    ]
  },
  {
    "objectID": "activities/05_slr_model_eval.html#exercise-1-is-the-model-correct",
    "href": "activities/05_slr_model_eval.html#exercise-1-is-the-model-correct",
    "title": "Simple linear regression: model evaluation",
    "section": "Exercise 1: Is the model correct?",
    "text": "Exercise 1: Is the model correct?\nWe previously explored modeling daily ridership among registered users as a function of temperature. Create a plot of this relationship with both a curved and linear trend line. Based on this plot, do you think a linear model is correct?\n\n# HINT CODE (don't write in this chunk)\n# Plot temp vs day_of_year with a model trend\n___(___, aes(x = ___, y = ___)) + \n    geom___() + \n    geom___(se = FALSE) +\n    geom___(method = \"lm\", se = FALSE, color = \"red\")\n\n\n# Solution\n# Plot riders_registered vs temp_feel with both a curved and linear trend",
    "crumbs": [
      "Simple linear regression: model evaluation"
    ]
  },
  {
    "objectID": "activities/05_slr_model_eval.html#exercise-2-fixing-the-model",
    "href": "activities/05_slr_model_eval.html#exercise-2-fixing-the-model",
    "title": "Simple linear regression: model evaluation",
    "section": "Exercise 2: Fixing the model",
    "text": "Exercise 2: Fixing the model\nIn this course, we have and will continue to build “linear” regression models. “Linear” means we have a linear combination of predictors. It does not mean that the models themselves must look linear! It’s possible to include “transformations” in our models in order to better match the trend. Below we create a squared version of temperature and visualize the predictions from 2 models: (1) with just temperature as a linear term and (2) with both temperature and squared temperature. (Don’t worry about the new syntax in geom_smooth().)\nHow does the quality (correctness) of the two models compare?\n\nbikes &lt;- bikes %&gt;% \n    mutate(temp_feel_squared = temp_feel^2)\n\n# Plot the model WITHOUT squared temperature\nggplot(bikes, aes(x = temp_feel, y = riders_registered)) + \n    geom_point() + \n    geom_smooth(se = FALSE) +\n    geom_smooth(method = \"lm\", se = FALSE, color = \"red\")\n# Plot the model WITH squared temperature\nggplot(bikes, aes(x = temp_feel, y = riders_registered)) + \n    geom_point() + \n    geom_smooth(se = FALSE) +\n    geom_smooth(method = \"lm\", formula = y ~ x + I(x^2), se = FALSE, color = \"red\")",
    "crumbs": [
      "Simple linear regression: model evaluation"
    ]
  },
  {
    "objectID": "activities/05_slr_model_eval.html#exercise-3-residual-plots",
    "href": "activities/05_slr_model_eval.html#exercise-3-residual-plots",
    "title": "Simple linear regression: model evaluation",
    "section": "Exercise 3: Residual plots",
    "text": "Exercise 3: Residual plots\nPlotting the residuals vs the predictions (also called “fitted values”) for each case can help us assess how wrong our model is. This will be a particularly important tool when evaluating models with multiple predictors. Construct the residual plots for our two temperature models. Do these suggest that bike_mod1 is wrong? What about bike_mod2? Explain.\nNote: Information about the residuals (.resid) and predictions (.fitted) are stored within our model, thus we start our ggplot() with the model name as opposed to the raw dataset. We will rarely start ggplot() with a model instead of the data.\n\n# Fit a linear model\nbike_mod1 &lt;- lm(riders_registered ~ temp_feel, data = bikes)\n# Fit a quadratic model\nbike_mod2 &lt;- lm(riders_registered ~ temp_feel + temp_feel_squared, data = bikes)\n\n# Check out the residual plot for bike_mod1 (the incorrect model)\nggplot(bike_mod1, aes(x = .fitted, y = .resid)) + \n    geom_point() + \n    geom_hline(yintercept = 0) +\n    geom_smooth(se = FALSE)\n\n# Construct the residual plot for bike_mod2 (the good model)",
    "crumbs": [
      "Simple linear regression: model evaluation"
    ]
  },
  {
    "objectID": "activities/05_slr_model_eval.html#exercise-4-another-example-of-an-incorrect-model",
    "href": "activities/05_slr_model_eval.html#exercise-4-another-example-of-an-incorrect-model",
    "title": "Simple linear regression: model evaluation",
    "section": "Exercise 4: Another example of an incorrect model",
    "text": "Exercise 4: Another example of an incorrect model\nThe Bechdel test is a test applied to films to assess the quality of women’s presence in the film. We’ll be looking at movies that have had the Bechdel test applied available in the fivethirtyeight R package. In the Console, enter install.packages(\"fivethirtyeight\") to install this package.\nWe’ll be using the bechdel data. You can view the codebook by entering ?bechdel in the Console.\nLet’s examine the relationship between international earnings (intgross) and movie budget (budget) for films made in 1997.\n\n# Import the data\nlibrary(fivethirtyeight)\ndata(bechdel)\n\n# Get only 1997 movies\nmovies_1997 &lt;- bechdel %&gt;% \n    filter(year == 1997)\n\n# Construct the model\nbechdel_model &lt;- lm(intgross ~ budget, movies_1997)\n\n\nConstruct two plots:\n\n\n# Scatterplot of earnings and budget with linear and curved trend lines\n\n\n# Residual plot for bechdel_model\n\n\nThese two plots confirm that our model is wrong. What is wrong and how might we fix it?\nIdentify which movie is causing the problem. Hint: filter() according to budget. Also, note that we could, but won’t, take that film out of the data set and re-build the model.\n\n\n# HINT CODE (do not write in this chunk)\n# NOTE: Many numbers could go in the ___\nmovies_1997 %&gt;%\n    filter(budget &gt; ___)\n\n\n# Your code",
    "crumbs": [
      "Simple linear regression: model evaluation"
    ]
  },
  {
    "objectID": "activities/05_slr_model_eval.html#exercise-5-is-the-model-strong-developing-r-squared-intuition",
    "href": "activities/05_slr_model_eval.html#exercise-5-is-the-model-strong-developing-r-squared-intuition",
    "title": "Simple linear regression: model evaluation",
    "section": "Exercise 5: Is the model strong? Developing R-squared intuition",
    "text": "Exercise 5: Is the model strong? Developing R-squared intuition\nThe R-squared metric is a way to quantify the strength of a model. It measures how much variation in the outcome/response variable can be explained by the model.\nWhere does R-squared come from? Well, it turns out that we can partition the variance of the observed response values into the variability that’s explained by the model (the variance of the predictions) and the variability that’s left unexplained by the model (the variance of the residuals):\n\\[\\text{Var(observed) = Var(predicted) + Var(residuals)}\\]\n“Good” models have residuals that don’t deviate far from 0. So the smaller the variance in the residuals (thus larger the variance in the predictions), the stronger the model. Take a look at the picture below and write a few sentences addressing the following:\n\nThe two rows of plots show a stronger and a weaker model. Just by looking at the blue trend line and the dispersion of the points about the line, which row corresponds to the stronger model? How can you tell? Which row would you expect to have a higher correlation?\nWhat is different about the variance of the residuals from the first to the second row?\n\n\nPutting this together, the R-squared compares Var(predicted) to Var(response):\n\\[R^2 = \\frac{\\text{variance of predicted values}}{\\text{variance of observed response values}} = 1 - \\frac{\\text{variance of residuals}}{\\text{variance of observed response values}}\\]",
    "crumbs": [
      "Simple linear regression: model evaluation"
    ]
  },
  {
    "objectID": "activities/05_slr_model_eval.html#exercise-6-further-exploring-r-squared",
    "href": "activities/05_slr_model_eval.html#exercise-6-further-exploring-r-squared",
    "title": "Simple linear regression: model evaluation",
    "section": "Exercise 6: Further exploring R-squared",
    "text": "Exercise 6: Further exploring R-squared\nIn this exercise, we’ll look at data from a synthetic dataset called Anscombe’s quartet. Load the data in as follows, and look at the first few rows:\n\ndata(anscombe)\n\n# Look at the first few rows\n\nThe anscombe data is actually 4 datasets in one: x1 and y1 go together, and so forth. Examine the coefficient estimates (in the “Estimate” column of the “Coefficients:” part) and the “Multiple R-squared” value on the second to last line. What do you notice? How do these models compare?\n\nanscombe_mod1 &lt;- lm(y1 ~ x1, data = anscombe)\nanscombe_mod2 &lt;- lm(y2 ~ x2, data = anscombe)\nanscombe_mod3 &lt;- lm(y3 ~ x3, data = anscombe)\nanscombe_mod4 &lt;- lm(y4 ~ x4, data = anscombe)\n\nsummary(anscombe_mod1)\nsummary(anscombe_mod2)\nsummary(anscombe_mod3)\nsummary(anscombe_mod4)\n\nNow take a look at the following scatterplots of the 4 pairs of variables. What do you notice? What takeaway can we draw from this exercise?\n\nggplot(anscombe, aes(x = x1, y = y1)) +\n    geom_point() + \n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\nggplot(anscombe, aes(x = x2, y = y2)) +\n    geom_point() + \n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\nggplot(anscombe, aes(x = x3, y = y3)) +\n    geom_point() + \n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\nggplot(anscombe, aes(x = x4, y = y4)) +\n    geom_point() + \n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE)",
    "crumbs": [
      "Simple linear regression: model evaluation"
    ]
  },
  {
    "objectID": "activities/05_slr_model_eval.html#exercise-7-biased-data-biased-results-example-1",
    "href": "activities/05_slr_model_eval.html#exercise-7-biased-data-biased-results-example-1",
    "title": "Simple linear regression: model evaluation",
    "section": "Exercise 7: Biased data, biased results: example 1",
    "text": "Exercise 7: Biased data, biased results: example 1\nDATA ARE NOT NEUTRAL. Data can reflect personal biases, institutional biases, power dynamics, societal biases, the limits of our knowledge, and so on. In turn, biased data can lead to biased analyses. Consider an example.\n\nDo a Google image search for “statistics professor.” What do you observe?\nThese search results are produced by a search algorithm / model. Explain why the data used by this model are not neutral.\nWhat are the potential implications, personal or societal, of the search results produced from this biased data?",
    "crumbs": [
      "Simple linear regression: model evaluation"
    ]
  },
  {
    "objectID": "activities/05_slr_model_eval.html#exercise-8-biased-data-biased-results-example-2",
    "href": "activities/05_slr_model_eval.html#exercise-8-biased-data-biased-results-example-2",
    "title": "Simple linear regression: model evaluation",
    "section": "Exercise 8: Biased data, biased results: example 2",
    "text": "Exercise 8: Biased data, biased results: example 2\nConsider the example of a large company that developed a model / algorithm to review the résumés of applicants for software developer & other tech positions. The model then gave each applicant a score indicating their hireability or potential for success at the company. You can think of this model as something like:\n\\[\\text{potential for success } = \\beta_0 + \\beta_1 (\\text{features from the résumé})\\]\nSkim this Reuter’s article about the company’s résumé model.\n\nExplain why the data used by this model are not neutral.\nWhat are the potential implications, personal or societal, of the results produced from this biased data?",
    "crumbs": [
      "Simple linear regression: model evaluation"
    ]
  },
  {
    "objectID": "activities/05_slr_model_eval.html#exercise-9-rigid-data-collection-systems",
    "href": "activities/05_slr_model_eval.html#exercise-9-rigid-data-collection-systems",
    "title": "Simple linear regression: model evaluation",
    "section": "Exercise 9: Rigid data collection systems",
    "text": "Exercise 9: Rigid data collection systems\nWhen working with categorical variables, we’ve seen that our units of observation fall into neat groups. Reality isn’t so discrete. For example, check out questions 6 and 9 on page 2 of the 2020 US Census. With your group, discuss the following:\n\nWhat are a couple of issues you see with these questions?\nWhat impact might this type of data collection have on a subsequent analysis of the census responses and the policies it might inform?\nCan you think of a better way to write these questions while still preserving the privacy of respondents?\n\nFOR A DEEPER DISCUSSION: Read Chapter 4 of Data Feminism on “What gets counted counts”.",
    "crumbs": [
      "Simple linear regression: model evaluation"
    ]
  },
  {
    "objectID": "activities/05_slr_model_eval.html#exercise-10-presenting-data-elevating-emotion-and-embodiment",
    "href": "activities/05_slr_model_eval.html#exercise-10-presenting-data-elevating-emotion-and-embodiment",
    "title": "Simple linear regression: model evaluation",
    "section": "Exercise 10: Presenting data: “Elevating emotion and embodiment”",
    "text": "Exercise 10: Presenting data: “Elevating emotion and embodiment”\nNote: The following example highlights work done by W.E.B. Du Bois in the late 1800s / early 1900s. His work uses language common to that time period and addresses the topic of slavery.\nThe types of visualizations we’ve been learning in this course are standard practice, hence widely understood. Yet these standard visualizations can also suppress the lived experiences of people represented in the data, hence can miss the larger point. W.E.B. Du Bois (1868–1963), a “sociologist, socialist, historian, civil rights activist, Pan-Africanist, author, writer, and editor”1, was a pioneer in elevating emotion and embodiment in data visualization. For the Paris World Fair of 1900, Du Bois and his team of students from Atlanta University presented 60 data visualizations of the Black experience in America, less than 50 years after the abolishment of slavery. To this end, Du Bois noted that “I wanted to set down its aim and method in some outstanding way which would bring my work to notice by the thinking world.” That is, he wanted to increase the impact of his work by partnering technical visualizations with design that better connects to lived experiences. Check out:\n\nAn article by Allen Hillery (@AlDatavizguy).\nA complete set of the data visualizations provided by Anthony Starks (@ajstarks).\n\nDiscuss your observations. In what ways do you think the W.E.B. Du Bois visualizations might have been more effective at sharing his work than, say, plainer bar charts?\nFOR A DEEPER DISCUSSION AND MORE MODERN EXAMPLES: Read Chapter 3 of Data Feminism on the principle of elevating emotion and embodiment, i.e. the value of “multiple forms of knowledge, including the knowledge that comes from people as living, feeling bodies in the world.”",
    "crumbs": [
      "Simple linear regression: model evaluation"
    ]
  },
  {
    "objectID": "activities/05_slr_model_eval.html#reflection",
    "href": "activities/05_slr_model_eval.html#reflection",
    "title": "Simple linear regression: model evaluation",
    "section": "Reflection",
    "text": "Reflection\nWhat has stuck with you most in our exploration of model evaluation? Why\n\nResponse: Put your response here.",
    "crumbs": [
      "Simple linear regression: model evaluation"
    ]
  },
  {
    "objectID": "activities/05_slr_model_eval.html#render-your-work",
    "href": "activities/05_slr_model_eval.html#render-your-work",
    "title": "Simple linear regression: model evaluation",
    "section": "Render your work",
    "text": "Render your work\n\nClick the “Render” button in the menu bar for this pane (blue arrow pointing right). This will create an HTML file containing all of the directions, code, and responses from this activity. A preview of the HTML will appear in the browser.\nScroll through and inspect the document to check that your work translated to the HTML format correctly.\nClose the browser tab.\nGo to the “Background Jobs” pane in RStudio and click the Stop button to end the rendering process.\nNavigate to your “Activities” subfolder within your “STAT155” folder and locate the HTML file. You can open it again in your browser to double check.\n\n\nSolutions",
    "crumbs": [
      "Simple linear regression: model evaluation"
    ]
  },
  {
    "objectID": "activities/05_slr_model_eval.html#footnotes",
    "href": "activities/05_slr_model_eval.html#footnotes",
    "title": "Simple linear regression: model evaluation",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nhttps://en.wikipedia.org/wiki/W._E._B._Du_Bois↩︎",
    "crumbs": [
      "Simple linear regression: model evaluation"
    ]
  },
  {
    "objectID": "activities/07_slr_cat_predictor.html",
    "href": "activities/07_slr_cat_predictor.html",
    "title": "Simple linear regression: categorical predictor",
    "section": "",
    "text": "Download the .qmd file for this activity here.\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder.\nOpen the qmd file in RStudio, and use it to type your answers/code to the exercises and reflection on the in-class activities.\n\n\n\nBy the end of this lesson, you should be able to:\n\nWrite a model formula for a simple linear regression model with a categorical predictor using indicator variables\nInterpret the intercept and slope coefficients in a simple linear regression model with a categorical predictor\n\n\n\n\nChoose either the reading or the videos to go through before class.\n\nReading: Section 3.9 in the STAT 155 Notes only up through section 3.9.1 Indicator Variables\nVideos:\n\nSimple linear regression: categorical predictor (slides)\nR Code for Categorical Predictors",
    "crumbs": [
      "Simple linear regression: categorical predictor"
    ]
  },
  {
    "objectID": "activities/07_slr_cat_predictor.html#learning-goals",
    "href": "activities/07_slr_cat_predictor.html#learning-goals",
    "title": "Simple linear regression: categorical predictor",
    "section": "",
    "text": "By the end of this lesson, you should be able to:\n\nWrite a model formula for a simple linear regression model with a categorical predictor using indicator variables\nInterpret the intercept and slope coefficients in a simple linear regression model with a categorical predictor",
    "crumbs": [
      "Simple linear regression: categorical predictor"
    ]
  },
  {
    "objectID": "activities/07_slr_cat_predictor.html#readings-and-videos",
    "href": "activities/07_slr_cat_predictor.html#readings-and-videos",
    "title": "Simple linear regression: categorical predictor",
    "section": "",
    "text": "Choose either the reading or the videos to go through before class.\n\nReading: Section 3.9 in the STAT 155 Notes only up through section 3.9.1 Indicator Variables\nVideos:\n\nSimple linear regression: categorical predictor (slides)\nR Code for Categorical Predictors",
    "crumbs": [
      "Simple linear regression: categorical predictor"
    ]
  },
  {
    "objectID": "activities/07_slr_cat_predictor.html#exercise-1-get-to-know-the-data",
    "href": "activities/07_slr_cat_predictor.html#exercise-1-get-to-know-the-data",
    "title": "Simple linear regression: categorical predictor",
    "section": "Exercise 1: Get to know the data",
    "text": "Exercise 1: Get to know the data\nWrite R code to answer the following:\n\nHow many cases and variables do we have? What does a case represent?\nWhat do the first few rows of the data look like?\nConstruct and interpret two different visualizations of the price variable.\nConstruct and interpret a visualization of the cut variable.",
    "crumbs": [
      "Simple linear regression: categorical predictor"
    ]
  },
  {
    "objectID": "activities/07_slr_cat_predictor.html#exercise-2-visualizations",
    "href": "activities/07_slr_cat_predictor.html#exercise-2-visualizations",
    "title": "Simple linear regression: categorical predictor",
    "section": "Exercise 2: Visualizations",
    "text": "Exercise 2: Visualizations\nStart by visualizing this relationship of interest, that between price and cut.\n\nThe appropriate plot depends upon the type of variables we’re plotting. When exploring the relationship between a quantitative response (ridership) and a quantitative predictor (temperature), a scatterplot was an effective choice. After running the code below, explain why a scatterplot is not effective for exploring the relationship between ridership and our categorical cut predictor.\n\n\n# Try a scatterplot\nggplot(diamonds, aes(y = price, x = cut)) + \n    geom_point()\n\n\nSeparately run each chunk below, with two plots. Comment (#) on what changes in the code / output.\n\n\n# Univariate boxplot\nggplot(diamonds, aes(y = price)) + \n    geom_boxplot()\n\n\n# ???\nggplot(diamonds, aes(y = price, x = cut)) + \n    geom_boxplot()\n\n\n# Univariate density plot\nggplot(diamonds, aes(x = price)) + \n    geom_density()\n\n\n# ???\nggplot(diamonds, aes(x = price, color = cut)) + \n    geom_density()\n\n\n# Univariate histogram\nggplot(diamonds, aes(x = price)) + \n    geom_histogram()\n\n\n# ???\nggplot(diamonds, aes(x = price)) + \n    geom_histogram() + \n    facet_wrap(~ cut)\n\n\nDo you notice anything interesting about the relationship between price and cut? What do you think might be happening here?",
    "crumbs": [
      "Simple linear regression: categorical predictor"
    ]
  },
  {
    "objectID": "activities/07_slr_cat_predictor.html#exercise-3-numerical-summaries",
    "href": "activities/07_slr_cat_predictor.html#exercise-3-numerical-summaries",
    "title": "Simple linear regression: categorical predictor",
    "section": "Exercise 3: Numerical summaries",
    "text": "Exercise 3: Numerical summaries\nLet’s follow up our plots with some numerical summaries.\n\nTo warm up, first calculate the mean price across all diamonds.\n\n\n# HINT CODE: don't change this\ndiamonds %&gt;% \n    ___(mean(___))\n\n\n# Your solution\n\n\nTo summarize the trends we observed in the grouped plots above, we can calculate the mean price for each type of cut. This requires the inclusion of the group_by() function:\n\n\n# HINT CODE\n# Calculate mean price by cut\ndiamonds %&gt;% \n    group_by(cut) %&gt;% \n    ___(mean(___))\n\n\n# Your solution\n\n\nExamine the group mean measurements, and make sure that you can match these numbers up with what you see in the plots.",
    "crumbs": [
      "Simple linear regression: categorical predictor"
    ]
  },
  {
    "objectID": "activities/07_slr_cat_predictor.html#exercise-4-modeling-trend",
    "href": "activities/07_slr_cat_predictor.html#exercise-4-modeling-trend",
    "title": "Simple linear regression: categorical predictor",
    "section": "Exercise 4: Modeling trend",
    "text": "Exercise 4: Modeling trend\nThe plots and mean calculations provide some insight into the relationship between price and cut. Next, let’s model the trend in this relationship. After examining the summary table below, complete the model formula:\n\n\nE[price | cut] = ___ +/- ___ cutGood +/- ___ cutVery Good +/- ___ cutPremium +/- ___ cutIdeal\n \n\n# Construct the model\ndiamond_mod &lt;- lm(price ~ cut, data = diamonds)\n\n# Summarize the model\ncoef(summary(diamond_mod))\n\n\nPAUSE: Categorical predictors\nNotice that our cut variable shows up as 4 different indicator variables in our model. An indicator variable numerically indicates if a categorical variable is at a particular level:\n\ncutGood = 1 if the diamond is of Good cut\ncutGood = 0 otherwise (any other value of cut (Fair, Very Good, Premium, Ideal))\n\n\n\nNOTE: We see 4 indicator variables (for Good, Very Good, Premium, and Ideal), but we do not see cutFair in the model output. This is because Fair is the reference level of the cut variable (it’s first alphabetically). You’ll see below that it is, indeed, still in the model. You’ll also see why the term “reference level” makes sense!",
    "crumbs": [
      "Simple linear regression: categorical predictor"
    ]
  },
  {
    "objectID": "activities/07_slr_cat_predictor.html#exercise-5-making-sense-of-the-model",
    "href": "activities/07_slr_cat_predictor.html#exercise-5-making-sense-of-the-model",
    "title": "Simple linear regression: categorical predictor",
    "section": "Exercise 5: Making sense of the model",
    "text": "Exercise 5: Making sense of the model\nRecall our model: E[price | cut] = 4358.7578 - 429.8933 cutGood - 376.9979 cutVery Good + 225.4999 cutPremium - 901.2158 cutIdeal\n\nUse the model formula to calculate the expected/typical price for diamonds of Good cut.\nSimilarly, calculate the expected/typical price for diamonds of Fair cut.\nRe-examine these 2 calculations. Where have you seen these numbers before?!",
    "crumbs": [
      "Simple linear regression: categorical predictor"
    ]
  },
  {
    "objectID": "activities/07_slr_cat_predictor.html#exercise-6-interpreting-coefficients",
    "href": "activities/07_slr_cat_predictor.html#exercise-6-interpreting-coefficients",
    "title": "Simple linear regression: categorical predictor",
    "section": "Exercise 6: Interpreting coefficients",
    "text": "Exercise 6: Interpreting coefficients\nRecall that our model formula is not a formula for a line. Thus we can’t interpret the coefficients as “slopes” as we have before. Taking this into account and reflecting upon your calculations above…\n\nInterpret the intercept coefficient (4358.7578) in terms of the data context. Make sure to use non-causal language, include units, and talk about averages rather than individual cases.\nInterpret the cutGood and cutVery Good coefficients (-429.8933 and -376.9979) in terms of the data context. Hint: where did you use these value in the prediction calculations above?",
    "crumbs": [
      "Simple linear regression: categorical predictor"
    ]
  },
  {
    "objectID": "activities/07_slr_cat_predictor.html#exercise-7-modeling-choices-challenge",
    "href": "activities/07_slr_cat_predictor.html#exercise-7-modeling-choices-challenge",
    "title": "Simple linear regression: categorical predictor",
    "section": "Exercise 7: Modeling choices (CHALLENGE)",
    "text": "Exercise 7: Modeling choices (CHALLENGE)\nWhy do we fit this model in this way (using 4 indicator variables cutGood, cutVery Good, cutPremium, cutIdeal)? Instead, suppose that we created a single variable cutCat that gave each category a numerical value: 0 for Fair, 1 for Good, 2 for Very Good, 3 for Premium, and 4 for Ideal.\nHow would this change things? What are the pros and cons of each approach?",
    "crumbs": [
      "Simple linear regression: categorical predictor"
    ]
  },
  {
    "objectID": "activities/07_slr_cat_predictor.html#reflection",
    "href": "activities/07_slr_cat_predictor.html#reflection",
    "title": "Simple linear regression: categorical predictor",
    "section": "Reflection",
    "text": "Reflection\nThrough the exercises above, you learned how to build and interpret models that incorporate a categorical predictor variable. For the benefit of your future self, summarize how one can interpret the coefficients for a categorical predictor.\n\nResponse: Put your response here.",
    "crumbs": [
      "Simple linear regression: categorical predictor"
    ]
  },
  {
    "objectID": "activities/07_slr_cat_predictor.html#render-your-work",
    "href": "activities/07_slr_cat_predictor.html#render-your-work",
    "title": "Simple linear regression: categorical predictor",
    "section": "Render your work",
    "text": "Render your work\n\nClick the “Render” button in the menu bar for this pane (blue arrow pointing right). This will create an HTML file containing all of the directions, code, and responses from this activity. A preview of the HTML will appear in the browser.\nScroll through and inspect the document to check that your work translated to the HTML format correctly.\nClose the browser tab.\nGo to the “Background Jobs” pane in RStudio and click the Stop button to end the rendering process.\nNavigate to your “Activities” subfolder within your “STAT155” folder and locate the HTML file. You can open it again in your browser to double check.",
    "crumbs": [
      "Simple linear regression: categorical predictor"
    ]
  },
  {
    "objectID": "activities/07_slr_cat_predictor.html#exercise-8-diamond-color",
    "href": "activities/07_slr_cat_predictor.html#exercise-8-diamond-color",
    "title": "Simple linear regression: categorical predictor",
    "section": "Exercise 8: Diamond color",
    "text": "Exercise 8: Diamond color\nConsider modeling price by color.\n\nBefore creating a visualization that shows the relationship between price and color, write down what you expect the plot to look like. Then construct and interpret an apporpriate plot.\nCompute the average price for each color.\nFit an appropriate linear model with lm() and display a short summary of the model.\nWrite out the model formula from the above summary.\nWhich color is the reference level? How can you tell from the model summary?\nInterpret the intercept and two other coefficients from the model in terms of the data context.",
    "crumbs": [
      "Simple linear regression: categorical predictor"
    ]
  },
  {
    "objectID": "activities/07_slr_cat_predictor.html#exercise-9-diamond-clarity",
    "href": "activities/07_slr_cat_predictor.html#exercise-9-diamond-clarity",
    "title": "Simple linear regression: categorical predictor",
    "section": "Exercise 9: Diamond clarity",
    "text": "Exercise 9: Diamond clarity\nIf you want more practice, repeat the steps from Exercise 8 for the clarity variable.\n\nSolutions",
    "crumbs": [
      "Simple linear regression: categorical predictor"
    ]
  },
  {
    "objectID": "activities/08_mlr_intro.html#learning-goals",
    "href": "activities/08_mlr_intro.html#learning-goals",
    "title": "Introduction to multiple regression",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of this lesson, you should be familiar with:\n\nsome limitations of simple linear regression\nthe general goals behind multiple linear regression\nstrategies for visualizing and interpreting multiple linear regression models of \\(y\\) vs 2 predictors, 1 quantitative and 1 categorical"
  },
  {
    "objectID": "activities/08_mlr_intro.html#readings-and-videos",
    "href": "activities/08_mlr_intro.html#readings-and-videos",
    "title": "Introduction to multiple regression",
    "section": "Readings and videos",
    "text": "Readings and videos\nToday is a day to discover ideas, so no readings or videos to go through before class."
  },
  {
    "objectID": "activities/08_mlr_intro.html#motivation",
    "href": "activities/08_mlr_intro.html#motivation",
    "title": "Introduction to multiple regression",
    "section": "Motivation",
    "text": "Motivation\nEXAMPLE 1\nLet’s explore some data on penguins. First, enter install.packages(\"palmerpenguins\") in the console (not Rmd). Then load the penguins data. You can find a codebook for these data by typing ?penguins in your console (not Rmd).\n\n# Load packages\nlibrary(readr)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Load data\nlibrary(palmerpenguins)\ndata(penguins)\npenguins &lt;- penguins %&gt;% \n  filter(species != \"Adelie\", bill_length_mm &lt; 57)\n\n# Check it out\nhead(penguins)\n\nOur goal is to build a model that we can use to get good predictions of penguins’ flipper (“arm”) lengths. Consider 2 simple linear regression models of flipper_length_mm by penguin sex and species:\n\nsummary(lm(flipper_length_mm ~ sex, penguins))$r.squared\nsummary(lm(flipper_length_mm ~ species, penguins))$r.squared\n\nHow might we improve our predictions of flipper_length_mm using only these 2 predictors? What do you think our new R-squared would be?\nEXAMPLE 2\nConsider a simple linear regression model of flipper_length_mm by bill_length_mm:\n\npenguins %&gt;% \n  ggplot(aes(y = flipper_length_mm, x = bill_length_mm)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE)\n\nThoughts? What’s going on here? How does this highlight the limitations of a simple linear regression model?\nEXAMPLE 3\nThe cps dataset contains employment information collected by the U.S. Current Population Survey (CPS) in 2018. We can use these data to explore wages among 18-34 year olds. The original codebook is here.\n\n# Import data\ncps &lt;- read_csv(\"https://mac-stat.github.io/data/cps_2018.csv\") %&gt;% \n  select(-education, -hours) %&gt;% \n  filter(age &gt;= 18, age &lt;= 34) %&gt;% \n  filter(wage &lt; 250000)\n\n\n# Check it out\nhead(cps)\n\nWe can use a simple linear regression model to summarize the relationship of wage with marital status:\n\n# Build the model\nwage_mod &lt;- lm(wage ~ marital, data = cps)\n\n# Summarize the model\ncoef(summary(wage_mod))\n\nWhat do you / don’t you conclude from this model? How does it highlight the limitations of a simple linear regression model?\nReflection: Why are multiple regression models so useful?\nWe can put more than 1 predictor into a regression model! Adding predictors to models…\n\nPredictive viewpoint: Helps us better predict the response\nDescriptive viewpoint: Helps us better understand the isolated (causal) effect of a variable by holding constant confounders\n\nMultiple linear regression model formula\nIn general, a multiple linear regression model of \\(y\\) with multiple predictors \\((x_1, x_2, ..., x_p)\\) is represented by the following formula:\n\\[E[y \\mid x_1, x_2, ..., x_p] = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_p x_p\\]"
  },
  {
    "objectID": "activities/08_mlr_intro.html#exercise-1-visualizing-the-relationship",
    "href": "activities/08_mlr_intro.html#exercise-1-visualizing-the-relationship",
    "title": "Introduction to multiple regression",
    "section": "Exercise 1: Visualizing the relationship",
    "text": "Exercise 1: Visualizing the relationship\nWe’ve learned how to visualize the relationship of flipper_length_mm by bill_length_mm alone:\n\npenguins %&gt;% \n  ggplot(aes(y = flipper_length_mm, x = bill_length_mm)) + \n  geom_point()\n\n\nTHINK: How might we change the scatterplot points to also indicate information about penguin species? (There’s more than 1 approach!)\nTry out your idea by modifying the code below. If you get stuck, talk with the tables around you!\n\n\n# penguins %&gt;% \n#   ggplot(aes(y = flipper_length_mm, x = bill_length_mm, ___ = ___)) + \n#   geom_point()"
  },
  {
    "objectID": "activities/08_mlr_intro.html#exercise-2-visualizing-the-model",
    "href": "activities/08_mlr_intro.html#exercise-2-visualizing-the-model",
    "title": "Introduction to multiple regression",
    "section": "Exercise 2: Visualizing the model",
    "text": "Exercise 2: Visualizing the model\nWe’ve also learned that a simple linear regression model of flipper_length_mm by bill_length_mm alone can be represented by a line:\n\npenguins %&gt;% \n  ggplot(aes(y = flipper_length_mm, x = bill_length_mm)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE)\n\n\nTHINK: Reflecting on your plot of flipper_length_mm by bill_length_mm and species in Exercise 1, how do you think a multiple regression model of flipper_length_mm using both of these predictors would be represented?\nCheck your intuition below by modifying the code below to include species in this plot, as you did in Exercise 1.\n\n\n# penguins %&gt;%\n#   ggplot(aes(y = flipper_length_mm, x = bill_length_mm, ___ = ___)) +\n#   geom_point() +\n#   geom_smooth(method = \"lm\", se = FALSE)"
  },
  {
    "objectID": "activities/08_mlr_intro.html#exercise-3-intuition",
    "href": "activities/08_mlr_intro.html#exercise-3-intuition",
    "title": "Introduction to multiple regression",
    "section": "Exercise 3: Intuition",
    "text": "Exercise 3: Intuition\nYour plot in Exercise 2 demonstrated that the multiple linear regression model of flipper_length_mm by bill_length_mm and species is represented by 2 lines. Let’s interpret the punchlines! For each question, provide an answer along with evidence from the model lines that supports your answer.\n\nWhat’s the relationship between flipper_length_mm and species, no matter a penguin’s bill_length_mm?\nWhat’s the relationship between flipper_length_mm and bill_length_mm, no matter a penguin’s species?\nDoes the rate of increase in flipper_length_mm with bill_length_mm differ between the two species?"
  },
  {
    "objectID": "activities/08_mlr_intro.html#exercise-4-model-formula",
    "href": "activities/08_mlr_intro.html#exercise-4-model-formula",
    "title": "Introduction to multiple regression",
    "section": "Exercise 4: Model formula",
    "text": "Exercise 4: Model formula\nOf course, there’s a formula behind the multiple regression model. We can obtain this using the usual lm() function.\n\n# Build the model\npenguin_mod &lt;- lm(flipper_length_mm ~ bill_length_mm + species, data = penguins)\n\n# Summarize the model\ncoef(summary(penguin_mod))\n\n\nIn the lm() function, how did we communicate that we wanted to model flipper_length_mm by both bill_length_mm and species?\nComplete the following model formula:\nE[flipper_length_mm | bill_length_mm, speciesGentoo] = ___ + ___ * bill_length_mm + ___ * speciesGentoo"
  },
  {
    "objectID": "activities/08_mlr_intro.html#exercise-5-sub-model-formulas",
    "href": "activities/08_mlr_intro.html#exercise-5-sub-model-formulas",
    "title": "Introduction to multiple regression",
    "section": "Exercise 5: Sub-model formulas",
    "text": "Exercise 5: Sub-model formulas\nOk. We now have a single formula for the model. And we observed earlier that this formula is represented by two lines: one describing the relationship between flipper_length_mm and bill_length_mm for Chinstrap penguins and the other for Gentoo penguins. Let’s bring these ideas together. Utilize the model formula to obtain the equations of these two lines, i.e. to obtain the sub-model formulas for the 2 species. Hint: Plug speciesGentoo = 0 and speciesGentoo = 1.\nChinstrap: flipper_length_mm = ___ + ___ bill_length_mm\nGentoo: flipper_length_mm = ___ + ___ bill_length_mm"
  },
  {
    "objectID": "activities/08_mlr_intro.html#exercise-6-coefficients-physical-interpretation",
    "href": "activities/08_mlr_intro.html#exercise-6-coefficients-physical-interpretation",
    "title": "Introduction to multiple regression",
    "section": "Exercise 6: coefficients – physical interpretation",
    "text": "Exercise 6: coefficients – physical interpretation\nReflecting on Exercise 5, let’s interpret what the model coefficients tell us about the physical properties of the two 2 sub-model lines. Choose the correct option given in parentheses:\n\nThe intercept coefficient, 127.75, is the intercept of the line for (Chinstrap / Gentoo) penguins.\nThe bill_length_mm coefficient, 1.40, is the (intercept / slope) of both lines.\nThe speciesGentoo coefficient, 22.85, indicates that the (intercept / slope) of the line for Gentoo is 22.85mm higher than the (intercept / slope) of the line for Chinstrap. Similarly, since the lines are parallel, the line for Gentoo is 22.85mm higher than the line for Chinstrap at any bill_length_mm."
  },
  {
    "objectID": "activities/08_mlr_intro.html#exercise-7-coefficients-contextual-interpretation",
    "href": "activities/08_mlr_intro.html#exercise-7-coefficients-contextual-interpretation",
    "title": "Introduction to multiple regression",
    "section": "Exercise 7: coefficients – contextual interpretation",
    "text": "Exercise 7: coefficients – contextual interpretation\nNext, interpret each coefficient in a contextually meaningful way. What do they tell us about penguin flipper lengths?!\n\nInterpret 127.75 (intercept of the Chinstrap line).\nInterpret 1.40 (slope of both lines). For both Chinstrap and Gentoo penguins, we expect…\nInterpret 22.85. At any bill_length_mm, we expect…"
  },
  {
    "objectID": "activities/08_mlr_intro.html#exercise-8-prediction",
    "href": "activities/08_mlr_intro.html#exercise-8-prediction",
    "title": "Introduction to multiple regression",
    "section": "Exercise 8: Prediction",
    "text": "Exercise 8: Prediction\nNow that we better understand the model, let’s use it to predict flipper lengths! Recall the model summary and visualization:\n\ncoef(summary(penguin_mod))\n\npenguins %&gt;% \n  ggplot(aes(y = flipper_length_mm, x = bill_length_mm, color = species)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE)\n\n\nPredict the flipper length of a Chinstrap penguin with a 50mm long bill. Make sure your calculation is consistent with the plot.\n\n\n# 127.75 + 1.40*___ + 22.85*___\n\n\nPredict the flipper length of a Gentoo penguin with a 50mm long bill. Make sure your calculation is consistent with the plot.\n\n\n# 127.75 + 1.40*___ + 22.85*___\n\n\nUse the predict() function to confirm your predictions in parts a and b.\n\n\n# Confirm the calculation in part a\n# predict(penguin_mod,\n#         newdata = data.frame(bill_length_mm = ___, species = \"___\"))\n\n# Confirm the calculation in part b\n# predict(penguin_mod,\n#         newdata = data.frame(bill_length_mm = ___, species = \"___\"))"
  },
  {
    "objectID": "activities/08_mlr_intro.html#exercise-9-r-squared",
    "href": "activities/08_mlr_intro.html#exercise-9-r-squared",
    "title": "Introduction to multiple regression",
    "section": "Exercise 9: R-squared",
    "text": "Exercise 9: R-squared\nFinally, recall that improving our predictions was one motivation for multiple linear regression (using 2 predictors instead of 1). To this end, consider the R-squared values of the simple linear regression models that use just one predictor at a time:\n\nsummary(lm(flipper_length_mm ~ bill_length_mm, data = penguins))$r.squared\n\nsummary(lm(flipper_length_mm ~ species, data = penguins))$r.squared\n\n\nIf you had to use only 1 of our 2 predictors, which would give the better predictions of flipper_length_mm?\nWhat do you guess is the R-squared of our multiple regression model that uses both of these predictors? Why?\nCheck your intuition. How does the R-squared of our multiple regression model compare to that of the 2 separate simple linear regression models?\n\n\nsummary(penguin_mod)$r.squared"
  },
  {
    "objectID": "activities/08_mlr_intro.html#reflection",
    "href": "activities/08_mlr_intro.html#reflection",
    "title": "Introduction to multiple regression",
    "section": "Reflection",
    "text": "Reflection\nYou’ve now explored your first multiple regression model! Thus you likely have a lot of questions about what’s to come. What are they?\n\nResponse: Put your response here.\n\n\nSolutions"
  },
  {
    "objectID": "solutions/07_slr_cat_predictor.html",
    "href": "solutions/07_slr_cat_predictor.html",
    "title": "Solutions for Simple linear regression: categorical predictor",
    "section": "",
    "text": "A case represents a single diamond.\nThe distribution of price is right skewed with considerable high outliers. The right skew is evidenced by the mean price ($3932) being much higher than the median price ($2401).\nMost diamonds in this data are of Good cut or better. Ideal cut diamonds are the most common with each succesive grade being the next most common.\n\n\n# Load packages and import data\nlibrary(ggplot2)\nlibrary(dplyr)\n\ndata(diamonds)\n\n# A little bit of data wrangling code - let's not focus on this for now\ndiamonds &lt;- diamonds %&gt;% \n    mutate(\n        cut = factor(cut, ordered = FALSE),\n        color = factor(color, ordered = FALSE),\n        clarity = factor(clarity, ordered = FALSE)\n    )\n\n\ndim(diamonds)\n\n[1] 53940    10\n\nhead(diamonds)\n\n# A tibble: 6 × 10\n  carat cut       color clarity depth table price     x     y     z\n  &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; &lt;fct&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n\n# Visualize price (outcome variable)\nggplot(diamonds, aes(x = price)) +\n    geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nggplot(diamonds, aes(y = price)) +\n    geom_boxplot()\n\n\n\n\n\n\n\ndiamonds %&gt;%\n    summarize(mean(price), median(price), sd(price))\n\n# A tibble: 1 × 3\n  `mean(price)` `median(price)` `sd(price)`\n          &lt;dbl&gt;           &lt;dbl&gt;       &lt;dbl&gt;\n1         3933.            2401       3989.\n\n# Visualize cut (predictor variable)\nggplot(diamonds, aes(x = cut)) +\n    geom_bar()\n\n\n\n\n\n\n\ndiamonds %&gt;% \n    count(cut)\n\n# A tibble: 5 × 2\n  cut           n\n  &lt;fct&gt;     &lt;int&gt;\n1 Fair       1610\n2 Good       4906\n3 Very Good 12082\n4 Premium   13791\n5 Ideal     21551"
  },
  {
    "objectID": "solutions/07_slr_cat_predictor.html#exercise-1-get-to-know-the-data",
    "href": "solutions/07_slr_cat_predictor.html#exercise-1-get-to-know-the-data",
    "title": "Solutions for Simple linear regression: categorical predictor",
    "section": "",
    "text": "A case represents a single diamond.\nThe distribution of price is right skewed with considerable high outliers. The right skew is evidenced by the mean price ($3932) being much higher than the median price ($2401).\nMost diamonds in this data are of Good cut or better. Ideal cut diamonds are the most common with each succesive grade being the next most common.\n\n\n# Load packages and import data\nlibrary(ggplot2)\nlibrary(dplyr)\n\ndata(diamonds)\n\n# A little bit of data wrangling code - let's not focus on this for now\ndiamonds &lt;- diamonds %&gt;% \n    mutate(\n        cut = factor(cut, ordered = FALSE),\n        color = factor(color, ordered = FALSE),\n        clarity = factor(clarity, ordered = FALSE)\n    )\n\n\ndim(diamonds)\n\n[1] 53940    10\n\nhead(diamonds)\n\n# A tibble: 6 × 10\n  carat cut       color clarity depth table price     x     y     z\n  &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; &lt;fct&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n\n# Visualize price (outcome variable)\nggplot(diamonds, aes(x = price)) +\n    geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nggplot(diamonds, aes(y = price)) +\n    geom_boxplot()\n\n\n\n\n\n\n\ndiamonds %&gt;%\n    summarize(mean(price), median(price), sd(price))\n\n# A tibble: 1 × 3\n  `mean(price)` `median(price)` `sd(price)`\n          &lt;dbl&gt;           &lt;dbl&gt;       &lt;dbl&gt;\n1         3933.            2401       3989.\n\n# Visualize cut (predictor variable)\nggplot(diamonds, aes(x = cut)) +\n    geom_bar()\n\n\n\n\n\n\n\ndiamonds %&gt;% \n    count(cut)\n\n# A tibble: 5 × 2\n  cut           n\n  &lt;fct&gt;     &lt;int&gt;\n1 Fair       1610\n2 Good       4906\n3 Very Good 12082\n4 Premium   13791\n5 Ideal     21551"
  },
  {
    "objectID": "solutions/07_slr_cat_predictor.html#exercise-2-visualizations",
    "href": "solutions/07_slr_cat_predictor.html#exercise-2-visualizations",
    "title": "Solutions for Simple linear regression: categorical predictor",
    "section": "Exercise 2: Visualizations",
    "text": "Exercise 2: Visualizations\nStart by visualizing this relationship of interest, that between price and cut.\n\nWe just don’t see anything clearly on a scatterplot. With the small number of unique values of the predictor variable, all of the points are bunched up on each other.\n\n\n# Try a scatterplot\nggplot(diamonds, aes(y = price, x = cut)) + \n    geom_point()\n\n\n\n\n\n\n\n\n\nSeparately run each chunk below, with two plots. Comment (#) on what changes in the code / output.\n\n\n# Univariate boxplot\nggplot(diamonds, aes(y = price)) + \n    geom_boxplot()\n\n\n\n\n\n\n\n\n\n# Separate boxes by category\nggplot(diamonds, aes(y = price, x = cut)) + \n    geom_boxplot()\n\n\n\n\n\n\n\n\n\n# Univariate density plot\nggplot(diamonds, aes(x = price)) + \n    geom_density()\n\n\n\n\n\n\n\n\n\n# Separate density plots by category\nggplot(diamonds, aes(x = price, color = cut)) + \n    geom_density()\n\n\n\n\n\n\n\n\n\n# Univariate histogram\nggplot(diamonds, aes(x = price)) + \n    geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\n# Separate histograms by category\nggplot(diamonds, aes(x = price)) + \n    geom_histogram() + \n    facet_wrap(~ cut)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\nThe relationship between price and cut seems to be opposite what we would expect. The diamonds with the best cut (Ideal) have the lowest average price, and the ones with the worst cut (Fair) are woth the most. Maybe something else is different between the diamonds with the best and worst cuts…size maybe?"
  },
  {
    "objectID": "solutions/07_slr_cat_predictor.html#exercise-3-numerical-summaries",
    "href": "solutions/07_slr_cat_predictor.html#exercise-3-numerical-summaries",
    "title": "Solutions for Simple linear regression: categorical predictor",
    "section": "Exercise 3: Numerical summaries",
    "text": "Exercise 3: Numerical summaries\nLet’s follow up our plots with some numerical summaries.\n\nMean price across all diamonds:\n\n\ndiamonds %&gt;% \n    summarize(mean(price))\n\n# A tibble: 1 × 1\n  `mean(price)`\n          &lt;dbl&gt;\n1         3933.\n\n\n\nMean price for each type of cut:\n\n\ndiamonds %&gt;% \n    group_by(cut) %&gt;% \n    summarize(mean(price))\n\n\nGroup means should reflect what you see in the plots (easiest to see in the boxplots)"
  },
  {
    "objectID": "solutions/07_slr_cat_predictor.html#exercise-4-modeling-trend",
    "href": "solutions/07_slr_cat_predictor.html#exercise-4-modeling-trend",
    "title": "Solutions for Simple linear regression: categorical predictor",
    "section": "Exercise 4: Modeling trend",
    "text": "Exercise 4: Modeling trend\n\n# Construct the model\ndiamond_mod &lt;- lm(price ~ cut, data = diamonds)\n\n# Summarize the model\ncoef(summary(diamond_mod))\n\n              Estimate Std. Error   t value     Pr(&gt;|t|)\n(Intercept)  4358.7578   98.78795 44.122361 0.000000e+00\ncutGood      -429.8933  113.84940 -3.775982 1.595493e-04\ncutVery Good -376.9979  105.16422 -3.584849 3.375707e-04\ncutPremium    225.4999  104.39521  2.160060 3.077240e-02\ncutIdeal     -901.2158  102.41155 -8.799943 1.408406e-18\n\n\nE[price | cut] = 4358.7578 - 429.8933 cutGood - 376.9979 cutVery Good + 225.4999 cutPremium - 901.2158 cutIdeal"
  },
  {
    "objectID": "solutions/07_slr_cat_predictor.html#exercise-5-making-sense-of-the-model",
    "href": "solutions/07_slr_cat_predictor.html#exercise-5-making-sense-of-the-model",
    "title": "Solutions for Simple linear regression: categorical predictor",
    "section": "Exercise 5: Making sense of the model",
    "text": "Exercise 5: Making sense of the model\n\nExpected/typical price for diamonds of Good cut:\n\nE[price | cut] = 4358.7578 - 429.8933 * 1 - 376.9979 * 0 + 225.4999 * 0 - 901.2158 * 0 = 4358.7578 - 429.8933 = $3928.865\n\npredict(diamond_mod, newdata = data.frame(cut = \"Good\"))\n\n       1 \n3928.864 \n\n\n\nExpected/typical price for diamonds of Fair cut:\n\nE[price | cut] = 4358.7578 - 429.8933 * 0 - 376.9979 * 0 + 225.4999 * 0 - 901.2158 * 0 = $4358.7578\n\npredict(diamond_mod, newdata = data.frame(cut = \"Fair\"))\n\n       1 \n4358.758 \n\n\n\nThese come from our group mean calculations in Exercise 3b!"
  },
  {
    "objectID": "solutions/07_slr_cat_predictor.html#exercise-6-interpreting-coefficients",
    "href": "solutions/07_slr_cat_predictor.html#exercise-6-interpreting-coefficients",
    "title": "Solutions for Simple linear regression: categorical predictor",
    "section": "Exercise 6: Interpreting coefficients",
    "text": "Exercise 6: Interpreting coefficients\nRecall that our model formula is not a formula for a line. Thus we can’t interpret the coefficients as “slopes” as we have before. Taking this into account and reflecting upon your calculations above…\n\nThe average price of a Fair cut diamonds is $4358.7578.\n\nInterpretation of cutGood coefficient: On average, Good cut diamonds are worth $429.89 less than Fair cut diamonds.\nInterpretation of cutVery Good coefficient: On average, Very Good cut diamonds are worth $377.00 less than Fair cut diamonds."
  },
  {
    "objectID": "solutions/07_slr_cat_predictor.html#exercise-7-modeling-choices-challenge",
    "href": "solutions/07_slr_cat_predictor.html#exercise-7-modeling-choices-challenge",
    "title": "Solutions for Simple linear regression: categorical predictor",
    "section": "Exercise 7: Modeling choices (CHALLENGE)",
    "text": "Exercise 7: Modeling choices (CHALLENGE)\nWhy do we fit this model in this way (using 4 indicator variables cutGood, cutVery Good, cutPremium, cutIdeal)? Instead, suppose that we created a single variable cutCat that gave each category a numerical value: 0 for Fair, 1 for Good, 2 for Very Good, 3 for Premium, and 4 for Ideal.\n\nIf we used 0-4 instead of creating indicator variables, we would be constraining the change from 0 to 1, from 1 to 2, etc. to always be of the same magnitude. That is, a 1 unit change in the cut variable would always have the same change in price in our model.\nUsing separate indicator variables allows the difference between subsequent categories to be different, which allows our model to be a bit more nuanced. It is possible to take nuance too far though. For example, in our previous investigations of bikeshare data, we modeled ridership versus temperature. We treated temperature as a quantitative predictor. Imagine if we had created an indicator variable for each unique temperature in the data—that would be so many variables! Having so many variables creates a very complex model which can be hard to make sense of. (These ideas are addressed further in STAT 253: Statistical Machine Learning!)"
  },
  {
    "objectID": "solutions/07_slr_cat_predictor.html#exercise-8-diamond-color",
    "href": "solutions/07_slr_cat_predictor.html#exercise-8-diamond-color",
    "title": "Solutions for Simple linear regression: categorical predictor",
    "section": "Exercise 8: Diamond color",
    "text": "Exercise 8: Diamond color\nConsider modeling price by color.\n\nThe best color diamonds are J, and worst are D. We would expect D diamonds to have the lowest price and increase steadily as we get to J. This is in fact what we see in the boxplots.\n\n\nggplot(diamonds, aes(x = color, y = price)) +\n    geom_boxplot()\n\n\n\n\n\n\n\ndiamonds %&gt;% \n    group_by(color) %&gt;% \n    summarize(mean(price))\n\n# A tibble: 7 × 2\n  color `mean(price)`\n  &lt;fct&gt;         &lt;dbl&gt;\n1 D             3170.\n2 E             3077.\n3 F             3725.\n4 G             3999.\n5 H             4487.\n6 I             5092.\n7 J             5324.\n\n\n\nWe fit a linear model and obtain the model formula: E[price | color] = 3169.95 - 93.20 colorE + 554.93 colorF + 829.18 colorG + 1316.72 colorH + 1921.92 colorI + 2153.86 colorJ\n\n\ndiamond_mod2 &lt;- lm(price ~ color, data = diamonds)\n\ncoef(summary(diamond_mod2))\n\n              Estimate Std. Error   t value      Pr(&gt;|t|)\n(Intercept) 3169.95410   47.70694 66.446391  0.000000e+00\ncolorE       -93.20162   62.04724 -1.502107  1.330752e-01\ncolorF       554.93230   62.38527  8.895246  6.004834e-19\ncolorG       829.18158   60.34470 13.740751  6.836340e-43\ncolorH      1316.71510   64.28715 20.481777  7.074714e-93\ncolorI      1921.92086   71.55308 26.860072 7.078041e-158\ncolorJ      2153.86392   88.13203 24.439060 3.414906e-131\n\n\n\nColor D is the reference level because we don’t see its indicator variable in the model output.\nInterpretation of the intercept: Diamonds with D color cost $3169.95 on average.\nInterpretation of the colorE coefficient: Diamonds with E color cost $93.20 less than D color diamonds on average.\nInterpretation of the colorF coefficient: Diamonds with F color cost $554.93 more than D color diamonds on average."
  },
  {
    "objectID": "solutions/07_slr_cat_predictor.html#exercise-9-diamond-clarity",
    "href": "solutions/07_slr_cat_predictor.html#exercise-9-diamond-clarity",
    "title": "Solutions for Simple linear regression: categorical predictor",
    "section": "Exercise 9: Diamond clarity",
    "text": "Exercise 9: Diamond clarity\nWe see the unexpected result that diamonds of better clarity (VS1 and higher) have lower average prices. In fact the best clarity diamonds (VVS1 and IF) have the lowest average prices. What might be going on? What if the most clear diamonds were also quite small…\n\nggplot(diamonds, aes(x = clarity, y = price)) +\n    geom_boxplot()\n\n\n\n\n\n\n\ndiamonds %&gt;% \n    group_by(clarity) %&gt;% \n    summarize(mean(price))\n\n# A tibble: 8 × 2\n  clarity `mean(price)`\n  &lt;fct&gt;           &lt;dbl&gt;\n1 I1              3924.\n2 SI2             5063.\n3 SI1             3996.\n4 VS2             3925.\n5 VS1             3839.\n6 VVS2            3284.\n7 VVS1            2523.\n8 IF              2865.\n\ndiamond_mod3 &lt;- lm(price ~ clarity, data = diamonds)\n\ncoef(summary(diamond_mod3))\n\n                 Estimate Std. Error      t value      Pr(&gt;|t|)\n(Intercept)  3924.1686910   144.5619 27.145247517 3.513547e-161\nclaritySI2   1138.8599147   150.2746  7.578526239  3.550711e-14\nclaritySI1     71.8324571   148.6049  0.483378837  6.288287e-01\nclarityVS2      0.8207037   148.8672  0.005512992  9.956013e-01\nclarityVS1    -84.7132999   150.9746 -0.561109670  5.747251e-01\nclarityVVS2  -640.4316203   154.7737 -4.137858008  3.510944e-05\nclarityVVS1 -1401.0540535   158.5401 -8.837224284  1.010097e-18\nclarityIF   -1059.3295848   171.8990 -6.162510636  7.210567e-10"
  },
  {
    "objectID": "activities/02_foundations_univariate.html",
    "href": "activities/02_foundations_univariate.html",
    "title": "Univariate visualization and summaries",
    "section": "",
    "text": "Download the .qmd file for this activity here.\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder.\nOpen the qmd file in Rstudio, and use it to type your answers/code to the exercises and reflection on the in-class activities.\nFollow this process for this and all future activities",
    "crumbs": [
      "Univariate visualization and summaries"
    ]
  },
  {
    "objectID": "activities/02_foundations_univariate.html#learning-goals",
    "href": "activities/02_foundations_univariate.html#learning-goals",
    "title": "Univariate visualization and summaries",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of this lesson, you should be able to:\n\nUnderstand the basics of working with Quarto documents in RStudio\nDescribe what a case (or unit of analysis) represents in a dataset.\nDescribe what a variable represents in a dataset.\nIdentify whether a variable is categorical or quantitative and what summarizations and visualizations are appropriate for that variable\nWrite R code to read in data and to summarize and visualize a single variable at a time.\nInterpret key features of barplots, boxplots, histograms, and density plots\nDescribe information about the distribution of a quantitative variable using the concepts of shape, center, spread, and outliers\nRelate summary statistics of data to the concepts of shape, center, spread, and outliers",
    "crumbs": [
      "Univariate visualization and summaries"
    ]
  },
  {
    "objectID": "activities/02_foundations_univariate.html#readings-and-videos",
    "href": "activities/02_foundations_univariate.html#readings-and-videos",
    "title": "Univariate visualization and summaries",
    "section": "Readings and videos",
    "text": "Readings and videos\nChoose either the reading or the videos to go through before class.\n\nReading: Sections 2.1-2.4, 2.6 in the STAT 155 Notes\nVideos:\n\nUnivariate visualization and summarization (slides)\nR Code for Categorical Visualization and Summarization\nR Code for Quantitative Visualization and Summarization",
    "crumbs": [
      "Univariate visualization and summaries"
    ]
  },
  {
    "objectID": "activities/02_foundations_univariate.html#exercise-1-get-curious",
    "href": "activities/02_foundations_univariate.html#exercise-1-get-curious",
    "title": "Univariate visualization and summaries",
    "section": "Exercise 1: Get curious",
    "text": "Exercise 1: Get curious\n\nHypothesize with each other: what themes do you think might come up often in Dear Abby letters?\nAfter brainstorming, take a quick glance at the original article from The Pudding to see what themes they explored.\nGo to the very end of the Pudding article to the section titled “Data and Method”. In thinking about the who, what, when, where, why, and how of data context, what concerns/limitations surface with regards to using this data to learn about Americans’ concerns over the decades?",
    "crumbs": [
      "Univariate visualization and summaries"
    ]
  },
  {
    "objectID": "activities/02_foundations_univariate.html#exercise-2-importing-and-getting-to-know-the-data",
    "href": "activities/02_foundations_univariate.html#exercise-2-importing-and-getting-to-know-the-data",
    "title": "Univariate visualization and summaries",
    "section": "Exercise 2: Importing and getting to know the data",
    "text": "Exercise 2: Importing and getting to know the data\n\n# Load package\nlibrary(tidyverse)\nlibrary(readr)\n\n# Read in the course evaluation data\nabby &lt;- read_csv(\"https://mac-stat.github.io/data/dear_abby.csv\")\n\n\nClick on the Environment tab (generally in the upper right hand pane in RStudio). Then click the abby line. The abby data will pop up as a separate pane (like viewing a spreadsheet) – check it out.\nIn this tidy dataset, what is the unit of observation? That is, what is represented in each row of the dataset?\nWhat term do we use for the columns of the dataset?\nTry out each function below. Identify what each function tells you about the abby data and note this in the ???:\n\n\n# ??? [what do both numbers mean?]\ndim(abby)\n\n# ???\nnrow(abby)\n\n# ???\nncol(abby)\n\n# ???\nhead(abby)\n\n# ???\nnames(abby)\n\n\nWe can learn what functions do by pulling up help pages. To do this, click inside the Console pane, and enter ?function_name. For example, to pull up a help page for the dim() function, we can type ?dim and hit Enter. Pull up the help page for the head() function.\n\nRead the Description.\nChallenge: Look at the Arguments and Examples sections to figure out how to display the first 10 rows of the evals data (instead of the default first 6 rows).",
    "crumbs": [
      "Univariate visualization and summaries"
    ]
  },
  {
    "objectID": "activities/02_foundations_univariate.html#exercise-3-preparing-to-summarize-and-visualize-the-data",
    "href": "activities/02_foundations_univariate.html#exercise-3-preparing-to-summarize-and-visualize-the-data",
    "title": "Univariate visualization and summaries",
    "section": "Exercise 3: Preparing to summarize and visualize the data",
    "text": "Exercise 3: Preparing to summarize and visualize the data\nIn the next exercises, we will be exploring themes in the Dear Abby questions and the overall “mood” or sentiment of the questions. Before continuing, read the codebook for this dataset for some context about sentiment analysis, which gives us a measure of the mood/sentiment of a text.\n\nWhat sentiment variables do we have in the dataset? Are they quantitative or categorical?\nIf we were able to create a theme variable that took values like “friendship”, “marriage”, and “relationships”, would theme be quantitative or categorical?\nWhat visualizations are appropriate for looking at the distribution of a single quantitative variable? What about a single categorical variable?",
    "crumbs": [
      "Univariate visualization and summaries"
    ]
  },
  {
    "objectID": "activities/02_foundations_univariate.html#exercise-4-exploring-themes-in-the-letters",
    "href": "activities/02_foundations_univariate.html#exercise-4-exploring-themes-in-the-letters",
    "title": "Univariate visualization and summaries",
    "section": "Exercise 4: Exploring themes in the letters",
    "text": "Exercise 4: Exploring themes in the letters\nThe dplyr package provides many useful functions for managing data (like creating new variables, summarizing information). The stringr package provides tools for working with strings (text). We’ll use these packages to search for words in the questions in order to (roughly) identify themes/subjects.\nThe code below searches for words related to mothers, fathers, marriage, and money and combines them into a single theme variable.\n\nInside mutate() the line moms = ifelse(str_detect(question_only, \"mother|mama|mom\"), \"mom\", \"no mom\") creates a new variable called moms. If any of the text “mother”, “mama”, or “mom” (which covers “mommy”) is found, then the variable takes the value “mom”. Otherwise, the variable takes the value “no mom”.\nThe dads, marriage, and money variables are created similarly.\nThe themes = str_c(moms, dads, marriage, money, sep = \"|\") line takes the 4 created variables and combines the text of those variables separated with a |. For example, one value of the themes variable is “mom|no_dad|no_marriage|no_money” (which contains words about moms but not dads, marriage, or money).\n\n\nlibrary(dplyr)\nlibrary(stringr)\n\nabby &lt;- abby %&gt;% \n    mutate(\n        moms = ifelse(str_detect(question_only, \"mother|mama|mom\"), \"mom\", \"no mom\"),\n        dads = ifelse(str_detect(question_only, \"father|papa|dad\"), \"dad\", \"no dad\"),\n        marriage = ifelse(str_detect(question_only, \"marriage|marry|married\"), \"marriage\", \"no marriage\"),\n        money = ifelse(str_detect(question_only, \"money|finance\"), \"money\", \"no money\"),\n        themes = str_c(moms, dads, marriage, money, sep = \"|\")\n    )\n\n\nModify the code above however you wish to replace themes (e.g., replace “moms” with something else) or add new themes to search for. If you want to add a new subject to search for, copy and paste a line for an existing subject above the themes line, and modify the code like this:\n\nIf your subject is captured by multiple words: YOUR_SUBJECT = ifelse(str_detect(question_only, \"WORD1|WORD2|ETC\"), \"SUBJECT\", \"NO SUBJECT\"),\nIf your subject is captured by a single word: YOUR_SUBJECT = ifelse(str_detect(question_only, \"WORD\"), \"SUBJECT\", \"NO SUBJECT\"),\nTry to have no more than 6 subjects—otherwise we’ll have too many themes, which will complicate exploration.\n\nThe code below makes a barplot of the themes variable using the ggplot2 visualization package. Before making the plot, make note of what you expect the plot might look like. (This might be hard–just do your best!) Then compare to what you observe when you run the code chunk to make the plot. (Clearly defining your expectations first is good scientific practice to avoid confirmation bias.)\n\n\n# Load package\nlibrary(ggplot2)\n\n# barplot\nggplot(abby, aes(x = themes)) +\n    geom_bar() +\n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\nWe can follow up on the barplot with a simple numerical summary. Whereas the ggplot2 package is great for visualizations, dplyr is great for numerical summaries. The code below constructs a table of the number of questions with each theme. Make sure that these numerical summaries match up with what you saw in the barplot.\n\n\n# Construct a table of counts\nabby %&gt;% \n    count(themes)\n\n\nBefore proceeding, let’s break down the plotting code above. Run each chunk to see how the two lines of code above build up the plot in “layers”. Add comments (on the lines starting with #) to document what you notice.\n\n\n# ???\nggplot(abby, aes(x = themes))\n\n\n# ???\nggplot(abby, aes(x = themes)) +\n    geom_bar()\n\n\n# ???\nggplot(abby, aes(x = themes)) +\n    geom_bar() +\n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\n# ???\nggplot(abby, aes(x = themes)) +\n    geom_bar() +\n    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +\n    theme_classic()",
    "crumbs": [
      "Univariate visualization and summaries"
    ]
  },
  {
    "objectID": "activities/02_foundations_univariate.html#exercise-5-exploring-sentiment",
    "href": "activities/02_foundations_univariate.html#exercise-5-exploring-sentiment",
    "title": "Univariate visualization and summaries",
    "section": "Exercise 5: Exploring sentiment",
    "text": "Exercise 5: Exploring sentiment\nWe’ll look at the distribution of the afinn_overall sentiment variable and associated summary statistics.\n\nThe code below creates a boxplot of this variable. In the comment, make note of how this code is simliar to the code for the barplot above. As in the previous exercise, before running the code chunk to create the plot, make note of what you expect the boxplot to look like.\n\n\n# ???\nggplot(abby, aes(x = afinn_overall)) +\n    geom_boxplot()\n\n\nChallenge: Using the code for the barplot and boxplot as a guide, try to make a histogram and a density plot of the overall average ratings.\n\nWhat information is given by the tallest bar of the histogram?\nHow would you describe the shape of the distribution?\n\n\n\n# Histogram\n\n# Density plot\n\n\nWe can compute summary statistics (numerical summaries) for a quantitative variable using the summary() function or with the summarize() function from the dplyr package. (1st Qu. and 3rd Qu. stand for first and third quartile.) After inspecting these summaries, look back to your boxplot, histogram, and density plot. Which plots show which summaries most clearly?\n\n\n# Summary statistics\n# Using summary() - convenient for computing many summaries in one command\n# Does not show the standard deviation\nsummary(abby$afinn_overall)\n\n# Using summarize() from dplyr\n# Note that we use %&gt;% to pipe the data into the summarize() function\n# We need to use na.rm = TRUE because there are missing values (NAs)\nabby %&gt;% \n    summarize(mean(afinn_overall, na.rm = TRUE), median(afinn_overall, na.rm = TRUE), sd(afinn_overall, na.rm = TRUE))\n\n\nWrite a good paragraph describing the information in the histogram (or density plot) by discussing shape, center, spread, and outliers. Incorporate the numerical summaries from part c.",
    "crumbs": [
      "Univariate visualization and summaries"
    ]
  },
  {
    "objectID": "activities/02_foundations_univariate.html#exercise-6-box-plots-vs.-histograms-vs.-density-plots",
    "href": "activities/02_foundations_univariate.html#exercise-6-box-plots-vs.-histograms-vs.-density-plots",
    "title": "Univariate visualization and summaries",
    "section": "Exercise 6: Box plots vs. histograms vs. density plots",
    "text": "Exercise 6: Box plots vs. histograms vs. density plots\nWe took 3 different approaches to plotting the quantitative average course variable above. They all have pros and cons.\n\nWhat is one pro about the boxplot in comparison to the histogram and density plot?\nWhat is one con about the boxplot in comparison to the histogram and density plots?\nIn this example, which plot do you prefer and why?",
    "crumbs": [
      "Univariate visualization and summaries"
    ]
  },
  {
    "objectID": "activities/02_foundations_univariate.html#exercise-7-explore-outliers",
    "href": "activities/02_foundations_univariate.html#exercise-7-explore-outliers",
    "title": "Univariate visualization and summaries",
    "section": "Exercise 7: Explore outliers",
    "text": "Exercise 7: Explore outliers\nGiven that Dear Abby column is an advice column, it seems natural that the sentiment of the questions would lean more negative. What’s going on with the questions that have particularly positive sentiments?\nWe can use the filter() function in the dplyr package to look at the . Based on the plots of afinn_overall that you made in Exercise 5, pick a threshold for the afinn_overall variable—we’ll say that questions with an overall sentiment score above this threshold are high outliers. Fill in this number where it says YOUR_THRESHOLD below.\n\nabby %&gt;% \n    filter(afinn_overall &gt; YOUR_THRESHOLD) %&gt;% \n    pull(question_only)\n\nWhat do you notice? Why might these questions have such high sentiment scores?",
    "crumbs": [
      "Univariate visualization and summaries"
    ]
  },
  {
    "objectID": "activities/02_foundations_univariate.html#exercise-8-returning-to-our-context-looking-ahead",
    "href": "activities/02_foundations_univariate.html#exercise-8-returning-to-our-context-looking-ahead",
    "title": "Univariate visualization and summaries",
    "section": "Exercise 8: Returning to our context, looking ahead",
    "text": "Exercise 8: Returning to our context, looking ahead\nIn this activity, we explored data on Dear Abby question, with a focus on exploring a single variable at a time.\n\nIn big picture terms, what have we learned about Dear Abby questions?\nWhat further curiosities do you have about the data?",
    "crumbs": [
      "Univariate visualization and summaries"
    ]
  },
  {
    "objectID": "activities/02_foundations_univariate.html#exercise-9-different-ways-to-think-about-data-visualization",
    "href": "activities/02_foundations_univariate.html#exercise-9-different-ways-to-think-about-data-visualization",
    "title": "Univariate visualization and summaries",
    "section": "Exercise 9: Different ways to think about data visualization",
    "text": "Exercise 9: Different ways to think about data visualization\nIn working with and visualizing data, it’s important to keep in mind what a data point represents. It can reflect the experience of a real person. It might reflect the sentiment in a piece of art. It might reflect history. We’ve taken one very narrow and technical approach to data visualization. Check out the following examples, and write some notes about anything you find interesting.\n\nDear Data\nW.E.B. DuBois\nDecolonizing Data Viz\nPhase Change Project (by Prof Kim, Mac research students)",
    "crumbs": [
      "Univariate visualization and summaries"
    ]
  },
  {
    "objectID": "activities/02_foundations_univariate.html#exercise-10-rendering-your-work",
    "href": "activities/02_foundations_univariate.html#exercise-10-rendering-your-work",
    "title": "Univariate visualization and summaries",
    "section": "Exercise 10: Rendering your work",
    "text": "Exercise 10: Rendering your work\nSave this file, and then click the “Render” button in the menu bar for this pane (blue arrow pointing right). This will create an HTML file containing all of the directions, code, and responses from this activity. A preview of the HTML will appear in the browser.\n\nScroll through and inspect the document to see how your work was translated into this HTML format. Neat!\nClose the browser tab.\nGo to the “Background Jobs” pane in RStudio and click the Stop button to end the rendering process.\nNavigate to your “Activities” subfolder within your “STAT155” folder and locate the HTML file. You can open it again in your browser to double check.",
    "crumbs": [
      "Univariate visualization and summaries"
    ]
  },
  {
    "objectID": "activities/02_foundations_univariate.html#reflection",
    "href": "activities/02_foundations_univariate.html#reflection",
    "title": "Univariate visualization and summaries",
    "section": "Reflection",
    "text": "Reflection\nGo to the top of this file and review the learning objectives for this lesson. Which objectives do you have a good handle on, are at least familiar with, or are struggling with? What feels challenging right now? What are some wins from the day?\n\nResponse: Put your response here.",
    "crumbs": [
      "Univariate visualization and summaries"
    ]
  },
  {
    "objectID": "activities/02_foundations_univariate.html#exercise-11-read-in-and-get-to-know-the-weather-data",
    "href": "activities/02_foundations_univariate.html#exercise-11-read-in-and-get-to-know-the-weather-data",
    "title": "Univariate visualization and summaries",
    "section": "Exercise 11: Read in and get to know the weather data",
    "text": "Exercise 11: Read in and get to know the weather data\nDaily weather data are available for 3 locations in Perth, Australia.\n\nView the codebook here.\nComplete the code below to read in the data.\n\n\n# Replace the ??? with your own name for the weather data\n# Replace the ___ with the correct function\n??? &lt;- ___(\"https://mac-stat.github.io/data/weather_3_locations.csv\")",
    "crumbs": [
      "Univariate visualization and summaries"
    ]
  },
  {
    "objectID": "activities/02_foundations_univariate.html#exercise-12-exploring-the-data-structure",
    "href": "activities/02_foundations_univariate.html#exercise-12-exploring-the-data-structure",
    "title": "Univariate visualization and summaries",
    "section": "Exercise 12: Exploring the data structure",
    "text": "Exercise 12: Exploring the data structure\nCheck out the basic features of the weather data.\n\n# Examine the first six cases\n\n# Find the dimensions of the data\n\nWhat does a case represent in this data?",
    "crumbs": [
      "Univariate visualization and summaries"
    ]
  },
  {
    "objectID": "activities/02_foundations_univariate.html#exercise-13-exploring-rainfall",
    "href": "activities/02_foundations_univariate.html#exercise-13-exploring-rainfall",
    "title": "Univariate visualization and summaries",
    "section": "Exercise 13: Exploring rainfall",
    "text": "Exercise 13: Exploring rainfall\nThe raintoday variable contains information about rainfall.\n\nIs this variable quantitative or categorical?\nCreate an appropriate visualization, and compute appropriate numerical summaries.\nWhat do you learn about rainfall in Perth?\n\n\n# Visualization\n\n# Numerical summaries",
    "crumbs": [
      "Univariate visualization and summaries"
    ]
  },
  {
    "objectID": "activities/02_foundations_univariate.html#exercise-14-exploring-temperature",
    "href": "activities/02_foundations_univariate.html#exercise-14-exploring-temperature",
    "title": "Univariate visualization and summaries",
    "section": "Exercise 14: Exploring temperature",
    "text": "Exercise 14: Exploring temperature\nThe maxtemp variable contains information on the daily high temperature.\n\nIs this variable quantitative or categorical?\nCreate an appropriate visualization, and compute appropriate numerical summaries.\nWhat do you learn about high temperatures in Perth?\n\n\n# Visualization\n\n# Numerical summaries",
    "crumbs": [
      "Univariate visualization and summaries"
    ]
  },
  {
    "objectID": "activities/02_foundations_univariate.html#exercise-15-customizing-challenge",
    "href": "activities/02_foundations_univariate.html#exercise-15-customizing-challenge",
    "title": "Univariate visualization and summaries",
    "section": "Exercise 15: Customizing! (CHALLENGE)",
    "text": "Exercise 15: Customizing! (CHALLENGE)\nThough you will naturally absorb some RStudio code throughout the semester, being an effective statistical thinker and “programmer” does not require that we memorize all code. That would be impossible! In contrast, using the foundation you built today, do some digging online to learn how to customize your visualizations.\n\nFor the histogram below, add a title and more meaningful axis labels. Specifically, title the plot “Distribution of max temperatures in Perth”, change the x-axis label to “Maximum temperature” and y-axis label to “Number of days”. HINT: Do a Google search for something like “add axis labels ggplot”.\n\n\n# Add a title and axis labels\nggplot(weather, aes(x = maxtemp)) + \n    geom_histogram()\n\n\nAdjust the code below in order to color the bars green. NOTE: Color can be an effective tool, but here it is simply gratuitous.\n\n\n# Make the bars green\nggplot(weather, aes(x = raintoday)) + \n    geom_bar()\n\n\nCheck out the ggplot2 cheat sheet. Try making some of the other kinds of univariate plots outlined there.\nWhat else would you like to change about your plot? Try it!\n\n\nSolutions",
    "crumbs": [
      "Univariate visualization and summaries"
    ]
  },
  {
    "objectID": "activities/03_slr_introduction.html",
    "href": "activities/03_slr_introduction.html",
    "title": "Simple linear regression: Visualization and Introduction",
    "section": "",
    "text": "Download the .qmd file for this activity here.\nFile organization: Save this file in the “Activities” subfolder of your “STAT155” folder.\nOpen the qmd file in RStudio, and use it to type your answers/code to the exercises and reflection on the in-class activities.",
    "crumbs": [
      "Simple linear regression: Visualization and Introduction"
    ]
  },
  {
    "objectID": "activities/03_slr_introduction.html#learning-goals",
    "href": "activities/03_slr_introduction.html#learning-goals",
    "title": "Simple linear regression: Visualization and Introduction",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of this lesson, you should be able to:\n\nVisualize and describe the relationship between two quantitative variables using a scatterplot\nWrite R code to create a scatterplot and compute the linear correlation between two quantitative variables\nDescribe/identify weak / strong, and positive / negative correlation from a point cloud\nBuild intuition for fitting lines to quantify the relationship between two quantitative variables",
    "crumbs": [
      "Simple linear regression: Visualization and Introduction"
    ]
  },
  {
    "objectID": "activities/03_slr_introduction.html#readings-and-videos",
    "href": "activities/03_slr_introduction.html#readings-and-videos",
    "title": "Simple linear regression: Visualization and Introduction",
    "section": "Readings and videos",
    "text": "Readings and videos\n\nReading: Sections 2.8, 3.1-3.3, 3.6 in the STAT 155 Notes\nVideos:\n\nSummarizing the Relationships between Two Quantitative Variables (Time: 12:12)\nIntroduction to Linear Models (Time: 10:57)\nMethod of Least Squares (Time: 5:10)\nInterpretation of Intercept and Slope (Time: 11:09)\nR Code for Fitting a Linear Model (Time: 11:07)",
    "crumbs": [
      "Simple linear regression: Visualization and Introduction"
    ]
  },
  {
    "objectID": "activities/03_slr_introduction.html#exercise-1-get-to-know-the-data",
    "href": "activities/03_slr_introduction.html#exercise-1-get-to-know-the-data",
    "title": "Simple linear regression: Visualization and Introduction",
    "section": "Exercise 1: Get to know the data",
    "text": "Exercise 1: Get to know the data\n\nCreate a new code chunk by clicking the green “C” button with a green + sign in the top right of the menu bar. In this code chunk, use an appropriate function to look at the first few rows of the data.\nCreate a new code chunk, and use an appropriate function to learn how much data we have (in terms of cases and variables).\nWhat does a case represent?\nNavigate to the FAQ page and read the response to the “How does this site work? Do you just download results from the federations?” question. What do you learn about data quality and completeness from this response?",
    "crumbs": [
      "Simple linear regression: Visualization and Introduction"
    ]
  },
  {
    "objectID": "activities/03_slr_introduction.html#exercise-2-mutating-our-data",
    "href": "activities/03_slr_introduction.html#exercise-2-mutating-our-data",
    "title": "Simple linear regression: Visualization and Introduction",
    "section": "Exercise 2: Mutating our data",
    "text": "Exercise 2: Mutating our data\nStrength-to-weight ratio (SWR) is defined as TotalKg/BodyweightKg. We can use the mutate() function from the dplyr package to create a new variable in our dataframe for SWR using the following code:\n\n# The %&gt;% is called a \"pipe\" and feeds what comes before it\n# into what comes after (lifts data is \"fed into\" the mutate() function).\n# When creating a new variable, we often reassign the data frame to itself,\n# which updates the existing columns in lifts with the additional \"new\" column(s)\n# in lifts!\nlifts &lt;- lifts %&gt;% \n    mutate(NEW_VARIABLE_NAME = Age/BestSquatKg)\n\nAdapt the example above to create a new variable called SWR, where SWR is defined as TotalKg/BodyweightKg.",
    "crumbs": [
      "Simple linear regression: Visualization and Introduction"
    ]
  },
  {
    "objectID": "activities/03_slr_introduction.html#exercise-3-get-to-know-the-outcomeresponse-variable",
    "href": "activities/03_slr_introduction.html#exercise-3-get-to-know-the-outcomeresponse-variable",
    "title": "Simple linear regression: Visualization and Introduction",
    "section": "Exercise 3: Get to know the outcome/response variable",
    "text": "Exercise 3: Get to know the outcome/response variable\nLet’s get acquainted with the SWR variable.\n\nConstruct an appropriate plot to visualize the distribution of this variable, and compute appropriate numerical summaries.\nWrite a good paragraph interpreting the plot and numerical summaries.",
    "crumbs": [
      "Simple linear regression: Visualization and Introduction"
    ]
  },
  {
    "objectID": "activities/03_slr_introduction.html#exercise-4-data-visualization---two-quantitative-variables",
    "href": "activities/03_slr_introduction.html#exercise-4-data-visualization---two-quantitative-variables",
    "title": "Simple linear regression: Visualization and Introduction",
    "section": "Exercise 4: Data visualization - two quantitative variables",
    "text": "Exercise 4: Data visualization - two quantitative variables\nWe’d like to visualize the relationship between body weight and the strength-to-weight ratio. A scatterplot (or informally, a “point cloud”) allows us to do this! The code below creates a scatterplot of body weight vs. SWR using ggplot().\n\n# scatterplot\n\n# The alpha = 0.5 in geom_point() adds transparency to the points\n# to make them easier to see. You can make this smaller for more transparency\nlifts %&gt;%\n  ggplot(aes(x = BodyweightKg, y = SWR)) +\n  geom_point(alpha = 0.5)\n\n\nThis is your first bivariate data visualization (visualization for two variables)! What differences do you notice in the code structure when creating a bivariate visualization, compared to univariate visualizations we’ve worked with before?\nWhat similarities do you notice in the code structure?\nDoes there appear to be some sort of pattern in the structure of the point cloud? Describe it, in no more than three sentences! Comment on the direction of the relationship between the two variables (positive? negative?) and the spread of the points (are they dispersed? close together?).",
    "crumbs": [
      "Simple linear regression: Visualization and Introduction"
    ]
  },
  {
    "objectID": "activities/03_slr_introduction.html#exercise-5-scatterplots---patterns-in-point-clouds",
    "href": "activities/03_slr_introduction.html#exercise-5-scatterplots---patterns-in-point-clouds",
    "title": "Simple linear regression: Visualization and Introduction",
    "section": "Exercise 5: Scatterplots - patterns in point clouds",
    "text": "Exercise 5: Scatterplots - patterns in point clouds\nSometimes, it can be easier to see a pattern in a point cloud by adding a smoothing line to our scatterplots. The code below adapts the code in Exercise 4 to do this:\n\n# scatterplot with smoothing line\nlifts %&gt;%\n  ggplot(aes(x = BodyweightKg, y = SWR)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth()\n\n\nLook back at your answer to Exercise 4 (c). Does the smoothing line assist you in seeing a pattern, or change your answer at all? Why or why not?\nBased on the scatterplot with the smoothing line added above, does there appear to be a linear relationship between body weight and SWR (i.e. would a straight line do a decent job at summarizing the relationship between these two variables)? Why or why not?",
    "crumbs": [
      "Simple linear regression: Visualization and Introduction"
    ]
  },
  {
    "objectID": "activities/03_slr_introduction.html#exercise-6-correlation",
    "href": "activities/03_slr_introduction.html#exercise-6-correlation",
    "title": "Simple linear regression: Visualization and Introduction",
    "section": "Exercise 6: Correlation",
    "text": "Exercise 6: Correlation\nWe can quantify the linear relationship between two quantitative variables using a numerical summary known as correlation (sometimes known as a “correlation coefficient” or “Pearson’s correlation”). Correlation can range from -1 to 1, where a correlation of 0 indicates that there is no linear relationship between the two quantitative variables.\n\n\n\n\n\n\nCorrelation\n\n\n\n\n\nThe Pearson correlation coefficient, \\(r_{x, y}\\), of \\(x\\) and \\(y\\) is the (almost) average of products of the z-scores of variables \\(x\\) and \\(y\\):\n\\[\nr_{x, y} = \\frac{\\sum z_x z_y}{n - 1}\n\\]\n\n\n\nIn general, we will want to be able to describe (qualitatively) two aspects of correlation:\n\nStrength\n\n\nIs the correlation between x and y strong, or weak, i.e. how closely do the points fit around a line? This has to do with how dispersed our point clouds are.\n\n\nDirection\n\n\nIs the correlation between x and y positive or negative, i.e. does y go “up” when x goes “up” (positive), or does y go “down” when x goes “up” (negative)?\n\nStronger correlations will be further from 0 (closer to -1 or 1), and positive and negative correlations will have the appropriate respective sign (above or below zero).\n\nRather than a smooth trend line, we can force the line we add to our scatterplots to be linear using geom_smooth(method = 'lm'), as below:\n\n\n# scatterplot with linear trend line\nlifts %&gt;%\n  ggplot(aes(x = BodyweightKg, y = SWR)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\")\n\n\nBased on the above scatterplot, how would you describe the correlation between body weight and SWR, in terms of strength and direction?\nMake a guess as to what numerical value the correlation between body weight and SWR will have, based on your response to part (b).",
    "crumbs": [
      "Simple linear regression: Visualization and Introduction"
    ]
  },
  {
    "objectID": "activities/03_slr_introduction.html#exercise-7-computing-correlation-in-r",
    "href": "activities/03_slr_introduction.html#exercise-7-computing-correlation-in-r",
    "title": "Simple linear regression: Visualization and Introduction",
    "section": "Exercise 7: Computing correlation in R",
    "text": "Exercise 7: Computing correlation in R\nWe can compute the correlation between body weight and SWR using summarize and cor functions:\n\n# correlation\n\n# Note: the order in which you put your two quantitative variables into the cor\n# function doesn't matter! Try switching them around to cpmfor, this for yourself\nlifts %&gt;%\n  summarize(cor(SWR, BodyweightKg))\n\nIs the computed correlation close to what you guessed in Exercise 6 part (c)?",
    "crumbs": [
      "Simple linear regression: Visualization and Introduction"
    ]
  },
  {
    "objectID": "activities/03_slr_introduction.html#exercise-8-limitations-of-correlation",
    "href": "activities/03_slr_introduction.html#exercise-8-limitations-of-correlation",
    "title": "Simple linear regression: Visualization and Introduction",
    "section": "Exercise 8: Limitations of correlation",
    "text": "Exercise 8: Limitations of correlation\nWe previously noted that correlation was a numerical summary of the linear relationship between two variables. We’ll now go through some examples of relationships between quantitative variables to demonstrate why it is incredibly important to visualize our data in addition to just computing numerical summaries!\nFor this exercise, we’ll be working with the anscombe dataset, which is built in to R. To load this dataset into our environment, we run the following code:\n\n# load anscombe data\ndata(\"anscombe\")\n\nThe anscombe dataset contains four different pairs of quantitative variables:\n\nx1, y1\nx2, y2\nx3, y3\nx4, y4\n\nAdapt the code we used in Exercise 7 to compute the correlation between each of these four pairs of variables, below:\n\n# correlation between x1, y1\n\n# correlation between x2, y2\n\n# correlation between x3, y3\n\n# correlation between x4, y4\n\n\nWhat do you notice about each of these correlations (if the answer to this isn’t obvious, double-check your code)?\nDescribe these correlations in terms of strength and direction, using only the numerical summary to assist you in your description.\nDraw an example on the white board or at your tables of what you think the point clouds for these pairs of variables might look like. There are only 11 observations, so you can draw all 11 points if you’d like!\nAdapt the code for scatterplots given previously in this activity to make four distinct scatterplots for each pair of quantitative variables in the anscombe dataset. You do not need to add a smooth trend line or a linear trend line to these plots.\n\n\n# scatterplot: x1, y1\n\n# scatterplot: x2, y2\n\n# scatterplot: x3, y3\n\n# scatterplot: x4, y4\n\n\nBased on the correlations you calculated and scatterplots you made, what is the message of this last exercise as it relates to the limits of correlation?",
    "crumbs": [
      "Simple linear regression: Visualization and Introduction"
    ]
  },
  {
    "objectID": "activities/03_slr_introduction.html#reflection",
    "href": "activities/03_slr_introduction.html#reflection",
    "title": "Simple linear regression: Visualization and Introduction",
    "section": "Reflection",
    "text": "Reflection\nMuch of statistics is about making (hopefully) reasonable assumptions in attempt to summarize observed relationships in data. Today we started considering assumptions of linear relationships between quantitative variables.\nReview the learning objectives at the top of this file and today’s activity. How do you imagine assumptions of linearity might be useful in terms of quantifying relationships between quantitative variables? How do you imagine these assumptions could sometimes fall short, or even be unethical in certain cases?\n\nResponse: Put your response here.",
    "crumbs": [
      "Simple linear regression: Visualization and Introduction"
    ]
  },
  {
    "objectID": "activities/03_slr_introduction.html#exercise-9-lines-of-best-fit",
    "href": "activities/03_slr_introduction.html#exercise-9-lines-of-best-fit",
    "title": "Simple linear regression: Visualization and Introduction",
    "section": "Exercise 9: Lines of best fit",
    "text": "Exercise 9: Lines of best fit\nIn this activity, we’ve learned how to fit straight lines to data, to help us visualize the relationship between two quantitative variables. So far, ggplot has chosen the line for us. How does it know which line is “best”, and what does “best” even mean?\nFor this exercise, we’ll consider the relationship between x1 and y1 in the anscombe dataset. Run the following code, which creates a scatterplot with a fitted line to our data using the function geom_abline:\n\n# scatterplot with a fitted line, whose slope is 0.4 and intercept is 3\nanscombe %&gt;%\n  ggplot(aes(x = x1, y = y1)) +\n  geom_point() +\n  geom_abline(slope = 0.4, intercept = 3, col = \"blue\", size = 1)\n\nDescribe the line that you see. Do you think the line is “good”? What are you using to define “good”?\nSome things to think about:\n\nHow many points are above the line?\nHow many points are below the line?\nAre the distances of the points above and below the line roughly similar, or is there meaningful difference?\n\nNow we’ll add another line to our plot. Which line do you think is better suited for this data? Why? Be specific!\n\n# scatterplot with a fitted line, whose slope is 0.4 and intercept is 3\nanscombe %&gt;%\n  ggplot(aes(x = x1, y = y1)) +\n  geom_point() +\n  geom_abline(slope = 0.4, intercept = 3, col = \"blue\", size = 1) +\n  geom_abline(slope = 0.5, intercept = 4, col = \"orange\", size = 1)\n\nIt’s usually quite simple to note when a line is bad, but more difficult to quantify when a line is a good fit for our data. Consider the following line:\n\n# scatterplot with a fitted line, whose slope is 0.4 and intercept is 3\nanscombe %&gt;%\n  ggplot(aes(x = x1, y = y1)) +\n  geom_point() +\n  geom_abline(slope = -0.5, intercept = 10, col = \"red\", size = 1) \n\nIn the next activity, we’ll formalize the principle of least squares, which will give us one particular definition of a line of best fit that is commonly used in statistics! We’ll take advantage of the vertical distances between each point and the fitted line (residuals), which will help us define (mathematically) a line that best fits our data:\n\nlibrary(broom)\nanscombe %&gt;%\n  lm(y1 ~ x1, data = .) %&gt;%\n  augment() %&gt;%\n  ggplot(aes(x = x1, y = y1)) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  geom_segment(aes(xend = x1, yend = .fitted), col = \"red\") +\n  geom_point()",
    "crumbs": [
      "Simple linear regression: Visualization and Introduction"
    ]
  },
  {
    "objectID": "activities/03_slr_introduction.html#exercise-10-correlation-and-extreme-values",
    "href": "activities/03_slr_introduction.html#exercise-10-correlation-and-extreme-values",
    "title": "Simple linear regression: Visualization and Introduction",
    "section": "Exercise 10: Correlation and extreme values",
    "text": "Exercise 10: Correlation and extreme values\nIn this exercise, we’ll explore how correlation changes with the addition of extreme values, or observations. We’ll begin by generating a toy dataset called dat with two quantitative variables, x and y. Run the code below to create the dataset.\nwhile not required, recall that you can look up function documentation in R using the ? in front of a function name to figure out what that function is doing!\n\n# create a toy dataset\nset.seed(1234)\nx &lt;- rnorm(100, mean = 5, sd = 2)\ny &lt;- -3 * x + rnorm(100, sd = 4)\ndat &lt;- data.frame(x = x, y = y)\n\n\nMake a scatterplot of x vs. y.\n\n\n# scatterplot\n\n\nBased on your scatterplot, describe the correlation between x and y in terms of strength and direction.\nGuess the correlation (the numerical value) between x and y.\nCompute the correlation between x and y. Was your guess from part (c) close?\n\n\n# correlation\n\n\nSuppose we observe an additional observation with x = 15 and y = -45. We can create a new data frame, dat_new1, that contains this observation in addition to the original ones as follows:\n\n\n# creating dat_new1\nx1 &lt;- c(x, 15)\ny1 &lt;- c(y, -45)\ndat_new1 &lt;- data.frame(x = x1, y = y1)\n\n\nMake a scatterplot of x vs. y for this new data frame, and compute the correlation between x and y. Did your correlation change very much with the addition of this observation? Hypothesize why or why not.\n\n\n# scatterplot\n\n# correlation\n\n\nSuppose instead of our additional observation having values x = 15 and y = -45, we instead observe x = 15 and y = -15. We can create a new data frame, dat_new2, that contains this observation in addition to the original ones as follows:\n\n\n# creating dat_new1\nx2 &lt;- c(x, 15)\ny2 &lt;- c(y, 45)\ndat_new2 &lt;- data.frame(x = x2, y = y2)\n\n\nMake a scatterplot of x vs. y for this new data frame, and compute the correlation between x and y. Did your correlation change very much with the addition of this observation? Hypothesize why or why not.\n\n\n# scatterplot\n\n# correlation\n\n\nWhat do you think the takeaway message is of this exercise?\n\n\nChallenge Add linear trend lines to your scatterplots from parts (f) and (h). Does this give you any additional insight into why the correlations may have changed in different ways with the addition of a new observation?\n\n\nSolutions",
    "crumbs": [
      "Simple linear regression: Visualization and Introduction"
    ]
  }
]